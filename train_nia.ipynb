{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d59d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98dc1777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322569ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b26c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from models.ST_Former import GenerateModel\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dataloader.dataset_NIA import train_data_loader, test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8e3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from runner_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a7cc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pseudoarg():\n",
    "    def __init__(self):\n",
    "        self.workers = 1\n",
    "        self.epochs = 100\n",
    "        self.start_epoch = 0\n",
    "        self.batch_size = 32\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.9\n",
    "        self.weight_decay = 1e-4\n",
    "        self.print_freq = 10\n",
    "        self.resume = None\n",
    "        self.data_set = 0\n",
    "        \n",
    "args = Pseudoarg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fddf0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "time_str = now.strftime(\"%m%d_%H%M_\")\n",
    "project_path = \"/media/di/data/lee/nia/\"\n",
    "log_txt_path = project_path + 'log/' + time_str + 'set' + str(args.data_set) + '-log.txt'\n",
    "log_curve_path = project_path + 'log/' + time_str + 'set' + str(args.data_set) + '-log.png'\n",
    "checkpoint_path = project_path + 'checkpoint/' + time_str + 'set' + str(args.data_set) + '-model.pth'\n",
    "best_checkpoint_path = project_path + 'checkpoint/' + time_str + 'set' + str(args.data_set) + '-model_best.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f229715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 12-27 05:05\n",
      "The training set: set 0\n",
      "DataParallel(\n",
      "  (module): GenerateModel(\n",
      "    (s_former): ResNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (spatial_transformer): Transformer(\n",
      "        (layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): Residual(\n",
      "              (fn): PreNorm(\n",
      "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (fn): Attention(\n",
      "                  (to_qkv): Linear(in_features=256, out_features=768, bias=False)\n",
      "                  (to_out): Sequential(\n",
      "                    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "                    (1): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Residual(\n",
      "              (fn): PreNorm(\n",
      "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "                    (1): GELU()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                    (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "                    (4): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (t_former): TFormer(\n",
      "      (spatial_transformer): Transformer(\n",
      "        (layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): Residual(\n",
      "              (fn): PreNorm(\n",
      "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (fn): Attention(\n",
      "                  (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "                  (to_out): Sequential(\n",
      "                    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "                    (1): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Residual(\n",
      "              (fn): PreNorm(\n",
      "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "                    (1): GELU()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "                    (4): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): Residual(\n",
      "              (fn): PreNorm(\n",
      "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (fn): Attention(\n",
      "                  (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "                  (to_out): Sequential(\n",
      "                    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "                    (1): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Residual(\n",
      "              (fn): PreNorm(\n",
      "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "                    (1): GELU()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "                    (4): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): ModuleList(\n",
      "            (0): Residual(\n",
      "              (fn): PreNorm(\n",
      "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (fn): Attention(\n",
      "                  (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
      "                  (to_out): Sequential(\n",
      "                    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "                    (1): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Residual(\n",
      "              (fn): PreNorm(\n",
      "                (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "                    (1): GELU()\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "                    (4): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=512, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "best_acc = 0\n",
    "recorder = RecorderMeter(args.epochs)\n",
    "print('The training time: ' + now.strftime(\"%m-%d %H:%M\"))\n",
    "print('The training set: set ' + str(args.data_set))\n",
    "os.makedirs(project_path+\"log/\",exist_ok = True)\n",
    "with open(log_txt_path, 'a') as f:\n",
    "    f.write('The training set: set ' + str(args.data_set) + '\\n')\n",
    "\n",
    "# create model and load pre_trained parameters\n",
    "model = GenerateModel()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "print(model)\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf13e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc = checkpoint['best_acc']\n",
    "        recorder = checkpoint['recorder']\n",
    "        best_acc = best_acc.cuda()\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2534592f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video number:2801\n",
      "video number:800\n",
      "********************0********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [0][ 0/87]\tLoss 1.5449 (1.5449)\tAccuracy 31.250 (31.250)\n",
      "Epoch: [0][10/87]\tLoss 5.0881 (4.0296)\tAccuracy 28.125 (23.864)\n",
      "Epoch: [0][20/87]\tLoss 1.6990 (3.2211)\tAccuracy 21.875 (22.470)\n",
      "Epoch: [0][30/87]\tLoss 1.6571 (2.8030)\tAccuracy  9.375 (20.968)\n",
      "Epoch: [0][40/87]\tLoss 1.6023 (2.5302)\tAccuracy 18.750 (21.037)\n",
      "Epoch: [0][50/87]\tLoss 1.6378 (2.3635)\tAccuracy 21.875 (20.772)\n",
      "Epoch: [0][60/87]\tLoss 1.5337 (2.2386)\tAccuracy 31.250 (21.107)\n",
      "Epoch: [0][70/87]\tLoss 1.6574 (2.1570)\tAccuracy 12.500 (21.083)\n",
      "Epoch: [0][80/87]\tLoss 1.6386 (2.0904)\tAccuracy 31.250 (21.721)\n",
      "Test: [ 0/25]\tLoss 1.6151 (1.6151)\tAccuracy 25.000 (25.000)\n",
      "Test: [10/25]\tLoss 1.6140 (1.6367)\tAccuracy 25.000 (19.318)\n",
      "Test: [20/25]\tLoss 1.6885 (1.6500)\tAccuracy  6.250 (19.196)\n",
      "Current Accuracy: 18.875\n",
      "The best accuracy: 18.875\n",
      "An epoch time: 66.3s\n",
      "********************1********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [1][ 0/87]\tLoss 1.6613 (1.6613)\tAccuracy 15.625 (15.625)\n",
      "Epoch: [1][10/87]\tLoss 1.6145 (1.6278)\tAccuracy 18.750 (20.739)\n",
      "Epoch: [1][20/87]\tLoss 1.6343 (1.6224)\tAccuracy 21.875 (22.470)\n",
      "Epoch: [1][30/87]\tLoss 1.5833 (1.6193)\tAccuracy 25.000 (22.480)\n",
      "Epoch: [1][40/87]\tLoss 1.6734 (1.6191)\tAccuracy 18.750 (23.018)\n",
      "Epoch: [1][50/87]\tLoss 1.6227 (1.6140)\tAccuracy 21.875 (24.265)\n",
      "Epoch: [1][60/87]\tLoss 1.5977 (1.6129)\tAccuracy 34.375 (24.334)\n",
      "Epoch: [1][70/87]\tLoss 1.6997 (1.6122)\tAccuracy  9.375 (24.164)\n",
      "Epoch: [1][80/87]\tLoss 1.6224 (1.6150)\tAccuracy 12.500 (23.495)\n",
      "Test: [ 0/25]\tLoss 1.6023 (1.6023)\tAccuracy 25.000 (25.000)\n",
      "Test: [10/25]\tLoss 1.6011 (1.6016)\tAccuracy 15.625 (25.000)\n",
      "Test: [20/25]\tLoss 1.5862 (1.6094)\tAccuracy 37.500 (23.363)\n",
      "Current Accuracy: 23.625\n",
      "The best accuracy: 23.625\n",
      "An epoch time: 63.5s\n",
      "********************2********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [2][ 0/87]\tLoss 1.5721 (1.5721)\tAccuracy 28.125 (28.125)\n",
      "Epoch: [2][10/87]\tLoss 1.6290 (1.6103)\tAccuracy 21.875 (25.000)\n",
      "Epoch: [2][20/87]\tLoss 1.5933 (1.6089)\tAccuracy 25.000 (23.661)\n",
      "Epoch: [2][30/87]\tLoss 1.5869 (1.6050)\tAccuracy 31.250 (24.093)\n",
      "Epoch: [2][40/87]\tLoss 1.7258 (1.6121)\tAccuracy  6.250 (22.790)\n",
      "Epoch: [2][50/87]\tLoss 1.6103 (1.6137)\tAccuracy 25.000 (21.998)\n",
      "Epoch: [2][60/87]\tLoss 1.6233 (1.6118)\tAccuracy 21.875 (22.541)\n",
      "Epoch: [2][70/87]\tLoss 1.5696 (1.6107)\tAccuracy 28.125 (22.931)\n",
      "Epoch: [2][80/87]\tLoss 1.5419 (1.6082)\tAccuracy 25.000 (23.110)\n",
      "Test: [ 0/25]\tLoss 1.6222 (1.6222)\tAccuracy 18.750 (18.750)\n",
      "Test: [10/25]\tLoss 1.6411 (1.6247)\tAccuracy 18.750 (25.000)\n",
      "Test: [20/25]\tLoss 1.5714 (1.6405)\tAccuracy 34.375 (25.595)\n",
      "Current Accuracy: 25.375\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 62.3s\n",
      "********************3********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [3][ 0/87]\tLoss 1.6474 (1.6474)\tAccuracy 25.000 (25.000)\n",
      "Epoch: [3][10/87]\tLoss 1.5198 (1.5700)\tAccuracy 25.000 (24.148)\n",
      "Epoch: [3][20/87]\tLoss 1.6265 (1.5931)\tAccuracy 12.500 (19.940)\n",
      "Epoch: [3][30/87]\tLoss 1.6258 (1.5985)\tAccuracy 21.875 (20.464)\n",
      "Epoch: [3][40/87]\tLoss 1.5833 (1.5991)\tAccuracy 31.250 (21.951)\n",
      "Epoch: [3][50/87]\tLoss 1.5990 (1.6014)\tAccuracy 25.000 (21.998)\n",
      "Epoch: [3][60/87]\tLoss 1.5342 (1.6001)\tAccuracy 37.500 (22.387)\n",
      "Epoch: [3][70/87]\tLoss 1.5742 (1.6007)\tAccuracy 28.125 (22.271)\n",
      "Epoch: [3][80/87]\tLoss 1.6554 (1.5995)\tAccuracy 18.750 (22.377)\n",
      "Test: [ 0/25]\tLoss 1.6049 (1.6049)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.6261 (1.6103)\tAccuracy 15.625 (25.568)\n",
      "Test: [20/25]\tLoss 1.5702 (1.6240)\tAccuracy 34.375 (25.000)\n",
      "Current Accuracy: 25.000\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 62.3s\n",
      "********************4********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [4][ 0/87]\tLoss 1.5880 (1.5880)\tAccuracy 34.375 (34.375)\n",
      "Epoch: [4][10/87]\tLoss 1.5960 (1.5949)\tAccuracy 18.750 (23.580)\n",
      "Epoch: [4][20/87]\tLoss 1.5932 (1.5959)\tAccuracy 28.125 (25.298)\n",
      "Epoch: [4][30/87]\tLoss 1.5659 (1.6020)\tAccuracy 12.500 (23.185)\n",
      "Epoch: [4][40/87]\tLoss 1.5261 (1.6009)\tAccuracy 31.250 (23.628)\n",
      "Epoch: [4][50/87]\tLoss 1.5844 (1.6017)\tAccuracy 21.875 (23.346)\n",
      "Epoch: [4][60/87]\tLoss 1.5806 (1.6040)\tAccuracy 25.000 (23.207)\n",
      "Epoch: [4][70/87]\tLoss 1.5973 (1.6036)\tAccuracy 15.625 (23.460)\n",
      "Epoch: [4][80/87]\tLoss 1.6643 (1.6060)\tAccuracy 15.625 (23.187)\n",
      "Test: [ 0/25]\tLoss 1.5921 (1.5921)\tAccuracy 28.125 (28.125)\n",
      "Test: [10/25]\tLoss 1.5946 (1.6039)\tAccuracy 25.000 (21.875)\n",
      "Test: [20/25]\tLoss 1.6094 (1.6185)\tAccuracy 18.750 (18.601)\n",
      "Current Accuracy: 19.125\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 62.5s\n",
      "********************5********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [5][ 0/87]\tLoss 1.6187 (1.6187)\tAccuracy 18.750 (18.750)\n",
      "Epoch: [5][10/87]\tLoss 1.6002 (1.6307)\tAccuracy 28.125 (22.443)\n",
      "Epoch: [5][20/87]\tLoss 1.6717 (1.6129)\tAccuracy 15.625 (22.619)\n",
      "Epoch: [5][30/87]\tLoss 1.5757 (1.6103)\tAccuracy 28.125 (22.177)\n",
      "Epoch: [5][40/87]\tLoss 1.6593 (1.6086)\tAccuracy  9.375 (23.095)\n",
      "Epoch: [5][50/87]\tLoss 1.5200 (1.6059)\tAccuracy 25.000 (23.346)\n",
      "Epoch: [5][60/87]\tLoss 1.6367 (1.6076)\tAccuracy 18.750 (22.848)\n",
      "Epoch: [5][70/87]\tLoss 1.5886 (1.6066)\tAccuracy 28.125 (22.491)\n",
      "Epoch: [5][80/87]\tLoss 1.5516 (1.6068)\tAccuracy 25.000 (22.492)\n",
      "Test: [ 0/25]\tLoss 1.5940 (1.5940)\tAccuracy 25.000 (25.000)\n",
      "Test: [10/25]\tLoss 1.5982 (1.6031)\tAccuracy 15.625 (24.148)\n",
      "Test: [20/25]\tLoss 1.6018 (1.6146)\tAccuracy 31.250 (24.256)\n",
      "Current Accuracy: 24.000\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.8s\n",
      "********************6********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [6][ 0/87]\tLoss 1.6198 (1.6198)\tAccuracy 21.875 (21.875)\n",
      "Epoch: [6][10/87]\tLoss 1.6269 (1.5957)\tAccuracy 21.875 (26.136)\n",
      "Epoch: [6][20/87]\tLoss 1.6162 (1.5947)\tAccuracy 34.375 (25.595)\n",
      "Epoch: [6][30/87]\tLoss 1.5567 (1.5912)\tAccuracy 21.875 (25.403)\n",
      "Epoch: [6][40/87]\tLoss 1.6113 (1.5933)\tAccuracy 18.750 (24.619)\n",
      "Epoch: [6][50/87]\tLoss 1.6157 (1.5967)\tAccuracy 31.250 (24.939)\n",
      "Epoch: [6][60/87]\tLoss 1.5587 (1.5989)\tAccuracy 34.375 (25.051)\n",
      "Epoch: [6][70/87]\tLoss 1.6145 (1.6014)\tAccuracy 15.625 (24.340)\n",
      "Epoch: [6][80/87]\tLoss 1.6303 (1.6011)\tAccuracy 12.500 (23.727)\n",
      "Test: [ 0/25]\tLoss 1.5973 (1.5973)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.6102 (1.5978)\tAccuracy 18.750 (25.000)\n",
      "Test: [20/25]\tLoss 1.5829 (1.6117)\tAccuracy 34.375 (24.851)\n",
      "Current Accuracy: 24.500\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 62.8s\n",
      "********************7********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [7][ 0/87]\tLoss 1.5360 (1.5360)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [7][10/87]\tLoss 1.6319 (1.6036)\tAccuracy 12.500 (22.727)\n",
      "Epoch: [7][20/87]\tLoss 1.5719 (1.6000)\tAccuracy  9.375 (20.685)\n",
      "Epoch: [7][30/87]\tLoss 1.6627 (1.6051)\tAccuracy 15.625 (20.161)\n",
      "Epoch: [7][40/87]\tLoss 1.6377 (1.6063)\tAccuracy 31.250 (21.265)\n",
      "Epoch: [7][50/87]\tLoss 1.6068 (1.6049)\tAccuracy 21.875 (21.998)\n",
      "Epoch: [7][60/87]\tLoss 1.5771 (1.6023)\tAccuracy 21.875 (22.387)\n",
      "Epoch: [7][70/87]\tLoss 1.6050 (1.6015)\tAccuracy 25.000 (22.711)\n",
      "Epoch: [7][80/87]\tLoss 1.6298 (1.6027)\tAccuracy 37.500 (23.071)\n",
      "Test: [ 0/25]\tLoss 1.6178 (1.6178)\tAccuracy 18.750 (18.750)\n",
      "Test: [10/25]\tLoss 1.6102 (1.6021)\tAccuracy 21.875 (25.852)\n",
      "Test: [20/25]\tLoss 1.6009 (1.6081)\tAccuracy 28.125 (23.363)\n",
      "Current Accuracy: 23.125\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 62.4s\n",
      "********************8********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [8][ 0/87]\tLoss 1.5747 (1.5747)\tAccuracy 28.125 (28.125)\n",
      "Epoch: [8][10/87]\tLoss 1.5143 (1.5771)\tAccuracy 43.750 (29.830)\n",
      "Epoch: [8][20/87]\tLoss 1.5873 (1.5825)\tAccuracy 28.125 (27.976)\n",
      "Epoch: [8][30/87]\tLoss 1.5545 (1.5909)\tAccuracy 31.250 (27.722)\n",
      "Epoch: [8][40/87]\tLoss 1.6032 (1.5988)\tAccuracy 21.875 (26.753)\n",
      "Epoch: [8][50/87]\tLoss 1.6449 (1.6005)\tAccuracy 21.875 (26.164)\n",
      "Epoch: [8][60/87]\tLoss 1.6383 (1.6023)\tAccuracy 12.500 (25.461)\n",
      "Epoch: [8][70/87]\tLoss 1.6454 (1.6028)\tAccuracy 18.750 (24.956)\n",
      "Epoch: [8][80/87]\tLoss 1.6329 (1.6004)\tAccuracy 28.125 (25.463)\n",
      "Test: [ 0/25]\tLoss 1.6343 (1.6343)\tAccuracy 18.750 (18.750)\n",
      "Test: [10/25]\tLoss 1.6379 (1.6542)\tAccuracy 21.875 (17.898)\n",
      "Test: [20/25]\tLoss 1.6604 (1.6619)\tAccuracy 15.625 (18.899)\n",
      "Current Accuracy: 19.375\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 62.5s\n",
      "********************9********************\n",
      "Current learning rate:  0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][ 0/87]\tLoss 1.6959 (1.6959)\tAccuracy 12.500 (12.500)\n",
      "Epoch: [9][10/87]\tLoss 1.6269 (1.6186)\tAccuracy 21.875 (20.455)\n",
      "Epoch: [9][20/87]\tLoss 1.6051 (1.6056)\tAccuracy 21.875 (22.321)\n",
      "Epoch: [9][30/87]\tLoss 1.6431 (1.6089)\tAccuracy 15.625 (21.472)\n",
      "Epoch: [9][40/87]\tLoss 1.6009 (1.6041)\tAccuracy 28.125 (22.256)\n",
      "Epoch: [9][50/87]\tLoss 1.5951 (1.6020)\tAccuracy 28.125 (23.407)\n",
      "Epoch: [9][60/87]\tLoss 1.6183 (1.6059)\tAccuracy 15.625 (22.439)\n",
      "Epoch: [9][70/87]\tLoss 1.6184 (1.6067)\tAccuracy 12.500 (22.315)\n",
      "Epoch: [9][80/87]\tLoss 1.6788 (1.6063)\tAccuracy  6.250 (22.299)\n",
      "Test: [ 0/25]\tLoss 1.5921 (1.5921)\tAccuracy 31.250 (31.250)\n",
      "Test: [10/25]\tLoss 1.6025 (1.6035)\tAccuracy 21.875 (21.875)\n",
      "Test: [20/25]\tLoss 1.6035 (1.6138)\tAccuracy 21.875 (19.643)\n",
      "Current Accuracy: 19.875\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 63.1s\n",
      "********************10********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [10][ 0/87]\tLoss 1.5768 (1.5768)\tAccuracy 12.500 (12.500)\n",
      "Epoch: [10][10/87]\tLoss 1.5749 (1.5976)\tAccuracy 18.750 (23.011)\n",
      "Epoch: [10][20/87]\tLoss 1.5693 (1.5963)\tAccuracy 31.250 (23.661)\n",
      "Epoch: [10][30/87]\tLoss 1.7237 (1.5982)\tAccuracy 18.750 (24.798)\n",
      "Epoch: [10][40/87]\tLoss 1.6415 (1.5969)\tAccuracy 18.750 (24.924)\n",
      "Epoch: [10][50/87]\tLoss 1.6593 (1.5959)\tAccuracy 12.500 (24.265)\n",
      "Epoch: [10][60/87]\tLoss 1.6099 (1.5980)\tAccuracy 25.000 (23.566)\n",
      "Epoch: [10][70/87]\tLoss 1.6189 (1.5979)\tAccuracy 25.000 (23.460)\n",
      "Epoch: [10][80/87]\tLoss 1.5297 (1.5976)\tAccuracy 40.625 (23.958)\n",
      "Test: [ 0/25]\tLoss 1.6045 (1.6045)\tAccuracy 25.000 (25.000)\n",
      "Test: [10/25]\tLoss 1.6296 (1.6030)\tAccuracy 18.750 (25.284)\n",
      "Test: [20/25]\tLoss 1.5860 (1.6084)\tAccuracy 34.375 (25.149)\n",
      "Current Accuracy: 25.000\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 62.7s\n",
      "********************11********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [11][ 0/87]\tLoss 1.6229 (1.6229)\tAccuracy 15.625 (15.625)\n",
      "Epoch: [11][10/87]\tLoss 1.6340 (1.5927)\tAccuracy 15.625 (21.875)\n",
      "Epoch: [11][20/87]\tLoss 1.6382 (1.6031)\tAccuracy 12.500 (20.387)\n",
      "Epoch: [11][30/87]\tLoss 1.6233 (1.6003)\tAccuracy 18.750 (21.069)\n",
      "Epoch: [11][40/87]\tLoss 1.6108 (1.6016)\tAccuracy 28.125 (21.951)\n",
      "Epoch: [11][50/87]\tLoss 1.6074 (1.6012)\tAccuracy 21.875 (22.610)\n",
      "Epoch: [11][60/87]\tLoss 1.5967 (1.5985)\tAccuracy 28.125 (23.002)\n",
      "Epoch: [11][70/87]\tLoss 1.5645 (1.5958)\tAccuracy 31.250 (23.371)\n",
      "Epoch: [11][80/87]\tLoss 1.6300 (1.5990)\tAccuracy 21.875 (23.418)\n",
      "Test: [ 0/25]\tLoss 1.5852 (1.5852)\tAccuracy 28.125 (28.125)\n",
      "Test: [10/25]\tLoss 1.5957 (1.6085)\tAccuracy 25.000 (21.875)\n",
      "Test: [20/25]\tLoss 1.6199 (1.6198)\tAccuracy 18.750 (18.601)\n",
      "Current Accuracy: 19.125\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 62.6s\n",
      "********************12********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [12][ 0/87]\tLoss 1.5566 (1.5566)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [12][10/87]\tLoss 1.5790 (1.6057)\tAccuracy 21.875 (24.716)\n",
      "Epoch: [12][20/87]\tLoss 1.6716 (1.6064)\tAccuracy 18.750 (25.149)\n",
      "Epoch: [12][30/87]\tLoss 1.6329 (1.6002)\tAccuracy 18.750 (25.302)\n",
      "Epoch: [12][40/87]\tLoss 1.6523 (1.6050)\tAccuracy 12.500 (23.552)\n",
      "Epoch: [12][50/87]\tLoss 1.6071 (1.6035)\tAccuracy 28.125 (23.591)\n",
      "Epoch: [12][60/87]\tLoss 1.6037 (1.6033)\tAccuracy 28.125 (23.668)\n",
      "Epoch: [12][70/87]\tLoss 1.5751 (1.6052)\tAccuracy 34.375 (23.504)\n",
      "Epoch: [12][80/87]\tLoss 1.6257 (1.6061)\tAccuracy 25.000 (23.727)\n",
      "Test: [ 0/25]\tLoss 1.6031 (1.6031)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.6306 (1.5973)\tAccuracy 18.750 (25.284)\n",
      "Test: [20/25]\tLoss 1.5610 (1.6061)\tAccuracy 34.375 (25.298)\n",
      "Current Accuracy: 25.000\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.7s\n",
      "********************13********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [13][ 0/87]\tLoss 1.5932 (1.5932)\tAccuracy 25.000 (25.000)\n",
      "Epoch: [13][10/87]\tLoss 1.5956 (1.6013)\tAccuracy 25.000 (25.852)\n",
      "Epoch: [13][20/87]\tLoss 1.6174 (1.5949)\tAccuracy 15.625 (25.298)\n",
      "Epoch: [13][30/87]\tLoss 1.5764 (1.5952)\tAccuracy 25.000 (25.101)\n",
      "Epoch: [13][40/87]\tLoss 1.5894 (1.5951)\tAccuracy 18.750 (24.848)\n",
      "Epoch: [13][50/87]\tLoss 1.6417 (1.5988)\tAccuracy 18.750 (24.081)\n",
      "Epoch: [13][60/87]\tLoss 1.6695 (1.5996)\tAccuracy 25.000 (23.975)\n",
      "Epoch: [13][70/87]\tLoss 1.5422 (1.5997)\tAccuracy 34.375 (24.032)\n",
      "Epoch: [13][80/87]\tLoss 1.5783 (1.5997)\tAccuracy 15.625 (23.958)\n",
      "Test: [ 0/25]\tLoss 1.5985 (1.5985)\tAccuracy 28.125 (28.125)\n",
      "Test: [10/25]\tLoss 1.6195 (1.6034)\tAccuracy 12.500 (21.591)\n",
      "Test: [20/25]\tLoss 1.5685 (1.6190)\tAccuracy 34.375 (22.173)\n",
      "Current Accuracy: 22.750\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.5s\n",
      "********************14********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [14][ 0/87]\tLoss 1.5600 (1.5600)\tAccuracy 28.125 (28.125)\n",
      "Epoch: [14][10/87]\tLoss 1.6430 (1.5967)\tAccuracy 18.750 (27.557)\n",
      "Epoch: [14][20/87]\tLoss 1.5858 (1.6006)\tAccuracy 25.000 (26.488)\n",
      "Epoch: [14][30/87]\tLoss 1.6269 (1.6009)\tAccuracy 12.500 (26.815)\n",
      "Epoch: [14][40/87]\tLoss 1.6164 (1.6036)\tAccuracy 25.000 (25.610)\n",
      "Epoch: [14][50/87]\tLoss 1.5500 (1.6010)\tAccuracy 28.125 (25.061)\n",
      "Epoch: [14][60/87]\tLoss 1.7057 (1.6016)\tAccuracy 18.750 (24.949)\n",
      "Epoch: [14][70/87]\tLoss 1.5570 (1.5991)\tAccuracy 21.875 (24.604)\n",
      "Epoch: [14][80/87]\tLoss 1.6102 (1.5995)\tAccuracy 25.000 (24.460)\n",
      "Test: [ 0/25]\tLoss 1.5931 (1.5931)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.6324 (1.5967)\tAccuracy 18.750 (25.000)\n",
      "Test: [20/25]\tLoss 1.5790 (1.6138)\tAccuracy 34.375 (25.000)\n",
      "Current Accuracy: 24.750\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.6s\n",
      "********************15********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [15][ 0/87]\tLoss 1.6123 (1.6123)\tAccuracy 28.125 (28.125)\n",
      "Epoch: [15][10/87]\tLoss 1.5729 (1.5705)\tAccuracy 21.875 (21.307)\n",
      "Epoch: [15][20/87]\tLoss 1.5888 (1.5838)\tAccuracy 34.375 (21.726)\n",
      "Epoch: [15][30/87]\tLoss 1.5956 (1.5887)\tAccuracy 15.625 (21.270)\n",
      "Epoch: [15][40/87]\tLoss 1.6114 (1.5950)\tAccuracy 25.000 (20.884)\n",
      "Epoch: [15][50/87]\tLoss 1.5871 (1.5957)\tAccuracy 31.250 (21.691)\n",
      "Epoch: [15][60/87]\tLoss 1.5721 (1.5958)\tAccuracy 34.375 (22.490)\n",
      "Epoch: [15][70/87]\tLoss 1.5548 (1.5958)\tAccuracy 28.125 (22.667)\n",
      "Epoch: [15][80/87]\tLoss 1.6569 (1.5989)\tAccuracy 18.750 (22.492)\n",
      "Test: [ 0/25]\tLoss 1.6223 (1.6223)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.6508 (1.6137)\tAccuracy 18.750 (25.284)\n",
      "Test: [20/25]\tLoss 1.6020 (1.6140)\tAccuracy 34.375 (25.298)\n",
      "Current Accuracy: 25.000\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.8s\n",
      "********************16********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [16][ 0/87]\tLoss 1.6218 (1.6218)\tAccuracy 25.000 (25.000)\n",
      "Epoch: [16][10/87]\tLoss 1.6108 (1.6094)\tAccuracy 12.500 (24.716)\n",
      "Epoch: [16][20/87]\tLoss 1.5815 (1.6065)\tAccuracy 21.875 (22.321)\n",
      "Epoch: [16][30/87]\tLoss 1.5680 (1.5998)\tAccuracy 28.125 (23.690)\n",
      "Epoch: [16][40/87]\tLoss 1.6407 (1.6021)\tAccuracy 18.750 (23.933)\n",
      "Epoch: [16][50/87]\tLoss 1.5748 (1.5978)\tAccuracy 18.750 (23.713)\n",
      "Epoch: [16][60/87]\tLoss 1.5642 (1.6025)\tAccuracy 21.875 (23.463)\n",
      "Epoch: [16][70/87]\tLoss 1.5960 (1.6035)\tAccuracy 28.125 (23.283)\n",
      "Epoch: [16][80/87]\tLoss 1.5950 (1.6042)\tAccuracy 28.125 (23.032)\n",
      "Test: [ 0/25]\tLoss 1.6006 (1.6006)\tAccuracy 18.750 (18.750)\n",
      "Test: [10/25]\tLoss 1.6263 (1.6058)\tAccuracy 15.625 (21.875)\n",
      "Test: [20/25]\tLoss 1.5957 (1.6200)\tAccuracy 34.375 (21.875)\n",
      "Current Accuracy: 21.750\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 62.0s\n",
      "********************17********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [17][ 0/87]\tLoss 1.5615 (1.5615)\tAccuracy 34.375 (34.375)\n",
      "Epoch: [17][10/87]\tLoss 1.6044 (1.5862)\tAccuracy 25.000 (26.420)\n",
      "Epoch: [17][20/87]\tLoss 1.5530 (1.5916)\tAccuracy 34.375 (25.149)\n",
      "Epoch: [17][30/87]\tLoss 1.6196 (1.5932)\tAccuracy 25.000 (25.302)\n",
      "Epoch: [17][40/87]\tLoss 1.5819 (1.5928)\tAccuracy 12.500 (24.238)\n",
      "Epoch: [17][50/87]\tLoss 1.5728 (1.5976)\tAccuracy 34.375 (23.958)\n",
      "Epoch: [17][60/87]\tLoss 1.6272 (1.5947)\tAccuracy 15.625 (24.898)\n",
      "Epoch: [17][70/87]\tLoss 1.6053 (1.5977)\tAccuracy 28.125 (24.560)\n",
      "Epoch: [17][80/87]\tLoss 1.5742 (1.5974)\tAccuracy 18.750 (24.306)\n",
      "Test: [ 0/25]\tLoss 1.5738 (1.5738)\tAccuracy 28.125 (28.125)\n",
      "Test: [10/25]\tLoss 1.6143 (1.6040)\tAccuracy 21.875 (21.023)\n",
      "Test: [20/25]\tLoss 1.6355 (1.6303)\tAccuracy 12.500 (18.304)\n",
      "Current Accuracy: 18.750\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.9s\n",
      "********************18********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [18][ 0/87]\tLoss 1.5910 (1.5910)\tAccuracy 21.875 (21.875)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [18][10/87]\tLoss 1.6429 (1.5978)\tAccuracy 21.875 (23.011)\n",
      "Epoch: [18][20/87]\tLoss 1.6211 (1.6013)\tAccuracy 18.750 (23.363)\n",
      "Epoch: [18][30/87]\tLoss 1.5521 (1.5927)\tAccuracy 40.625 (25.504)\n",
      "Epoch: [18][40/87]\tLoss 1.5665 (1.5953)\tAccuracy 25.000 (25.229)\n",
      "Epoch: [18][50/87]\tLoss 1.5475 (1.5933)\tAccuracy 18.750 (25.429)\n",
      "Epoch: [18][60/87]\tLoss 1.6163 (1.5960)\tAccuracy 21.875 (24.795)\n",
      "Epoch: [18][70/87]\tLoss 1.6006 (1.5971)\tAccuracy 15.625 (24.032)\n",
      "Epoch: [18][80/87]\tLoss 1.6061 (1.5958)\tAccuracy 21.875 (24.306)\n",
      "Test: [ 0/25]\tLoss 1.5821 (1.5821)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.6164 (1.5916)\tAccuracy 18.750 (25.284)\n",
      "Test: [20/25]\tLoss 1.6137 (1.6068)\tAccuracy 34.375 (25.298)\n",
      "Current Accuracy: 25.000\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.9s\n",
      "********************19********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [19][ 0/87]\tLoss 1.5327 (1.5327)\tAccuracy 34.375 (34.375)\n",
      "Epoch: [19][10/87]\tLoss 1.5851 (1.5685)\tAccuracy 37.500 (28.409)\n",
      "Epoch: [19][20/87]\tLoss 1.5491 (1.5768)\tAccuracy 28.125 (26.488)\n",
      "Epoch: [19][30/87]\tLoss 1.6202 (1.5828)\tAccuracy 18.750 (25.806)\n",
      "Epoch: [19][40/87]\tLoss 1.6942 (1.5882)\tAccuracy 18.750 (25.534)\n",
      "Epoch: [19][50/87]\tLoss 1.6254 (1.5955)\tAccuracy 25.000 (24.755)\n",
      "Epoch: [19][60/87]\tLoss 1.6271 (1.5945)\tAccuracy 34.375 (24.436)\n",
      "Epoch: [19][70/87]\tLoss 1.6041 (1.5935)\tAccuracy 28.125 (24.780)\n",
      "Epoch: [19][80/87]\tLoss 1.6557 (1.5951)\tAccuracy  6.250 (24.421)\n",
      "Test: [ 0/25]\tLoss 1.5999 (1.5999)\tAccuracy 15.625 (15.625)\n",
      "Test: [10/25]\tLoss 1.6175 (1.6007)\tAccuracy 15.625 (22.443)\n",
      "Test: [20/25]\tLoss 1.6189 (1.6103)\tAccuracy 18.750 (22.470)\n",
      "Current Accuracy: 22.375\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.7s\n",
      "********************20********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [20][ 0/87]\tLoss 1.5678 (1.5678)\tAccuracy 31.250 (31.250)\n",
      "Epoch: [20][10/87]\tLoss 1.5751 (1.6018)\tAccuracy 25.000 (20.739)\n",
      "Epoch: [20][20/87]\tLoss 1.5576 (1.5983)\tAccuracy 18.750 (21.577)\n",
      "Epoch: [20][30/87]\tLoss 1.6697 (1.6007)\tAccuracy 18.750 (22.077)\n",
      "Epoch: [20][40/87]\tLoss 1.5905 (1.5984)\tAccuracy 25.000 (22.637)\n",
      "Epoch: [20][50/87]\tLoss 1.6110 (1.5955)\tAccuracy 21.875 (23.346)\n",
      "Epoch: [20][60/87]\tLoss 1.5872 (1.5937)\tAccuracy 31.250 (24.232)\n",
      "Epoch: [20][70/87]\tLoss 1.6281 (1.5946)\tAccuracy 18.750 (23.900)\n",
      "Epoch: [20][80/87]\tLoss 1.6755 (1.5973)\tAccuracy  9.375 (23.534)\n",
      "Test: [ 0/25]\tLoss 1.6106 (1.6106)\tAccuracy 12.500 (12.500)\n",
      "Test: [10/25]\tLoss 1.6124 (1.6116)\tAccuracy 15.625 (24.432)\n",
      "Test: [20/25]\tLoss 1.6256 (1.6332)\tAccuracy 37.500 (24.107)\n",
      "Current Accuracy: 24.125\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.8s\n",
      "********************21********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [21][ 0/87]\tLoss 1.6224 (1.6224)\tAccuracy 25.000 (25.000)\n",
      "Epoch: [21][10/87]\tLoss 1.5656 (1.5976)\tAccuracy 31.250 (23.864)\n",
      "Epoch: [21][20/87]\tLoss 1.5189 (1.5878)\tAccuracy 31.250 (25.298)\n",
      "Epoch: [21][30/87]\tLoss 1.5496 (1.5875)\tAccuracy 34.375 (25.000)\n",
      "Epoch: [21][40/87]\tLoss 1.5951 (1.5971)\tAccuracy 21.875 (23.552)\n",
      "Epoch: [21][50/87]\tLoss 1.5591 (1.5951)\tAccuracy 15.625 (23.223)\n",
      "Epoch: [21][60/87]\tLoss 1.5928 (1.5946)\tAccuracy 28.125 (23.207)\n",
      "Epoch: [21][70/87]\tLoss 1.5618 (1.5968)\tAccuracy 37.500 (23.371)\n",
      "Epoch: [21][80/87]\tLoss 1.5654 (1.5985)\tAccuracy 31.250 (23.418)\n",
      "Test: [ 0/25]\tLoss 1.6084 (1.6084)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.6385 (1.6047)\tAccuracy 18.750 (24.148)\n",
      "Test: [20/25]\tLoss 1.6060 (1.6115)\tAccuracy 21.875 (22.917)\n",
      "Current Accuracy: 22.000\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.6s\n",
      "********************22********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [22][ 0/87]\tLoss 1.6217 (1.6217)\tAccuracy 18.750 (18.750)\n",
      "Epoch: [22][10/87]\tLoss 1.6190 (1.6023)\tAccuracy 21.875 (21.875)\n",
      "Epoch: [22][20/87]\tLoss 1.5620 (1.5945)\tAccuracy 28.125 (23.065)\n",
      "Epoch: [22][30/87]\tLoss 1.5271 (1.5952)\tAccuracy 40.625 (23.488)\n",
      "Epoch: [22][40/87]\tLoss 1.5210 (1.5955)\tAccuracy 31.250 (23.323)\n",
      "Epoch: [22][50/87]\tLoss 1.6387 (1.5987)\tAccuracy 25.000 (23.346)\n",
      "Epoch: [22][60/87]\tLoss 1.6183 (1.5979)\tAccuracy 21.875 (23.412)\n",
      "Epoch: [22][70/87]\tLoss 1.5796 (1.5983)\tAccuracy 21.875 (23.327)\n",
      "Epoch: [22][80/87]\tLoss 1.5560 (1.5956)\tAccuracy 34.375 (23.650)\n",
      "Test: [ 0/25]\tLoss 1.6078 (1.6078)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.6376 (1.6369)\tAccuracy 18.750 (25.284)\n",
      "Test: [20/25]\tLoss 1.5901 (1.6480)\tAccuracy 34.375 (25.298)\n",
      "Current Accuracy: 24.875\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.7s\n",
      "********************23********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [23][ 0/87]\tLoss 1.6813 (1.6813)\tAccuracy 15.625 (15.625)\n",
      "Epoch: [23][10/87]\tLoss 1.6240 (1.6137)\tAccuracy 18.750 (23.295)\n",
      "Epoch: [23][20/87]\tLoss 1.6180 (1.6057)\tAccuracy 28.125 (24.405)\n",
      "Epoch: [23][30/87]\tLoss 1.5839 (1.6022)\tAccuracy 21.875 (25.000)\n",
      "Epoch: [23][40/87]\tLoss 1.5216 (1.6012)\tAccuracy 37.500 (24.771)\n",
      "Epoch: [23][50/87]\tLoss 1.6218 (1.6027)\tAccuracy 25.000 (24.571)\n",
      "Epoch: [23][60/87]\tLoss 1.6160 (1.6008)\tAccuracy 28.125 (23.924)\n",
      "Epoch: [23][70/87]\tLoss 1.6113 (1.5973)\tAccuracy 28.125 (24.032)\n",
      "Epoch: [23][80/87]\tLoss 1.5635 (1.5955)\tAccuracy 31.250 (23.804)\n",
      "Test: [ 0/25]\tLoss 1.6071 (1.6071)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.6335 (1.5919)\tAccuracy 18.750 (26.420)\n",
      "Test: [20/25]\tLoss 1.6224 (1.6138)\tAccuracy 34.375 (25.893)\n",
      "Current Accuracy: 25.250\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.7s\n",
      "********************24********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [24][ 0/87]\tLoss 1.6151 (1.6151)\tAccuracy 15.625 (15.625)\n",
      "Epoch: [24][10/87]\tLoss 1.6078 (1.5922)\tAccuracy 28.125 (26.136)\n",
      "Epoch: [24][20/87]\tLoss 1.5762 (1.5841)\tAccuracy 40.625 (27.679)\n",
      "Epoch: [24][30/87]\tLoss 1.6131 (1.5862)\tAccuracy 15.625 (25.101)\n",
      "Epoch: [24][40/87]\tLoss 1.6138 (1.5871)\tAccuracy  9.375 (25.381)\n",
      "Epoch: [24][50/87]\tLoss 1.6040 (1.5872)\tAccuracy 18.750 (25.429)\n",
      "Epoch: [24][60/87]\tLoss 1.6196 (1.5878)\tAccuracy 25.000 (25.000)\n",
      "Epoch: [24][70/87]\tLoss 1.5707 (1.5879)\tAccuracy 28.125 (25.484)\n",
      "Epoch: [24][80/87]\tLoss 1.5360 (1.5859)\tAccuracy 37.500 (25.656)\n",
      "Test: [ 0/25]\tLoss 1.6145 (1.6145)\tAccuracy 15.625 (15.625)\n",
      "Test: [10/25]\tLoss 1.6390 (1.6010)\tAccuracy 15.625 (25.000)\n",
      "Test: [20/25]\tLoss 1.5407 (1.6165)\tAccuracy 37.500 (25.446)\n",
      "Current Accuracy: 25.250\n",
      "The best accuracy: 25.375\n",
      "An epoch time: 61.5s\n",
      "********************25********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [25][ 0/87]\tLoss 1.5033 (1.5033)\tAccuracy 31.250 (31.250)\n",
      "Epoch: [25][10/87]\tLoss 1.6221 (1.5840)\tAccuracy 31.250 (22.727)\n",
      "Epoch: [25][20/87]\tLoss 1.6045 (1.6002)\tAccuracy 21.875 (22.470)\n",
      "Epoch: [25][30/87]\tLoss 1.5149 (1.5965)\tAccuracy 28.125 (22.077)\n",
      "Epoch: [25][40/87]\tLoss 1.5817 (1.5980)\tAccuracy 40.625 (21.951)\n",
      "Epoch: [25][50/87]\tLoss 1.6109 (1.5910)\tAccuracy 18.750 (23.407)\n",
      "Epoch: [25][60/87]\tLoss 1.6001 (1.5917)\tAccuracy 18.750 (23.053)\n",
      "Epoch: [25][70/87]\tLoss 1.5349 (1.5947)\tAccuracy 28.125 (22.579)\n",
      "Epoch: [25][80/87]\tLoss 1.6476 (1.5932)\tAccuracy 25.000 (22.878)\n",
      "Test: [ 0/25]\tLoss 1.5585 (1.5585)\tAccuracy 25.000 (25.000)\n",
      "Test: [10/25]\tLoss 1.6098 (1.5668)\tAccuracy 15.625 (29.545)\n",
      "Test: [20/25]\tLoss 1.5289 (1.5777)\tAccuracy 37.500 (28.423)\n",
      "Current Accuracy: 27.500\n",
      "The best accuracy: 27.500\n",
      "An epoch time: 61.7s\n",
      "********************26********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [26][ 0/87]\tLoss 1.5202 (1.5202)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [26][10/87]\tLoss 1.5092 (1.5541)\tAccuracy 34.375 (29.545)\n",
      "Epoch: [26][20/87]\tLoss 1.5806 (1.5795)\tAccuracy 18.750 (26.488)\n",
      "Epoch: [26][30/87]\tLoss 1.5952 (1.5785)\tAccuracy 31.250 (26.915)\n",
      "Epoch: [26][40/87]\tLoss 1.5591 (1.5782)\tAccuracy 25.000 (27.210)\n",
      "Epoch: [26][50/87]\tLoss 1.6261 (1.5759)\tAccuracy 28.125 (27.574)\n",
      "Epoch: [26][60/87]\tLoss 1.5619 (1.5778)\tAccuracy 28.125 (27.459)\n",
      "Epoch: [26][70/87]\tLoss 1.5481 (1.5757)\tAccuracy 28.125 (27.113)\n",
      "Epoch: [26][80/87]\tLoss 1.6171 (1.5770)\tAccuracy 18.750 (26.620)\n",
      "Test: [ 0/25]\tLoss 1.5623 (1.5623)\tAccuracy 15.625 (15.625)\n",
      "Test: [10/25]\tLoss 1.6393 (1.5825)\tAccuracy 21.875 (21.591)\n",
      "Test: [20/25]\tLoss 1.5277 (1.5967)\tAccuracy 31.250 (21.875)\n",
      "Current Accuracy: 21.750\n",
      "The best accuracy: 27.500\n",
      "An epoch time: 61.7s\n",
      "********************27********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [27][ 0/87]\tLoss 1.5173 (1.5173)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [27][10/87]\tLoss 1.4973 (1.5428)\tAccuracy 34.375 (29.261)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [27][20/87]\tLoss 1.6013 (1.5604)\tAccuracy 21.875 (24.702)\n",
      "Epoch: [27][30/87]\tLoss 1.6578 (1.5700)\tAccuracy 12.500 (24.798)\n",
      "Epoch: [27][40/87]\tLoss 1.6384 (1.5773)\tAccuracy 15.625 (23.857)\n",
      "Epoch: [27][50/87]\tLoss 1.5121 (1.5776)\tAccuracy 34.375 (24.265)\n",
      "Epoch: [27][60/87]\tLoss 1.6018 (1.5746)\tAccuracy 15.625 (24.846)\n",
      "Epoch: [27][70/87]\tLoss 1.6055 (1.5724)\tAccuracy 25.000 (25.132)\n",
      "Epoch: [27][80/87]\tLoss 1.4655 (1.5709)\tAccuracy 37.500 (25.694)\n",
      "Test: [ 0/25]\tLoss 1.5970 (1.5970)\tAccuracy 25.000 (25.000)\n",
      "Test: [10/25]\tLoss 1.6453 (1.5761)\tAccuracy 21.875 (24.432)\n",
      "Test: [20/25]\tLoss 1.5435 (1.5802)\tAccuracy 37.500 (25.893)\n",
      "Current Accuracy: 25.875\n",
      "The best accuracy: 27.500\n",
      "An epoch time: 61.6s\n",
      "********************28********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [28][ 0/87]\tLoss 1.5843 (1.5843)\tAccuracy 21.875 (21.875)\n",
      "Epoch: [28][10/87]\tLoss 1.5387 (1.5705)\tAccuracy 37.500 (27.841)\n",
      "Epoch: [28][20/87]\tLoss 1.3822 (1.5570)\tAccuracy 53.125 (29.018)\n",
      "Epoch: [28][30/87]\tLoss 1.5857 (1.5547)\tAccuracy 34.375 (27.823)\n",
      "Epoch: [28][40/87]\tLoss 1.4581 (1.5360)\tAccuracy 34.375 (28.506)\n",
      "Epoch: [28][50/87]\tLoss 1.6066 (1.5312)\tAccuracy 25.000 (29.412)\n",
      "Epoch: [28][60/87]\tLoss 1.4317 (1.5212)\tAccuracy 31.250 (30.328)\n",
      "Epoch: [28][70/87]\tLoss 1.4634 (1.5063)\tAccuracy 37.500 (30.854)\n",
      "Epoch: [28][80/87]\tLoss 1.3503 (1.4974)\tAccuracy 37.500 (31.096)\n",
      "Test: [ 0/25]\tLoss 1.4895 (1.4895)\tAccuracy 28.125 (28.125)\n",
      "Test: [10/25]\tLoss 1.4706 (1.4230)\tAccuracy 34.375 (36.932)\n",
      "Test: [20/25]\tLoss 1.3557 (1.4319)\tAccuracy 40.625 (35.417)\n",
      "Current Accuracy: 34.750\n",
      "The best accuracy: 34.750\n",
      "An epoch time: 62.5s\n",
      "********************29********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [29][ 0/87]\tLoss 1.4816 (1.4816)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [29][10/87]\tLoss 1.4626 (1.4043)\tAccuracy 28.125 (34.943)\n",
      "Epoch: [29][20/87]\tLoss 1.2033 (1.3873)\tAccuracy 43.750 (33.780)\n",
      "Epoch: [29][30/87]\tLoss 1.3352 (1.3637)\tAccuracy 31.250 (36.391)\n",
      "Epoch: [29][40/87]\tLoss 1.3370 (1.3550)\tAccuracy 37.500 (36.357)\n",
      "Epoch: [29][50/87]\tLoss 1.4091 (1.3690)\tAccuracy 43.750 (35.662)\n",
      "Epoch: [29][60/87]\tLoss 1.2338 (1.3611)\tAccuracy 37.500 (36.270)\n",
      "Epoch: [29][70/87]\tLoss 1.4963 (1.3625)\tAccuracy 37.500 (35.783)\n",
      "Epoch: [29][80/87]\tLoss 1.0426 (1.3551)\tAccuracy 46.875 (35.918)\n",
      "Test: [ 0/25]\tLoss 1.5443 (1.5443)\tAccuracy 25.000 (25.000)\n",
      "Test: [10/25]\tLoss 1.5093 (1.3858)\tAccuracy 25.000 (30.966)\n",
      "Test: [20/25]\tLoss 1.4527 (1.4167)\tAccuracy 28.125 (31.696)\n",
      "Current Accuracy: 32.250\n",
      "The best accuracy: 34.750\n",
      "An epoch time: 61.8s\n",
      "********************30********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [30][ 0/87]\tLoss 1.2441 (1.2441)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [30][10/87]\tLoss 1.3300 (1.3299)\tAccuracy 37.500 (35.795)\n",
      "Epoch: [30][20/87]\tLoss 1.1368 (1.3355)\tAccuracy 43.750 (37.202)\n",
      "Epoch: [30][30/87]\tLoss 1.5099 (1.3175)\tAccuracy 25.000 (38.508)\n",
      "Epoch: [30][40/87]\tLoss 1.1826 (1.3435)\tAccuracy 37.500 (37.195)\n",
      "Epoch: [30][50/87]\tLoss 1.3577 (1.3501)\tAccuracy 43.750 (37.255)\n",
      "Epoch: [30][60/87]\tLoss 1.3757 (1.3502)\tAccuracy 31.250 (36.885)\n",
      "Epoch: [30][70/87]\tLoss 1.4495 (1.3500)\tAccuracy 18.750 (36.796)\n",
      "Epoch: [30][80/87]\tLoss 1.2452 (1.3534)\tAccuracy 43.750 (36.651)\n",
      "Test: [ 0/25]\tLoss 1.3650 (1.3650)\tAccuracy 25.000 (25.000)\n",
      "Test: [10/25]\tLoss 1.5286 (1.3943)\tAccuracy 25.000 (30.966)\n",
      "Test: [20/25]\tLoss 1.3477 (1.3873)\tAccuracy 37.500 (32.887)\n",
      "Current Accuracy: 32.500\n",
      "The best accuracy: 34.750\n",
      "An epoch time: 61.6s\n",
      "********************31********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [31][ 0/87]\tLoss 1.3699 (1.3699)\tAccuracy 40.625 (40.625)\n",
      "Epoch: [31][10/87]\tLoss 1.3291 (1.4107)\tAccuracy 34.375 (32.102)\n",
      "Epoch: [31][20/87]\tLoss 1.3152 (1.3878)\tAccuracy 37.500 (32.440)\n",
      "Epoch: [31][30/87]\tLoss 1.2457 (1.3605)\tAccuracy 40.625 (35.484)\n",
      "Epoch: [31][40/87]\tLoss 1.2935 (1.3489)\tAccuracy 37.500 (36.433)\n",
      "Epoch: [31][50/87]\tLoss 1.4704 (1.3379)\tAccuracy 43.750 (36.949)\n",
      "Epoch: [31][60/87]\tLoss 1.2894 (1.3449)\tAccuracy 34.375 (36.885)\n",
      "Epoch: [31][70/87]\tLoss 1.4086 (1.3419)\tAccuracy 28.125 (36.752)\n",
      "Epoch: [31][80/87]\tLoss 1.2543 (1.3285)\tAccuracy 50.000 (37.731)\n",
      "Test: [ 0/25]\tLoss 1.4870 (1.4870)\tAccuracy 31.250 (31.250)\n",
      "Test: [10/25]\tLoss 1.3624 (1.4544)\tAccuracy 28.125 (34.943)\n",
      "Test: [20/25]\tLoss 1.4251 (1.5234)\tAccuracy 46.875 (34.970)\n",
      "Current Accuracy: 34.375\n",
      "The best accuracy: 34.750\n",
      "An epoch time: 61.7s\n",
      "********************32********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [32][ 0/87]\tLoss 1.1946 (1.1946)\tAccuracy 34.375 (34.375)\n",
      "Epoch: [32][10/87]\tLoss 1.3254 (1.3034)\tAccuracy 28.125 (37.216)\n",
      "Epoch: [32][20/87]\tLoss 1.3785 (1.2912)\tAccuracy 37.500 (38.988)\n",
      "Epoch: [32][30/87]\tLoss 1.2009 (1.3036)\tAccuracy 43.750 (38.911)\n",
      "Epoch: [32][40/87]\tLoss 1.0872 (1.3067)\tAccuracy 56.250 (39.558)\n",
      "Epoch: [32][50/87]\tLoss 1.4607 (1.3116)\tAccuracy 31.250 (39.400)\n",
      "Epoch: [32][60/87]\tLoss 1.2822 (1.3218)\tAccuracy 37.500 (38.320)\n",
      "Epoch: [32][70/87]\tLoss 1.2496 (1.3177)\tAccuracy 37.500 (38.424)\n",
      "Epoch: [32][80/87]\tLoss 1.3903 (1.3171)\tAccuracy 46.875 (38.773)\n",
      "Test: [ 0/25]\tLoss 1.3134 (1.3134)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.4471 (1.2867)\tAccuracy 31.250 (34.659)\n",
      "Test: [20/25]\tLoss 1.3301 (1.3045)\tAccuracy 34.375 (34.970)\n",
      "Current Accuracy: 35.625\n",
      "The best accuracy: 35.625\n",
      "An epoch time: 61.5s\n",
      "********************33********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [33][ 0/87]\tLoss 1.3577 (1.3577)\tAccuracy 31.250 (31.250)\n",
      "Epoch: [33][10/87]\tLoss 1.3839 (1.3526)\tAccuracy 34.375 (37.784)\n",
      "Epoch: [33][20/87]\tLoss 1.2592 (1.3169)\tAccuracy 37.500 (37.946)\n",
      "Epoch: [33][30/87]\tLoss 1.3156 (1.2962)\tAccuracy 40.625 (38.407)\n",
      "Epoch: [33][40/87]\tLoss 1.3726 (1.2902)\tAccuracy 37.500 (38.338)\n",
      "Epoch: [33][50/87]\tLoss 1.6586 (1.2965)\tAccuracy 18.750 (37.684)\n",
      "Epoch: [33][60/87]\tLoss 1.1216 (1.2971)\tAccuracy 34.375 (37.705)\n",
      "Epoch: [33][70/87]\tLoss 1.0012 (1.2922)\tAccuracy 56.250 (37.984)\n",
      "Epoch: [33][80/87]\tLoss 1.2413 (1.2941)\tAccuracy 31.250 (37.539)\n",
      "Test: [ 0/25]\tLoss 1.3098 (1.3098)\tAccuracy 34.375 (34.375)\n",
      "Test: [10/25]\tLoss 1.3687 (1.2625)\tAccuracy 34.375 (38.636)\n",
      "Test: [20/25]\tLoss 1.3039 (1.2652)\tAccuracy 43.750 (39.137)\n",
      "Current Accuracy: 39.375\n",
      "The best accuracy: 39.375\n",
      "An epoch time: 62.9s\n",
      "********************34********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [34][ 0/87]\tLoss 1.4882 (1.4882)\tAccuracy 34.375 (34.375)\n",
      "Epoch: [34][10/87]\tLoss 1.2649 (1.3079)\tAccuracy 43.750 (37.784)\n",
      "Epoch: [34][20/87]\tLoss 1.3749 (1.3260)\tAccuracy 31.250 (37.202)\n",
      "Epoch: [34][30/87]\tLoss 1.2932 (1.3055)\tAccuracy 53.125 (37.903)\n",
      "Epoch: [34][40/87]\tLoss 1.3269 (1.3111)\tAccuracy 31.250 (36.738)\n",
      "Epoch: [34][50/87]\tLoss 1.2060 (1.2911)\tAccuracy 50.000 (37.806)\n",
      "Epoch: [34][60/87]\tLoss 1.2655 (1.2955)\tAccuracy 50.000 (37.346)\n",
      "Epoch: [34][70/87]\tLoss 1.2139 (1.2868)\tAccuracy 46.875 (38.116)\n",
      "Epoch: [34][80/87]\tLoss 1.2984 (1.2909)\tAccuracy 28.125 (38.233)\n",
      "Test: [ 0/25]\tLoss 1.2307 (1.2307)\tAccuracy 31.250 (31.250)\n",
      "Test: [10/25]\tLoss 1.4401 (1.2576)\tAccuracy 28.125 (40.625)\n",
      "Test: [20/25]\tLoss 1.2350 (1.2550)\tAccuracy 50.000 (40.774)\n",
      "Current Accuracy: 40.375\n",
      "The best accuracy: 40.375\n",
      "An epoch time: 61.7s\n",
      "********************35********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [35][ 0/87]\tLoss 1.1734 (1.1734)\tAccuracy 40.625 (40.625)\n",
      "Epoch: [35][10/87]\tLoss 1.2737 (1.2800)\tAccuracy 40.625 (40.057)\n",
      "Epoch: [35][20/87]\tLoss 1.3332 (1.3139)\tAccuracy 31.250 (36.012)\n",
      "Epoch: [35][30/87]\tLoss 1.1796 (1.2808)\tAccuracy 53.125 (39.516)\n",
      "Epoch: [35][40/87]\tLoss 1.1318 (1.2693)\tAccuracy 53.125 (40.244)\n",
      "Epoch: [35][50/87]\tLoss 1.2526 (1.2791)\tAccuracy 43.750 (39.032)\n",
      "Epoch: [35][60/87]\tLoss 1.2296 (1.2787)\tAccuracy 34.375 (37.961)\n",
      "Epoch: [35][70/87]\tLoss 1.1428 (1.2694)\tAccuracy 40.625 (37.632)\n",
      "Epoch: [35][80/87]\tLoss 1.2390 (1.2618)\tAccuracy 37.500 (38.387)\n",
      "Test: [ 0/25]\tLoss 1.2077 (1.2077)\tAccuracy 53.125 (53.125)\n",
      "Test: [10/25]\tLoss 1.3425 (1.2209)\tAccuracy 34.375 (43.466)\n",
      "Test: [20/25]\tLoss 1.1811 (1.2388)\tAccuracy 34.375 (39.732)\n",
      "Current Accuracy: 39.125\n",
      "The best accuracy: 40.375\n",
      "An epoch time: 61.5s\n",
      "********************36********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [36][ 0/87]\tLoss 1.3857 (1.3857)\tAccuracy 34.375 (34.375)\n",
      "Epoch: [36][10/87]\tLoss 1.2321 (1.2914)\tAccuracy 34.375 (38.068)\n",
      "Epoch: [36][20/87]\tLoss 1.0760 (1.2577)\tAccuracy 43.750 (40.030)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [36][30/87]\tLoss 1.2777 (1.2617)\tAccuracy 37.500 (39.617)\n",
      "Epoch: [36][40/87]\tLoss 1.1858 (1.2484)\tAccuracy 43.750 (39.787)\n",
      "Epoch: [36][50/87]\tLoss 1.1708 (1.2550)\tAccuracy 50.000 (39.032)\n",
      "Epoch: [36][60/87]\tLoss 1.1010 (1.2604)\tAccuracy 56.250 (38.986)\n",
      "Epoch: [36][70/87]\tLoss 1.3829 (1.2667)\tAccuracy 37.500 (38.644)\n",
      "Epoch: [36][80/87]\tLoss 1.3741 (1.2729)\tAccuracy 37.500 (38.735)\n",
      "Test: [ 0/25]\tLoss 1.3546 (1.3546)\tAccuracy 34.375 (34.375)\n",
      "Test: [10/25]\tLoss 1.3156 (1.2482)\tAccuracy 25.000 (40.057)\n",
      "Test: [20/25]\tLoss 1.2787 (1.2665)\tAccuracy 37.500 (39.137)\n",
      "Current Accuracy: 38.375\n",
      "The best accuracy: 40.375\n",
      "An epoch time: 61.9s\n",
      "********************37********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [37][ 0/87]\tLoss 1.2055 (1.2055)\tAccuracy 40.625 (40.625)\n",
      "Epoch: [37][10/87]\tLoss 1.1769 (1.2451)\tAccuracy 50.000 (37.500)\n",
      "Epoch: [37][20/87]\tLoss 1.1809 (1.2340)\tAccuracy 34.375 (38.393)\n",
      "Epoch: [37][30/87]\tLoss 1.1037 (1.2170)\tAccuracy 46.875 (40.020)\n",
      "Epoch: [37][40/87]\tLoss 1.1811 (1.2431)\tAccuracy 40.625 (39.787)\n",
      "Epoch: [37][50/87]\tLoss 1.3907 (1.2532)\tAccuracy 40.625 (39.522)\n",
      "Epoch: [37][60/87]\tLoss 1.2027 (1.2590)\tAccuracy 43.750 (39.754)\n",
      "Epoch: [37][70/87]\tLoss 1.2949 (1.2548)\tAccuracy 40.625 (39.921)\n",
      "Epoch: [37][80/87]\tLoss 1.2393 (1.2602)\tAccuracy 50.000 (39.622)\n",
      "Test: [ 0/25]\tLoss 1.2404 (1.2404)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.3960 (1.2483)\tAccuracy 28.125 (41.761)\n",
      "Test: [20/25]\tLoss 1.3023 (1.2639)\tAccuracy 31.250 (38.690)\n",
      "Current Accuracy: 38.500\n",
      "The best accuracy: 40.375\n",
      "An epoch time: 62.4s\n",
      "********************38********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [38][ 0/87]\tLoss 1.2156 (1.2156)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [38][10/87]\tLoss 1.2520 (1.2203)\tAccuracy 31.250 (39.205)\n",
      "Epoch: [38][20/87]\tLoss 1.1240 (1.2166)\tAccuracy 53.125 (41.518)\n",
      "Epoch: [38][30/87]\tLoss 1.5475 (1.2358)\tAccuracy 31.250 (40.323)\n",
      "Epoch: [38][40/87]\tLoss 1.1713 (1.2388)\tAccuracy 40.625 (40.244)\n",
      "Epoch: [38][50/87]\tLoss 1.0583 (1.2262)\tAccuracy 46.875 (40.441)\n",
      "Epoch: [38][60/87]\tLoss 1.3575 (1.2427)\tAccuracy 34.375 (39.293)\n",
      "Epoch: [38][70/87]\tLoss 1.3294 (1.2520)\tAccuracy 53.125 (39.393)\n",
      "Epoch: [38][80/87]\tLoss 1.1667 (1.2575)\tAccuracy 43.750 (39.082)\n",
      "Test: [ 0/25]\tLoss 1.2321 (1.2321)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.4329 (1.2469)\tAccuracy 31.250 (40.625)\n",
      "Test: [20/25]\tLoss 1.2413 (1.2595)\tAccuracy 31.250 (39.732)\n",
      "Current Accuracy: 39.750\n",
      "The best accuracy: 40.375\n",
      "An epoch time: 61.8s\n",
      "********************39********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [39][ 0/87]\tLoss 1.3126 (1.3126)\tAccuracy 34.375 (34.375)\n",
      "Epoch: [39][10/87]\tLoss 1.1485 (1.3429)\tAccuracy 50.000 (36.932)\n",
      "Epoch: [39][20/87]\tLoss 1.2115 (1.2933)\tAccuracy 46.875 (38.839)\n",
      "Epoch: [39][30/87]\tLoss 1.1954 (1.2719)\tAccuracy 34.375 (39.415)\n",
      "Epoch: [39][40/87]\tLoss 1.2981 (1.2751)\tAccuracy 40.625 (39.710)\n",
      "Epoch: [39][50/87]\tLoss 1.1970 (1.2692)\tAccuracy 37.500 (39.522)\n",
      "Epoch: [39][60/87]\tLoss 1.3293 (1.2624)\tAccuracy 28.125 (39.498)\n",
      "Epoch: [39][70/87]\tLoss 1.2069 (1.2622)\tAccuracy 46.875 (39.569)\n",
      "Epoch: [39][80/87]\tLoss 1.3781 (1.2652)\tAccuracy 31.250 (39.005)\n",
      "Test: [ 0/25]\tLoss 1.1752 (1.1752)\tAccuracy 37.500 (37.500)\n",
      "Test: [10/25]\tLoss 1.2794 (1.1988)\tAccuracy 37.500 (40.625)\n",
      "Test: [20/25]\tLoss 1.2084 (1.2147)\tAccuracy 43.750 (39.732)\n",
      "Current Accuracy: 39.500\n",
      "The best accuracy: 40.375\n",
      "An epoch time: 61.7s\n",
      "********************40********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [40][ 0/87]\tLoss 1.1806 (1.1806)\tAccuracy 40.625 (40.625)\n",
      "Epoch: [40][10/87]\tLoss 1.1768 (1.1979)\tAccuracy 50.000 (43.750)\n",
      "Epoch: [40][20/87]\tLoss 1.2734 (1.2116)\tAccuracy 37.500 (42.708)\n",
      "Epoch: [40][30/87]\tLoss 1.1752 (1.2186)\tAccuracy 46.875 (41.230)\n",
      "Epoch: [40][40/87]\tLoss 1.1715 (1.2245)\tAccuracy 46.875 (41.463)\n",
      "Epoch: [40][50/87]\tLoss 1.2805 (1.2159)\tAccuracy 31.250 (41.605)\n",
      "Epoch: [40][60/87]\tLoss 1.1328 (1.2216)\tAccuracy 62.500 (40.830)\n",
      "Epoch: [40][70/87]\tLoss 1.2950 (1.2154)\tAccuracy 40.625 (40.757)\n",
      "Epoch: [40][80/87]\tLoss 1.1267 (1.2078)\tAccuracy 37.500 (41.127)\n",
      "Test: [ 0/25]\tLoss 1.1535 (1.1535)\tAccuracy 40.625 (40.625)\n",
      "Test: [10/25]\tLoss 1.2846 (1.1841)\tAccuracy 37.500 (41.477)\n",
      "Test: [20/25]\tLoss 1.1918 (1.1910)\tAccuracy 37.500 (41.518)\n",
      "Current Accuracy: 41.375\n",
      "The best accuracy: 41.375\n",
      "An epoch time: 61.7s\n",
      "********************41********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [41][ 0/87]\tLoss 1.2460 (1.2460)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [41][10/87]\tLoss 1.1485 (1.2343)\tAccuracy 37.500 (42.330)\n",
      "Epoch: [41][20/87]\tLoss 1.1216 (1.2188)\tAccuracy 53.125 (43.304)\n",
      "Epoch: [41][30/87]\tLoss 1.1949 (1.2177)\tAccuracy 46.875 (42.944)\n",
      "Epoch: [41][40/87]\tLoss 1.1513 (1.1980)\tAccuracy 43.750 (43.216)\n",
      "Epoch: [41][50/87]\tLoss 1.3223 (1.2074)\tAccuracy 28.125 (42.463)\n",
      "Epoch: [41][60/87]\tLoss 1.2918 (1.2082)\tAccuracy 40.625 (42.213)\n",
      "Epoch: [41][70/87]\tLoss 1.1122 (1.2068)\tAccuracy 46.875 (41.945)\n",
      "Epoch: [41][80/87]\tLoss 1.3657 (1.2122)\tAccuracy 37.500 (41.590)\n",
      "Test: [ 0/25]\tLoss 1.1664 (1.1664)\tAccuracy 37.500 (37.500)\n",
      "Test: [10/25]\tLoss 1.2925 (1.1811)\tAccuracy 31.250 (41.193)\n",
      "Test: [20/25]\tLoss 1.1773 (1.1851)\tAccuracy 46.875 (41.815)\n",
      "Current Accuracy: 41.625\n",
      "The best accuracy: 41.625\n",
      "An epoch time: 62.0s\n",
      "********************42********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [42][ 0/87]\tLoss 1.2511 (1.2511)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [42][10/87]\tLoss 1.1818 (1.1894)\tAccuracy 46.875 (46.591)\n",
      "Epoch: [42][20/87]\tLoss 1.1435 (1.2031)\tAccuracy 37.500 (43.750)\n",
      "Epoch: [42][30/87]\tLoss 1.1642 (1.1927)\tAccuracy 40.625 (42.944)\n",
      "Epoch: [42][40/87]\tLoss 1.1046 (1.1956)\tAccuracy 46.875 (42.835)\n",
      "Epoch: [42][50/87]\tLoss 1.3771 (1.2069)\tAccuracy 31.250 (42.402)\n",
      "Epoch: [42][60/87]\tLoss 1.1733 (1.2039)\tAccuracy 40.625 (42.572)\n",
      "Epoch: [42][70/87]\tLoss 1.3068 (1.2038)\tAccuracy 37.500 (42.870)\n",
      "Epoch: [42][80/87]\tLoss 1.1225 (1.2064)\tAccuracy 56.250 (42.400)\n",
      "Test: [ 0/25]\tLoss 1.1494 (1.1494)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.2637 (1.1709)\tAccuracy 34.375 (42.614)\n",
      "Test: [20/25]\tLoss 1.1683 (1.1795)\tAccuracy 43.750 (41.667)\n",
      "Current Accuracy: 41.625\n",
      "The best accuracy: 41.625\n",
      "An epoch time: 61.9s\n",
      "********************43********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [43][ 0/87]\tLoss 1.2967 (1.2967)\tAccuracy 28.125 (28.125)\n",
      "Epoch: [43][10/87]\tLoss 1.3026 (1.2319)\tAccuracy 25.000 (37.500)\n",
      "Epoch: [43][20/87]\tLoss 0.9123 (1.1757)\tAccuracy 50.000 (42.262)\n",
      "Epoch: [43][30/87]\tLoss 1.2277 (1.1814)\tAccuracy 40.625 (41.028)\n",
      "Epoch: [43][40/87]\tLoss 1.1676 (1.1884)\tAccuracy 37.500 (42.302)\n",
      "Epoch: [43][50/87]\tLoss 1.2540 (1.1974)\tAccuracy 28.125 (41.483)\n",
      "Epoch: [43][60/87]\tLoss 1.1013 (1.1911)\tAccuracy 46.875 (42.162)\n",
      "Epoch: [43][70/87]\tLoss 1.3197 (1.1980)\tAccuracy 34.375 (42.650)\n",
      "Epoch: [43][80/87]\tLoss 1.1856 (1.1974)\tAccuracy 40.625 (42.477)\n",
      "Test: [ 0/25]\tLoss 1.1632 (1.1632)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.2726 (1.1720)\tAccuracy 37.500 (43.466)\n",
      "Test: [20/25]\tLoss 1.1742 (1.1812)\tAccuracy 40.625 (41.815)\n",
      "Current Accuracy: 41.875\n",
      "The best accuracy: 41.875\n",
      "An epoch time: 62.0s\n",
      "********************44********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [44][ 0/87]\tLoss 1.2380 (1.2380)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [44][10/87]\tLoss 1.2927 (1.2116)\tAccuracy 28.125 (40.057)\n",
      "Epoch: [44][20/87]\tLoss 1.1127 (1.2008)\tAccuracy 46.875 (41.369)\n",
      "Epoch: [44][30/87]\tLoss 0.9838 (1.1992)\tAccuracy 50.000 (41.633)\n",
      "Epoch: [44][40/87]\tLoss 1.2408 (1.1933)\tAccuracy 43.750 (41.768)\n",
      "Epoch: [44][50/87]\tLoss 1.1696 (1.1928)\tAccuracy 40.625 (42.341)\n",
      "Epoch: [44][60/87]\tLoss 1.1188 (1.1945)\tAccuracy 43.750 (42.572)\n",
      "Epoch: [44][70/87]\tLoss 1.3479 (1.2009)\tAccuracy 37.500 (42.165)\n",
      "Epoch: [44][80/87]\tLoss 1.2666 (1.1974)\tAccuracy 28.125 (42.052)\n",
      "Test: [ 0/25]\tLoss 1.1570 (1.1570)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.2629 (1.1681)\tAccuracy 50.000 (44.034)\n",
      "Test: [20/25]\tLoss 1.1982 (1.1759)\tAccuracy 43.750 (42.708)\n",
      "Current Accuracy: 43.000\n",
      "The best accuracy: 43.000\n",
      "An epoch time: 61.8s\n",
      "********************45********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [45][ 0/87]\tLoss 1.2976 (1.2976)\tAccuracy 40.625 (40.625)\n",
      "Epoch: [45][10/87]\tLoss 1.0734 (1.1979)\tAccuracy 43.750 (42.330)\n",
      "Epoch: [45][20/87]\tLoss 1.1832 (1.1981)\tAccuracy 46.875 (42.262)\n",
      "Epoch: [45][30/87]\tLoss 1.1074 (1.1933)\tAccuracy 56.250 (42.944)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [45][40/87]\tLoss 1.0088 (1.1804)\tAccuracy 40.625 (43.979)\n",
      "Epoch: [45][50/87]\tLoss 0.9643 (1.1924)\tAccuracy 53.125 (42.892)\n",
      "Epoch: [45][60/87]\tLoss 1.1044 (1.1917)\tAccuracy 59.375 (43.033)\n",
      "Epoch: [45][70/87]\tLoss 1.2936 (1.1910)\tAccuracy 34.375 (43.046)\n",
      "Epoch: [45][80/87]\tLoss 1.0878 (1.1928)\tAccuracy 62.500 (42.824)\n",
      "Test: [ 0/25]\tLoss 1.1621 (1.1621)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.2794 (1.1697)\tAccuracy 37.500 (41.193)\n",
      "Test: [20/25]\tLoss 1.1847 (1.1831)\tAccuracy 43.750 (40.923)\n",
      "Current Accuracy: 41.500\n",
      "The best accuracy: 43.000\n",
      "An epoch time: 61.8s\n",
      "********************46********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [46][ 0/87]\tLoss 1.1522 (1.1522)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [46][10/87]\tLoss 1.5644 (1.2406)\tAccuracy 37.500 (45.455)\n",
      "Epoch: [46][20/87]\tLoss 1.0762 (1.1986)\tAccuracy 53.125 (46.577)\n",
      "Epoch: [46][30/87]\tLoss 1.1131 (1.2065)\tAccuracy 53.125 (44.859)\n",
      "Epoch: [46][40/87]\tLoss 1.1574 (1.2042)\tAccuracy 50.000 (44.665)\n",
      "Epoch: [46][50/87]\tLoss 1.1167 (1.1955)\tAccuracy 40.625 (44.363)\n",
      "Epoch: [46][60/87]\tLoss 1.1606 (1.1919)\tAccuracy 46.875 (44.365)\n",
      "Epoch: [46][70/87]\tLoss 1.3116 (1.1862)\tAccuracy 37.500 (44.190)\n",
      "Epoch: [46][80/87]\tLoss 1.1693 (1.1901)\tAccuracy 40.625 (43.480)\n",
      "Test: [ 0/25]\tLoss 1.1577 (1.1577)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.2704 (1.1609)\tAccuracy 37.500 (45.170)\n",
      "Test: [20/25]\tLoss 1.1873 (1.1720)\tAccuracy 43.750 (42.560)\n",
      "Current Accuracy: 42.625\n",
      "The best accuracy: 43.000\n",
      "An epoch time: 62.0s\n",
      "********************47********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [47][ 0/87]\tLoss 1.2247 (1.2247)\tAccuracy 40.625 (40.625)\n",
      "Epoch: [47][10/87]\tLoss 1.2117 (1.2366)\tAccuracy 46.875 (39.489)\n",
      "Epoch: [47][20/87]\tLoss 1.0641 (1.2184)\tAccuracy 53.125 (41.071)\n",
      "Epoch: [47][30/87]\tLoss 1.2466 (1.2319)\tAccuracy 37.500 (40.827)\n",
      "Epoch: [47][40/87]\tLoss 1.2698 (1.2264)\tAccuracy 40.625 (40.549)\n",
      "Epoch: [47][50/87]\tLoss 1.2847 (1.2169)\tAccuracy 28.125 (40.993)\n",
      "Epoch: [47][60/87]\tLoss 1.1560 (1.2158)\tAccuracy 56.250 (41.701)\n",
      "Epoch: [47][70/87]\tLoss 1.1554 (1.2080)\tAccuracy 43.750 (42.298)\n",
      "Epoch: [47][80/87]\tLoss 1.1450 (1.2011)\tAccuracy 50.000 (42.593)\n",
      "Test: [ 0/25]\tLoss 1.1540 (1.1540)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.2702 (1.1620)\tAccuracy 40.625 (42.898)\n",
      "Test: [20/25]\tLoss 1.1978 (1.1725)\tAccuracy 43.750 (41.667)\n",
      "Current Accuracy: 42.125\n",
      "The best accuracy: 43.000\n",
      "An epoch time: 61.7s\n",
      "********************48********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [48][ 0/87]\tLoss 1.4096 (1.4096)\tAccuracy 28.125 (28.125)\n",
      "Epoch: [48][10/87]\tLoss 1.3038 (1.2459)\tAccuracy 37.500 (41.193)\n",
      "Epoch: [48][20/87]\tLoss 1.3414 (1.2111)\tAccuracy 28.125 (40.476)\n",
      "Epoch: [48][30/87]\tLoss 1.1951 (1.2010)\tAccuracy 34.375 (41.835)\n",
      "Epoch: [48][40/87]\tLoss 1.2963 (1.1888)\tAccuracy 31.250 (42.988)\n",
      "Epoch: [48][50/87]\tLoss 0.9753 (1.1897)\tAccuracy 62.500 (43.015)\n",
      "Epoch: [48][60/87]\tLoss 1.1670 (1.1869)\tAccuracy 53.125 (43.340)\n",
      "Epoch: [48][70/87]\tLoss 1.1296 (1.1812)\tAccuracy 46.875 (43.838)\n",
      "Epoch: [48][80/87]\tLoss 1.0177 (1.1806)\tAccuracy 43.750 (43.827)\n",
      "Test: [ 0/25]\tLoss 1.1770 (1.1770)\tAccuracy 37.500 (37.500)\n",
      "Test: [10/25]\tLoss 1.2761 (1.1600)\tAccuracy 34.375 (44.034)\n",
      "Test: [20/25]\tLoss 1.1813 (1.1687)\tAccuracy 43.750 (43.750)\n",
      "Current Accuracy: 44.000\n",
      "The best accuracy: 44.000\n",
      "An epoch time: 61.7s\n",
      "********************49********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [49][ 0/87]\tLoss 1.3322 (1.3322)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [49][10/87]\tLoss 1.3191 (1.1829)\tAccuracy 28.125 (44.602)\n",
      "Epoch: [49][20/87]\tLoss 1.2987 (1.1810)\tAccuracy 25.000 (42.262)\n",
      "Epoch: [49][30/87]\tLoss 1.1369 (1.1739)\tAccuracy 46.875 (43.750)\n",
      "Epoch: [49][40/87]\tLoss 1.1459 (1.1776)\tAccuracy 46.875 (43.293)\n",
      "Epoch: [49][50/87]\tLoss 1.1727 (1.1772)\tAccuracy 46.875 (43.260)\n",
      "Epoch: [49][60/87]\tLoss 1.3649 (1.1750)\tAccuracy 40.625 (43.596)\n",
      "Epoch: [49][70/87]\tLoss 1.0856 (1.1781)\tAccuracy 50.000 (43.178)\n",
      "Epoch: [49][80/87]\tLoss 1.1276 (1.1804)\tAccuracy 37.500 (43.248)\n",
      "Test: [ 0/25]\tLoss 1.1425 (1.1425)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.2456 (1.1441)\tAccuracy 31.250 (42.330)\n",
      "Test: [20/25]\tLoss 1.1898 (1.1582)\tAccuracy 37.500 (42.113)\n",
      "Current Accuracy: 42.250\n",
      "The best accuracy: 44.000\n",
      "An epoch time: 62.0s\n",
      "********************50********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [50][ 0/87]\tLoss 1.2209 (1.2209)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [50][10/87]\tLoss 1.2132 (1.1474)\tAccuracy 40.625 (48.011)\n",
      "Epoch: [50][20/87]\tLoss 1.1581 (1.1854)\tAccuracy 40.625 (43.750)\n",
      "Epoch: [50][30/87]\tLoss 1.1973 (1.1919)\tAccuracy 40.625 (43.750)\n",
      "Epoch: [50][40/87]\tLoss 1.2380 (1.1907)\tAccuracy 43.750 (43.826)\n",
      "Epoch: [50][50/87]\tLoss 1.0996 (1.1982)\tAccuracy 34.375 (43.627)\n",
      "Epoch: [50][60/87]\tLoss 1.3356 (1.1967)\tAccuracy 34.375 (43.186)\n",
      "Epoch: [50][70/87]\tLoss 1.3186 (1.1964)\tAccuracy 43.750 (43.222)\n",
      "Epoch: [50][80/87]\tLoss 1.0039 (1.1904)\tAccuracy 56.250 (43.904)\n",
      "Test: [ 0/25]\tLoss 1.1711 (1.1711)\tAccuracy 40.625 (40.625)\n",
      "Test: [10/25]\tLoss 1.2377 (1.1525)\tAccuracy 40.625 (43.466)\n",
      "Test: [20/25]\tLoss 1.1614 (1.1644)\tAccuracy 40.625 (42.857)\n",
      "Current Accuracy: 42.750\n",
      "The best accuracy: 44.000\n",
      "An epoch time: 61.8s\n",
      "********************51********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [51][ 0/87]\tLoss 1.2029 (1.2029)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [51][10/87]\tLoss 1.2161 (1.2243)\tAccuracy 31.250 (36.932)\n",
      "Epoch: [51][20/87]\tLoss 1.2733 (1.2300)\tAccuracy 25.000 (37.202)\n",
      "Epoch: [51][30/87]\tLoss 1.2194 (1.2124)\tAccuracy 43.750 (39.315)\n",
      "Epoch: [51][40/87]\tLoss 1.1700 (1.2006)\tAccuracy 43.750 (40.396)\n",
      "Epoch: [51][50/87]\tLoss 1.0721 (1.1965)\tAccuracy 43.750 (40.196)\n",
      "Epoch: [51][60/87]\tLoss 1.1107 (1.1889)\tAccuracy 50.000 (41.547)\n",
      "Epoch: [51][70/87]\tLoss 1.1159 (1.1855)\tAccuracy 46.875 (41.593)\n",
      "Epoch: [51][80/87]\tLoss 1.0270 (1.1844)\tAccuracy 46.875 (41.667)\n",
      "Test: [ 0/25]\tLoss 1.1635 (1.1635)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.2386 (1.1446)\tAccuracy 34.375 (44.318)\n",
      "Test: [20/25]\tLoss 1.1715 (1.1523)\tAccuracy 43.750 (44.048)\n",
      "Current Accuracy: 43.625\n",
      "The best accuracy: 44.000\n",
      "An epoch time: 61.9s\n",
      "********************52********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [52][ 0/87]\tLoss 1.1522 (1.1522)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [52][10/87]\tLoss 1.2313 (1.1763)\tAccuracy 40.625 (45.739)\n",
      "Epoch: [52][20/87]\tLoss 1.2319 (1.1727)\tAccuracy 34.375 (44.196)\n",
      "Epoch: [52][30/87]\tLoss 1.0607 (1.1732)\tAccuracy 43.750 (42.843)\n",
      "Epoch: [52][40/87]\tLoss 1.1452 (1.1777)\tAccuracy 37.500 (41.768)\n",
      "Epoch: [52][50/87]\tLoss 1.0292 (1.1733)\tAccuracy 56.250 (42.157)\n",
      "Epoch: [52][60/87]\tLoss 1.2622 (1.1779)\tAccuracy 40.625 (41.957)\n",
      "Epoch: [52][70/87]\tLoss 1.1406 (1.1871)\tAccuracy 53.125 (41.901)\n",
      "Epoch: [52][80/87]\tLoss 1.1149 (1.1852)\tAccuracy 50.000 (41.860)\n",
      "Test: [ 0/25]\tLoss 1.1566 (1.1566)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.2304 (1.1341)\tAccuracy 37.500 (44.886)\n",
      "Test: [20/25]\tLoss 1.1597 (1.1487)\tAccuracy 43.750 (43.750)\n",
      "Current Accuracy: 43.375\n",
      "The best accuracy: 44.000\n",
      "An epoch time: 61.8s\n",
      "********************53********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [53][ 0/87]\tLoss 1.2241 (1.2241)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [53][10/87]\tLoss 1.1676 (1.2630)\tAccuracy 43.750 (39.205)\n",
      "Epoch: [53][20/87]\tLoss 1.2350 (1.2246)\tAccuracy 40.625 (39.435)\n",
      "Epoch: [53][30/87]\tLoss 1.2112 (1.2303)\tAccuracy 31.250 (38.609)\n",
      "Epoch: [53][40/87]\tLoss 1.1215 (1.2068)\tAccuracy 50.000 (41.768)\n",
      "Epoch: [53][50/87]\tLoss 1.2409 (1.1958)\tAccuracy 34.375 (41.973)\n",
      "Epoch: [53][60/87]\tLoss 1.3328 (1.1948)\tAccuracy 43.750 (42.982)\n",
      "Epoch: [53][70/87]\tLoss 1.1832 (1.1824)\tAccuracy 46.875 (44.366)\n",
      "Epoch: [53][80/87]\tLoss 1.2088 (1.1802)\tAccuracy 46.875 (44.637)\n",
      "Test: [ 0/25]\tLoss 1.1582 (1.1582)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.2523 (1.1412)\tAccuracy 37.500 (44.886)\n",
      "Test: [20/25]\tLoss 1.1780 (1.1604)\tAccuracy 43.750 (42.708)\n",
      "Current Accuracy: 42.750\n",
      "The best accuracy: 44.000\n",
      "An epoch time: 61.7s\n",
      "********************54********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [54][ 0/87]\tLoss 1.2863 (1.2863)\tAccuracy 34.375 (34.375)\n",
      "Epoch: [54][10/87]\tLoss 1.3092 (1.1838)\tAccuracy 25.000 (41.761)\n",
      "Epoch: [54][20/87]\tLoss 1.0684 (1.1870)\tAccuracy 53.125 (41.815)\n",
      "Epoch: [54][30/87]\tLoss 1.2282 (1.1816)\tAccuracy 40.625 (43.044)\n",
      "Epoch: [54][40/87]\tLoss 1.1934 (1.1765)\tAccuracy 37.500 (43.598)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [54][50/87]\tLoss 1.2996 (1.1905)\tAccuracy 40.625 (42.279)\n",
      "Epoch: [54][60/87]\tLoss 1.1593 (1.1876)\tAccuracy 40.625 (41.957)\n",
      "Epoch: [54][70/87]\tLoss 1.1873 (1.1792)\tAccuracy 43.750 (42.474)\n",
      "Epoch: [54][80/87]\tLoss 1.2148 (1.1748)\tAccuracy 43.750 (42.670)\n",
      "Test: [ 0/25]\tLoss 1.1497 (1.1497)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.2288 (1.1436)\tAccuracy 34.375 (46.023)\n",
      "Test: [20/25]\tLoss 1.1655 (1.1653)\tAccuracy 37.500 (42.560)\n",
      "Current Accuracy: 42.750\n",
      "The best accuracy: 44.000\n",
      "An epoch time: 61.6s\n",
      "********************55********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [55][ 0/87]\tLoss 1.2770 (1.2770)\tAccuracy 40.625 (40.625)\n",
      "Epoch: [55][10/87]\tLoss 1.1191 (1.1440)\tAccuracy 46.875 (44.318)\n",
      "Epoch: [55][20/87]\tLoss 1.2055 (1.1781)\tAccuracy 34.375 (40.923)\n",
      "Epoch: [55][30/87]\tLoss 1.0558 (1.1695)\tAccuracy 40.625 (42.036)\n",
      "Epoch: [55][40/87]\tLoss 1.3002 (1.1736)\tAccuracy 37.500 (41.692)\n",
      "Epoch: [55][50/87]\tLoss 1.1075 (1.1746)\tAccuracy 43.750 (42.034)\n",
      "Epoch: [55][60/87]\tLoss 1.0981 (1.1758)\tAccuracy 56.250 (42.520)\n",
      "Epoch: [55][70/87]\tLoss 1.1725 (1.1736)\tAccuracy 46.875 (42.782)\n",
      "Epoch: [55][80/87]\tLoss 1.1852 (1.1765)\tAccuracy 56.250 (42.863)\n",
      "Test: [ 0/25]\tLoss 1.1333 (1.1333)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.2480 (1.1277)\tAccuracy 37.500 (43.750)\n",
      "Test: [20/25]\tLoss 1.1800 (1.1403)\tAccuracy 50.000 (44.643)\n",
      "Current Accuracy: 44.250\n",
      "The best accuracy: 44.250\n",
      "An epoch time: 61.8s\n",
      "********************56********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [56][ 0/87]\tLoss 1.2821 (1.2821)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [56][10/87]\tLoss 1.2763 (1.2178)\tAccuracy 37.500 (43.182)\n",
      "Epoch: [56][20/87]\tLoss 1.1215 (1.1872)\tAccuracy 56.250 (43.601)\n",
      "Epoch: [56][30/87]\tLoss 1.0390 (1.1729)\tAccuracy 56.250 (43.649)\n",
      "Epoch: [56][40/87]\tLoss 1.0743 (1.1603)\tAccuracy 46.875 (44.207)\n",
      "Epoch: [56][50/87]\tLoss 1.1886 (1.1715)\tAccuracy 34.375 (43.260)\n",
      "Epoch: [56][60/87]\tLoss 1.3376 (1.1718)\tAccuracy 40.625 (43.494)\n",
      "Epoch: [56][70/87]\tLoss 1.2364 (1.1713)\tAccuracy 40.625 (43.706)\n",
      "Epoch: [56][80/87]\tLoss 1.0577 (1.1676)\tAccuracy 56.250 (44.329)\n",
      "Test: [ 0/25]\tLoss 1.0895 (1.0895)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.2122 (1.1154)\tAccuracy 31.250 (43.466)\n",
      "Test: [20/25]\tLoss 1.1766 (1.1311)\tAccuracy 40.625 (43.601)\n",
      "Current Accuracy: 43.500\n",
      "The best accuracy: 44.250\n",
      "An epoch time: 61.6s\n",
      "********************57********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [57][ 0/87]\tLoss 1.1436 (1.1436)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [57][10/87]\tLoss 1.1326 (1.1668)\tAccuracy 50.000 (45.739)\n",
      "Epoch: [57][20/87]\tLoss 1.1494 (1.1725)\tAccuracy 40.625 (44.940)\n",
      "Epoch: [57][30/87]\tLoss 1.2012 (1.1703)\tAccuracy 53.125 (45.060)\n",
      "Epoch: [57][40/87]\tLoss 1.1724 (1.1644)\tAccuracy 46.875 (45.046)\n",
      "Epoch: [57][50/87]\tLoss 1.1643 (1.1787)\tAccuracy 43.750 (44.792)\n",
      "Epoch: [57][60/87]\tLoss 1.3006 (1.1759)\tAccuracy 40.625 (44.980)\n",
      "Epoch: [57][70/87]\tLoss 1.0852 (1.1720)\tAccuracy 56.250 (45.290)\n",
      "Epoch: [57][80/87]\tLoss 1.2840 (1.1710)\tAccuracy 56.250 (45.525)\n",
      "Test: [ 0/25]\tLoss 1.0985 (1.0985)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.2184 (1.1246)\tAccuracy 43.750 (46.591)\n",
      "Test: [20/25]\tLoss 1.1831 (1.1388)\tAccuracy 43.750 (43.601)\n",
      "Current Accuracy: 44.000\n",
      "The best accuracy: 44.250\n",
      "An epoch time: 61.7s\n",
      "********************58********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [58][ 0/87]\tLoss 1.2027 (1.2027)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [58][10/87]\tLoss 1.0863 (1.1477)\tAccuracy 50.000 (44.602)\n",
      "Epoch: [58][20/87]\tLoss 1.1465 (1.1204)\tAccuracy 43.750 (47.321)\n",
      "Epoch: [58][30/87]\tLoss 1.1031 (1.1488)\tAccuracy 43.750 (44.859)\n",
      "Epoch: [58][40/87]\tLoss 1.1419 (1.1687)\tAccuracy 53.125 (43.902)\n",
      "Epoch: [58][50/87]\tLoss 1.2265 (1.1759)\tAccuracy 46.875 (43.382)\n",
      "Epoch: [58][60/87]\tLoss 1.2046 (1.1860)\tAccuracy 37.500 (42.623)\n",
      "Epoch: [58][70/87]\tLoss 1.1221 (1.1808)\tAccuracy 56.250 (43.266)\n",
      "Epoch: [58][80/87]\tLoss 1.1042 (1.1707)\tAccuracy 43.750 (44.329)\n",
      "Test: [ 0/25]\tLoss 1.0877 (1.0877)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.2110 (1.1170)\tAccuracy 37.500 (46.591)\n",
      "Test: [20/25]\tLoss 1.1985 (1.1374)\tAccuracy 37.500 (44.792)\n",
      "Current Accuracy: 44.500\n",
      "The best accuracy: 44.500\n",
      "An epoch time: 62.1s\n",
      "********************59********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [59][ 0/87]\tLoss 1.3441 (1.3441)\tAccuracy 31.250 (31.250)\n",
      "Epoch: [59][10/87]\tLoss 0.9580 (1.1741)\tAccuracy 50.000 (43.750)\n",
      "Epoch: [59][20/87]\tLoss 1.1566 (1.1854)\tAccuracy 40.625 (43.006)\n",
      "Epoch: [59][30/87]\tLoss 1.1307 (1.1590)\tAccuracy 62.500 (44.052)\n",
      "Epoch: [59][40/87]\tLoss 1.0373 (1.1655)\tAccuracy 46.875 (44.360)\n",
      "Epoch: [59][50/87]\tLoss 1.1299 (1.1621)\tAccuracy 43.750 (44.975)\n",
      "Epoch: [59][60/87]\tLoss 1.2382 (1.1697)\tAccuracy 31.250 (44.570)\n",
      "Epoch: [59][70/87]\tLoss 1.0943 (1.1769)\tAccuracy 56.250 (44.718)\n",
      "Epoch: [59][80/87]\tLoss 1.2250 (1.1746)\tAccuracy 56.250 (44.637)\n",
      "Test: [ 0/25]\tLoss 1.0929 (1.0929)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.2034 (1.1142)\tAccuracy 37.500 (44.602)\n",
      "Test: [20/25]\tLoss 1.2073 (1.1302)\tAccuracy 40.625 (43.601)\n",
      "Current Accuracy: 44.375\n",
      "The best accuracy: 44.500\n",
      "An epoch time: 62.2s\n",
      "********************60********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [60][ 0/87]\tLoss 1.1042 (1.1042)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [60][10/87]\tLoss 0.8943 (1.1052)\tAccuracy 65.625 (48.011)\n",
      "Epoch: [60][20/87]\tLoss 1.0223 (1.1278)\tAccuracy 53.125 (47.024)\n",
      "Epoch: [60][30/87]\tLoss 1.1544 (1.1306)\tAccuracy 37.500 (45.665)\n",
      "Epoch: [60][40/87]\tLoss 0.9658 (1.1292)\tAccuracy 50.000 (46.113)\n",
      "Epoch: [60][50/87]\tLoss 1.1871 (1.1383)\tAccuracy 50.000 (45.282)\n",
      "Epoch: [60][60/87]\tLoss 1.1844 (1.1450)\tAccuracy 43.750 (45.236)\n",
      "Epoch: [60][70/87]\tLoss 1.1221 (1.1516)\tAccuracy 53.125 (44.762)\n",
      "Epoch: [60][80/87]\tLoss 1.3844 (1.1535)\tAccuracy 18.750 (44.792)\n",
      "Test: [ 0/25]\tLoss 1.0766 (1.0766)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.1860 (1.1035)\tAccuracy 34.375 (46.307)\n",
      "Test: [20/25]\tLoss 1.2167 (1.1233)\tAccuracy 37.500 (44.940)\n",
      "Current Accuracy: 44.375\n",
      "The best accuracy: 44.500\n",
      "An epoch time: 61.9s\n",
      "********************61********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [61][ 0/87]\tLoss 1.0570 (1.0570)\tAccuracy 40.625 (40.625)\n",
      "Epoch: [61][10/87]\tLoss 0.9054 (1.1072)\tAccuracy 68.750 (48.295)\n",
      "Epoch: [61][20/87]\tLoss 1.1379 (1.1464)\tAccuracy 56.250 (45.089)\n",
      "Epoch: [61][30/87]\tLoss 1.0889 (1.1514)\tAccuracy 40.625 (43.952)\n",
      "Epoch: [61][40/87]\tLoss 1.1868 (1.1690)\tAccuracy 40.625 (43.902)\n",
      "Epoch: [61][50/87]\tLoss 1.1784 (1.1656)\tAccuracy 46.875 (44.608)\n",
      "Epoch: [61][60/87]\tLoss 1.2155 (1.1658)\tAccuracy 40.625 (44.365)\n",
      "Epoch: [61][70/87]\tLoss 1.1495 (1.1692)\tAccuracy 43.750 (44.366)\n",
      "Epoch: [61][80/87]\tLoss 1.2302 (1.1681)\tAccuracy 34.375 (44.676)\n",
      "Test: [ 0/25]\tLoss 1.0902 (1.0902)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.2080 (1.0994)\tAccuracy 34.375 (44.034)\n",
      "Test: [20/25]\tLoss 1.1675 (1.1110)\tAccuracy 43.750 (44.792)\n",
      "Current Accuracy: 44.625\n",
      "The best accuracy: 44.625\n",
      "An epoch time: 61.7s\n",
      "********************62********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [62][ 0/87]\tLoss 1.0154 (1.0154)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [62][10/87]\tLoss 1.0881 (1.0963)\tAccuracy 43.750 (49.148)\n",
      "Epoch: [62][20/87]\tLoss 1.2657 (1.1026)\tAccuracy 43.750 (48.512)\n",
      "Epoch: [62][30/87]\tLoss 1.2114 (1.1091)\tAccuracy 40.625 (48.387)\n",
      "Epoch: [62][40/87]\tLoss 1.1726 (1.1189)\tAccuracy 37.500 (47.180)\n",
      "Epoch: [62][50/87]\tLoss 1.1410 (1.1292)\tAccuracy 56.250 (46.875)\n",
      "Epoch: [62][60/87]\tLoss 1.2622 (1.1469)\tAccuracy 46.875 (46.311)\n",
      "Epoch: [62][70/87]\tLoss 1.3741 (1.1505)\tAccuracy 28.125 (45.731)\n",
      "Epoch: [62][80/87]\tLoss 1.3569 (1.1567)\tAccuracy 25.000 (45.293)\n",
      "Test: [ 0/25]\tLoss 1.1051 (1.1051)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.2170 (1.1042)\tAccuracy 28.125 (45.739)\n",
      "Test: [20/25]\tLoss 1.1393 (1.1185)\tAccuracy 34.375 (44.345)\n",
      "Current Accuracy: 43.750\n",
      "The best accuracy: 44.625\n",
      "An epoch time: 61.7s\n",
      "********************63********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [63][ 0/87]\tLoss 1.1840 (1.1840)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [63][10/87]\tLoss 1.0560 (1.1308)\tAccuracy 31.250 (46.023)\n",
      "Epoch: [63][20/87]\tLoss 1.0660 (1.1272)\tAccuracy 53.125 (47.917)\n",
      "Epoch: [63][30/87]\tLoss 1.1599 (1.1348)\tAccuracy 46.875 (47.883)\n",
      "Epoch: [63][40/87]\tLoss 1.1894 (1.1574)\tAccuracy 37.500 (45.655)\n",
      "Epoch: [63][50/87]\tLoss 1.1539 (1.1623)\tAccuracy 43.750 (46.140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63][60/87]\tLoss 1.0777 (1.1574)\tAccuracy 53.125 (46.107)\n",
      "Epoch: [63][70/87]\tLoss 0.9169 (1.1656)\tAccuracy 53.125 (45.379)\n",
      "Epoch: [63][80/87]\tLoss 1.1752 (1.1651)\tAccuracy 40.625 (45.332)\n",
      "Test: [ 0/25]\tLoss 1.0749 (1.0749)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.2045 (1.1015)\tAccuracy 37.500 (48.011)\n",
      "Test: [20/25]\tLoss 1.2139 (1.1169)\tAccuracy 37.500 (45.685)\n",
      "Current Accuracy: 45.750\n",
      "The best accuracy: 45.750\n",
      "An epoch time: 61.9s\n",
      "********************64********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [64][ 0/87]\tLoss 1.0784 (1.0784)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [64][10/87]\tLoss 1.1294 (1.1707)\tAccuracy 43.750 (44.034)\n",
      "Epoch: [64][20/87]\tLoss 1.0481 (1.1734)\tAccuracy 50.000 (43.899)\n",
      "Epoch: [64][30/87]\tLoss 1.1964 (1.1819)\tAccuracy 34.375 (42.742)\n",
      "Epoch: [64][40/87]\tLoss 1.1066 (1.1734)\tAccuracy 40.625 (43.369)\n",
      "Epoch: [64][50/87]\tLoss 0.7657 (1.1605)\tAccuracy 71.875 (44.240)\n",
      "Epoch: [64][60/87]\tLoss 1.3196 (1.1620)\tAccuracy 40.625 (44.826)\n",
      "Epoch: [64][70/87]\tLoss 1.1877 (1.1659)\tAccuracy 50.000 (44.850)\n",
      "Epoch: [64][80/87]\tLoss 1.2927 (1.1651)\tAccuracy 28.125 (44.830)\n",
      "Test: [ 0/25]\tLoss 1.0875 (1.0875)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.2308 (1.1062)\tAccuracy 31.250 (44.886)\n",
      "Test: [20/25]\tLoss 1.1306 (1.1095)\tAccuracy 43.750 (44.494)\n",
      "Current Accuracy: 44.625\n",
      "The best accuracy: 45.750\n",
      "An epoch time: 62.7s\n",
      "********************65********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [65][ 0/87]\tLoss 1.0072 (1.0072)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [65][10/87]\tLoss 1.2243 (1.1477)\tAccuracy 40.625 (44.318)\n",
      "Epoch: [65][20/87]\tLoss 1.2660 (1.1351)\tAccuracy 43.750 (46.577)\n",
      "Epoch: [65][30/87]\tLoss 1.1665 (1.1434)\tAccuracy 46.875 (45.665)\n",
      "Epoch: [65][40/87]\tLoss 1.1235 (1.1295)\tAccuracy 40.625 (46.113)\n",
      "Epoch: [65][50/87]\tLoss 1.2722 (1.1413)\tAccuracy 37.500 (45.037)\n",
      "Epoch: [65][60/87]\tLoss 1.1213 (1.1480)\tAccuracy 50.000 (45.082)\n",
      "Epoch: [65][70/87]\tLoss 1.1345 (1.1506)\tAccuracy 46.875 (44.542)\n",
      "Epoch: [65][80/87]\tLoss 0.9693 (1.1531)\tAccuracy 53.125 (44.290)\n",
      "Test: [ 0/25]\tLoss 1.0925 (1.0925)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.1798 (1.0920)\tAccuracy 31.250 (45.455)\n",
      "Test: [20/25]\tLoss 1.1514 (1.0975)\tAccuracy 43.750 (45.089)\n",
      "Current Accuracy: 44.750\n",
      "The best accuracy: 45.750\n",
      "An epoch time: 61.4s\n",
      "********************66********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [66][ 0/87]\tLoss 1.0589 (1.0589)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [66][10/87]\tLoss 1.3203 (1.2172)\tAccuracy 34.375 (42.614)\n",
      "Epoch: [66][20/87]\tLoss 1.2629 (1.1933)\tAccuracy 40.625 (43.155)\n",
      "Epoch: [66][30/87]\tLoss 1.3290 (1.1899)\tAccuracy 40.625 (43.548)\n",
      "Epoch: [66][40/87]\tLoss 1.1178 (1.1849)\tAccuracy 56.250 (44.512)\n",
      "Epoch: [66][50/87]\tLoss 1.1215 (1.1711)\tAccuracy 43.750 (44.975)\n",
      "Epoch: [66][60/87]\tLoss 1.2265 (1.1716)\tAccuracy 31.250 (45.236)\n",
      "Epoch: [66][70/87]\tLoss 1.0386 (1.1710)\tAccuracy 46.875 (45.643)\n",
      "Epoch: [66][80/87]\tLoss 1.1659 (1.1686)\tAccuracy 31.250 (45.139)\n",
      "Test: [ 0/25]\tLoss 1.0591 (1.0591)\tAccuracy 53.125 (53.125)\n",
      "Test: [10/25]\tLoss 1.2129 (1.0988)\tAccuracy 46.875 (46.023)\n",
      "Test: [20/25]\tLoss 1.1758 (1.1168)\tAccuracy 43.750 (45.387)\n",
      "Current Accuracy: 45.750\n",
      "The best accuracy: 45.750\n",
      "An epoch time: 62.3s\n",
      "********************67********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [67][ 0/87]\tLoss 1.4014 (1.4014)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [67][10/87]\tLoss 1.0488 (1.1932)\tAccuracy 53.125 (44.886)\n",
      "Epoch: [67][20/87]\tLoss 1.3335 (1.1667)\tAccuracy 40.625 (45.833)\n",
      "Epoch: [67][30/87]\tLoss 1.1641 (1.1466)\tAccuracy 43.750 (46.169)\n",
      "Epoch: [67][40/87]\tLoss 1.1734 (1.1433)\tAccuracy 40.625 (45.655)\n",
      "Epoch: [67][50/87]\tLoss 1.1069 (1.1330)\tAccuracy 56.250 (46.507)\n",
      "Epoch: [67][60/87]\tLoss 1.2244 (1.1332)\tAccuracy 34.375 (46.670)\n",
      "Epoch: [67][70/87]\tLoss 1.2458 (1.1381)\tAccuracy 37.500 (46.127)\n",
      "Epoch: [67][80/87]\tLoss 1.0796 (1.1426)\tAccuracy 43.750 (45.486)\n",
      "Test: [ 0/25]\tLoss 1.0546 (1.0546)\tAccuracy 53.125 (53.125)\n",
      "Test: [10/25]\tLoss 1.1824 (1.0811)\tAccuracy 37.500 (47.443)\n",
      "Test: [20/25]\tLoss 1.1583 (1.0884)\tAccuracy 31.250 (45.982)\n",
      "Current Accuracy: 45.500\n",
      "The best accuracy: 45.750\n",
      "An epoch time: 62.5s\n",
      "********************68********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [68][ 0/87]\tLoss 1.1166 (1.1166)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [68][10/87]\tLoss 1.1391 (1.2011)\tAccuracy 59.375 (44.318)\n",
      "Epoch: [68][20/87]\tLoss 1.2463 (1.1729)\tAccuracy 43.750 (47.173)\n",
      "Epoch: [68][30/87]\tLoss 0.9829 (1.1614)\tAccuracy 50.000 (47.480)\n",
      "Epoch: [68][40/87]\tLoss 1.0404 (1.1534)\tAccuracy 56.250 (47.409)\n",
      "Epoch: [68][50/87]\tLoss 1.1963 (1.1501)\tAccuracy 31.250 (47.243)\n",
      "Epoch: [68][60/87]\tLoss 1.2910 (1.1494)\tAccuracy 37.500 (46.670)\n",
      "Epoch: [68][70/87]\tLoss 1.3419 (1.1477)\tAccuracy 34.375 (46.699)\n",
      "Epoch: [68][80/87]\tLoss 1.3599 (1.1523)\tAccuracy 37.500 (46.181)\n",
      "Test: [ 0/25]\tLoss 1.0654 (1.0654)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1992 (1.0845)\tAccuracy 43.750 (46.307)\n",
      "Test: [20/25]\tLoss 1.1569 (1.0996)\tAccuracy 37.500 (44.048)\n",
      "Current Accuracy: 44.000\n",
      "The best accuracy: 45.750\n",
      "An epoch time: 62.4s\n",
      "********************69********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [69][ 0/87]\tLoss 1.1695 (1.1695)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [69][10/87]\tLoss 1.2492 (1.1678)\tAccuracy 31.250 (42.614)\n",
      "Epoch: [69][20/87]\tLoss 1.1486 (1.1659)\tAccuracy 40.625 (43.452)\n",
      "Epoch: [69][30/87]\tLoss 1.2458 (1.1555)\tAccuracy 50.000 (45.060)\n",
      "Epoch: [69][40/87]\tLoss 0.8848 (1.1527)\tAccuracy 68.750 (45.427)\n",
      "Epoch: [69][50/87]\tLoss 1.2185 (1.1540)\tAccuracy 46.875 (45.772)\n",
      "Epoch: [69][60/87]\tLoss 1.1776 (1.1594)\tAccuracy 46.875 (45.133)\n",
      "Epoch: [69][70/87]\tLoss 0.9925 (1.1519)\tAccuracy 43.750 (45.379)\n",
      "Epoch: [69][80/87]\tLoss 1.2506 (1.1551)\tAccuracy 50.000 (45.062)\n",
      "Test: [ 0/25]\tLoss 1.0250 (1.0250)\tAccuracy 56.250 (56.250)\n",
      "Test: [10/25]\tLoss 1.1901 (1.0597)\tAccuracy 46.875 (51.136)\n",
      "Test: [20/25]\tLoss 1.1241 (1.0782)\tAccuracy 34.375 (47.619)\n",
      "Current Accuracy: 46.875\n",
      "The best accuracy: 46.875\n",
      "An epoch time: 62.0s\n",
      "********************70********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [70][ 0/87]\tLoss 1.1280 (1.1280)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [70][10/87]\tLoss 1.2634 (1.1161)\tAccuracy 34.375 (49.716)\n",
      "Epoch: [70][20/87]\tLoss 1.1815 (1.1240)\tAccuracy 37.500 (47.024)\n",
      "Epoch: [70][30/87]\tLoss 1.1374 (1.1410)\tAccuracy 37.500 (45.262)\n",
      "Epoch: [70][40/87]\tLoss 0.9860 (1.1369)\tAccuracy 53.125 (45.960)\n",
      "Epoch: [70][50/87]\tLoss 1.2285 (1.1427)\tAccuracy 40.625 (45.772)\n",
      "Epoch: [70][60/87]\tLoss 1.1802 (1.1438)\tAccuracy 31.250 (45.645)\n",
      "Epoch: [70][70/87]\tLoss 0.8863 (1.1326)\tAccuracy 75.000 (46.567)\n",
      "Epoch: [70][80/87]\tLoss 1.1042 (1.1318)\tAccuracy 40.625 (46.798)\n",
      "Test: [ 0/25]\tLoss 1.0160 (1.0160)\tAccuracy 56.250 (56.250)\n",
      "Test: [10/25]\tLoss 1.2238 (1.0577)\tAccuracy 31.250 (49.148)\n",
      "Test: [20/25]\tLoss 1.0948 (1.0728)\tAccuracy 40.625 (47.470)\n",
      "Current Accuracy: 47.125\n",
      "The best accuracy: 47.125\n",
      "An epoch time: 62.0s\n",
      "********************71********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [71][ 0/87]\tLoss 1.1320 (1.1320)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [71][10/87]\tLoss 1.1809 (1.1265)\tAccuracy 40.625 (48.011)\n",
      "Epoch: [71][20/87]\tLoss 1.0912 (1.1498)\tAccuracy 53.125 (46.577)\n",
      "Epoch: [71][30/87]\tLoss 1.2599 (1.1533)\tAccuracy 43.750 (45.565)\n",
      "Epoch: [71][40/87]\tLoss 0.9556 (1.1540)\tAccuracy 62.500 (45.122)\n",
      "Epoch: [71][50/87]\tLoss 1.0527 (1.1401)\tAccuracy 53.125 (45.527)\n",
      "Epoch: [71][60/87]\tLoss 1.1961 (1.1389)\tAccuracy 46.875 (45.902)\n",
      "Epoch: [71][70/87]\tLoss 0.9715 (1.1276)\tAccuracy 59.375 (46.919)\n",
      "Epoch: [71][80/87]\tLoss 1.2428 (1.1274)\tAccuracy 37.500 (46.875)\n",
      "Test: [ 0/25]\tLoss 1.0471 (1.0471)\tAccuracy 53.125 (53.125)\n",
      "Test: [10/25]\tLoss 1.2243 (1.0598)\tAccuracy 40.625 (48.864)\n",
      "Test: [20/25]\tLoss 1.0570 (1.0684)\tAccuracy 46.875 (48.363)\n",
      "Current Accuracy: 48.000\n",
      "The best accuracy: 48.000\n",
      "An epoch time: 61.6s\n",
      "********************72********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [72][ 0/87]\tLoss 1.2096 (1.2096)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [72][10/87]\tLoss 0.9466 (1.1253)\tAccuracy 68.750 (49.432)\n",
      "Epoch: [72][20/87]\tLoss 1.0967 (1.1265)\tAccuracy 56.250 (50.149)\n",
      "Epoch: [72][30/87]\tLoss 1.0647 (1.1319)\tAccuracy 53.125 (48.690)\n",
      "Epoch: [72][40/87]\tLoss 1.2736 (1.1272)\tAccuracy 37.500 (47.790)\n",
      "Epoch: [72][50/87]\tLoss 1.3601 (1.1340)\tAccuracy 34.375 (47.365)\n",
      "Epoch: [72][60/87]\tLoss 1.0164 (1.1412)\tAccuracy 56.250 (47.336)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [72][70/87]\tLoss 0.9870 (1.1405)\tAccuracy 53.125 (47.095)\n",
      "Epoch: [72][80/87]\tLoss 1.0927 (1.1374)\tAccuracy 40.625 (46.528)\n",
      "Test: [ 0/25]\tLoss 1.0171 (1.0171)\tAccuracy 53.125 (53.125)\n",
      "Test: [10/25]\tLoss 1.2060 (1.0479)\tAccuracy 34.375 (50.568)\n",
      "Test: [20/25]\tLoss 1.0549 (1.0642)\tAccuracy 43.750 (48.065)\n",
      "Current Accuracy: 47.625\n",
      "The best accuracy: 48.000\n",
      "An epoch time: 63.2s\n",
      "********************73********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [73][ 0/87]\tLoss 1.3373 (1.3373)\tAccuracy 28.125 (28.125)\n",
      "Epoch: [73][10/87]\tLoss 1.1199 (1.1881)\tAccuracy 40.625 (40.341)\n",
      "Epoch: [73][20/87]\tLoss 1.0650 (1.1683)\tAccuracy 46.875 (41.369)\n",
      "Epoch: [73][30/87]\tLoss 1.1740 (1.1586)\tAccuracy 50.000 (43.548)\n",
      "Epoch: [73][40/87]\tLoss 1.3272 (1.1676)\tAccuracy 46.875 (43.750)\n",
      "Epoch: [73][50/87]\tLoss 1.2322 (1.1668)\tAccuracy 37.500 (44.240)\n",
      "Epoch: [73][60/87]\tLoss 1.0885 (1.1475)\tAccuracy 50.000 (45.645)\n",
      "Epoch: [73][70/87]\tLoss 1.0996 (1.1442)\tAccuracy 53.125 (45.819)\n",
      "Epoch: [73][80/87]\tLoss 1.0701 (1.1491)\tAccuracy 53.125 (45.486)\n",
      "Test: [ 0/25]\tLoss 1.0181 (1.0181)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1859 (1.0446)\tAccuracy 40.625 (49.148)\n",
      "Test: [20/25]\tLoss 1.0554 (1.0588)\tAccuracy 40.625 (48.363)\n",
      "Current Accuracy: 48.500\n",
      "The best accuracy: 48.500\n",
      "An epoch time: 62.1s\n",
      "********************74********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [74][ 0/87]\tLoss 1.2100 (1.2100)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [74][10/87]\tLoss 0.9888 (1.1175)\tAccuracy 62.500 (47.727)\n",
      "Epoch: [74][20/87]\tLoss 1.0214 (1.1179)\tAccuracy 53.125 (47.619)\n",
      "Epoch: [74][30/87]\tLoss 1.0399 (1.1233)\tAccuracy 53.125 (46.573)\n",
      "Epoch: [74][40/87]\tLoss 1.1413 (1.1107)\tAccuracy 37.500 (47.561)\n",
      "Epoch: [74][50/87]\tLoss 1.1956 (1.1234)\tAccuracy 53.125 (46.875)\n",
      "Epoch: [74][60/87]\tLoss 1.1652 (1.1329)\tAccuracy 43.750 (46.414)\n",
      "Epoch: [74][70/87]\tLoss 1.1550 (1.1344)\tAccuracy 50.000 (46.435)\n",
      "Epoch: [74][80/87]\tLoss 1.1449 (1.1310)\tAccuracy 46.875 (46.219)\n",
      "Test: [ 0/25]\tLoss 1.0255 (1.0255)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/25]\tLoss 1.1650 (1.0470)\tAccuracy 34.375 (48.295)\n",
      "Test: [20/25]\tLoss 1.0397 (1.0568)\tAccuracy 43.750 (46.131)\n",
      "Current Accuracy: 46.375\n",
      "The best accuracy: 48.500\n",
      "An epoch time: 62.5s\n",
      "********************75********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [75][ 0/87]\tLoss 1.1725 (1.1725)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [75][10/87]\tLoss 0.9913 (1.0432)\tAccuracy 62.500 (53.409)\n",
      "Epoch: [75][20/87]\tLoss 1.0819 (1.0657)\tAccuracy 43.750 (51.042)\n",
      "Epoch: [75][30/87]\tLoss 1.0866 (1.0898)\tAccuracy 43.750 (49.294)\n",
      "Epoch: [75][40/87]\tLoss 1.1303 (1.1125)\tAccuracy 40.625 (47.866)\n",
      "Epoch: [75][50/87]\tLoss 1.0721 (1.1319)\tAccuracy 56.250 (46.569)\n",
      "Epoch: [75][60/87]\tLoss 1.2868 (1.1226)\tAccuracy 43.750 (47.285)\n",
      "Epoch: [75][70/87]\tLoss 1.0002 (1.1167)\tAccuracy 43.750 (47.623)\n",
      "Epoch: [75][80/87]\tLoss 1.2600 (1.1226)\tAccuracy 40.625 (47.068)\n",
      "Test: [ 0/25]\tLoss 1.0100 (1.0100)\tAccuracy 53.125 (53.125)\n",
      "Test: [10/25]\tLoss 1.1679 (1.0282)\tAccuracy 34.375 (45.455)\n",
      "Test: [20/25]\tLoss 0.9870 (1.0215)\tAccuracy 46.875 (47.768)\n",
      "Current Accuracy: 48.125\n",
      "The best accuracy: 48.500\n",
      "An epoch time: 62.6s\n",
      "********************76********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [76][ 0/87]\tLoss 1.2609 (1.2609)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [76][10/87]\tLoss 1.0777 (1.1389)\tAccuracy 50.000 (48.295)\n",
      "Epoch: [76][20/87]\tLoss 0.8730 (1.1226)\tAccuracy 59.375 (48.512)\n",
      "Epoch: [76][30/87]\tLoss 1.1891 (1.1174)\tAccuracy 46.875 (49.698)\n",
      "Epoch: [76][40/87]\tLoss 1.0228 (1.1134)\tAccuracy 62.500 (49.543)\n",
      "Epoch: [76][50/87]\tLoss 0.9295 (1.1145)\tAccuracy 46.875 (49.081)\n",
      "Epoch: [76][60/87]\tLoss 1.2013 (1.1183)\tAccuracy 56.250 (48.975)\n",
      "Epoch: [76][70/87]\tLoss 1.1545 (1.1182)\tAccuracy 46.875 (49.164)\n",
      "Epoch: [76][80/87]\tLoss 1.2651 (1.1201)\tAccuracy 43.750 (48.495)\n",
      "Test: [ 0/25]\tLoss 0.9956 (0.9956)\tAccuracy 53.125 (53.125)\n",
      "Test: [10/25]\tLoss 1.1232 (1.0221)\tAccuracy 43.750 (50.284)\n",
      "Test: [20/25]\tLoss 1.0021 (1.0188)\tAccuracy 46.875 (49.554)\n",
      "Current Accuracy: 49.625\n",
      "The best accuracy: 49.625\n",
      "An epoch time: 63.6s\n",
      "********************77********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [77][ 0/87]\tLoss 1.1448 (1.1448)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [77][10/87]\tLoss 1.0381 (1.1276)\tAccuracy 62.500 (48.580)\n",
      "Epoch: [77][20/87]\tLoss 1.1945 (1.1364)\tAccuracy 40.625 (47.768)\n",
      "Epoch: [77][30/87]\tLoss 1.0529 (1.1167)\tAccuracy 46.875 (47.782)\n",
      "Epoch: [77][40/87]\tLoss 1.2547 (1.1170)\tAccuracy 43.750 (48.780)\n",
      "Epoch: [77][50/87]\tLoss 1.0248 (1.1104)\tAccuracy 50.000 (49.265)\n",
      "Epoch: [77][60/87]\tLoss 0.8557 (1.1152)\tAccuracy 71.875 (49.539)\n",
      "Epoch: [77][70/87]\tLoss 1.0574 (1.1162)\tAccuracy 56.250 (49.032)\n",
      "Epoch: [77][80/87]\tLoss 0.9326 (1.1113)\tAccuracy 53.125 (49.074)\n",
      "Test: [ 0/25]\tLoss 1.0609 (1.0609)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.2050 (1.0415)\tAccuracy 34.375 (47.159)\n",
      "Test: [20/25]\tLoss 0.9490 (1.0262)\tAccuracy 59.375 (49.851)\n",
      "Current Accuracy: 50.250\n",
      "The best accuracy: 50.250\n",
      "An epoch time: 62.6s\n",
      "********************78********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [78][ 0/87]\tLoss 1.1518 (1.1518)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [78][10/87]\tLoss 1.1500 (1.0652)\tAccuracy 50.000 (51.989)\n",
      "Epoch: [78][20/87]\tLoss 0.8871 (1.0762)\tAccuracy 46.875 (50.595)\n",
      "Epoch: [78][30/87]\tLoss 1.1413 (1.0819)\tAccuracy 43.750 (48.992)\n",
      "Epoch: [78][40/87]\tLoss 1.2273 (1.0884)\tAccuracy 37.500 (48.933)\n",
      "Epoch: [78][50/87]\tLoss 1.0841 (1.0919)\tAccuracy 53.125 (48.529)\n",
      "Epoch: [78][60/87]\tLoss 0.9297 (1.0826)\tAccuracy 50.000 (49.232)\n",
      "Epoch: [78][70/87]\tLoss 1.0768 (1.0848)\tAccuracy 46.875 (49.340)\n",
      "Epoch: [78][80/87]\tLoss 1.3030 (1.0922)\tAccuracy 37.500 (48.843)\n",
      "Test: [ 0/25]\tLoss 1.0526 (1.0526)\tAccuracy 40.625 (40.625)\n",
      "Test: [10/25]\tLoss 1.2382 (1.0279)\tAccuracy 43.750 (49.432)\n",
      "Test: [20/25]\tLoss 0.9156 (1.0002)\tAccuracy 50.000 (50.744)\n",
      "Current Accuracy: 50.625\n",
      "The best accuracy: 50.625\n",
      "An epoch time: 61.7s\n",
      "********************79********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [79][ 0/87]\tLoss 0.9239 (0.9239)\tAccuracy 59.375 (59.375)\n",
      "Epoch: [79][10/87]\tLoss 0.9638 (1.0925)\tAccuracy 50.000 (46.591)\n",
      "Epoch: [79][20/87]\tLoss 1.0962 (1.0888)\tAccuracy 40.625 (48.512)\n",
      "Epoch: [79][30/87]\tLoss 1.0401 (1.1048)\tAccuracy 53.125 (47.379)\n",
      "Epoch: [79][40/87]\tLoss 0.9860 (1.0800)\tAccuracy 56.250 (49.009)\n",
      "Epoch: [79][50/87]\tLoss 1.0212 (1.0920)\tAccuracy 50.000 (48.775)\n",
      "Epoch: [79][60/87]\tLoss 1.0959 (1.0885)\tAccuracy 43.750 (48.156)\n",
      "Epoch: [79][70/87]\tLoss 1.2697 (1.0908)\tAccuracy 37.500 (47.755)\n",
      "Epoch: [79][80/87]\tLoss 1.0370 (1.0910)\tAccuracy 43.750 (48.110)\n",
      "Test: [ 0/25]\tLoss 0.9786 (0.9786)\tAccuracy 53.125 (53.125)\n",
      "Test: [10/25]\tLoss 1.1949 (1.0172)\tAccuracy 40.625 (52.273)\n",
      "Test: [20/25]\tLoss 0.9901 (1.0115)\tAccuracy 46.875 (49.851)\n",
      "Current Accuracy: 50.375\n",
      "The best accuracy: 50.625\n",
      "An epoch time: 61.8s\n",
      "********************80********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [80][ 0/87]\tLoss 1.0308 (1.0308)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [80][10/87]\tLoss 0.9879 (1.0654)\tAccuracy 46.875 (48.011)\n",
      "Epoch: [80][20/87]\tLoss 1.1417 (1.0827)\tAccuracy 43.750 (47.917)\n",
      "Epoch: [80][30/87]\tLoss 1.1567 (1.0866)\tAccuracy 59.375 (48.286)\n",
      "Epoch: [80][40/87]\tLoss 1.1710 (1.0876)\tAccuracy 37.500 (47.942)\n",
      "Epoch: [80][50/87]\tLoss 0.8628 (1.0692)\tAccuracy 62.500 (48.713)\n",
      "Epoch: [80][60/87]\tLoss 1.3210 (1.0748)\tAccuracy 50.000 (48.975)\n",
      "Epoch: [80][70/87]\tLoss 0.9545 (1.0729)\tAccuracy 56.250 (49.384)\n",
      "Epoch: [80][80/87]\tLoss 1.1347 (1.0739)\tAccuracy 62.500 (49.576)\n",
      "Test: [ 0/25]\tLoss 0.9835 (0.9835)\tAccuracy 53.125 (53.125)\n",
      "Test: [10/25]\tLoss 1.1673 (1.0020)\tAccuracy 43.750 (51.705)\n",
      "Test: [20/25]\tLoss 0.9425 (0.9860)\tAccuracy 53.125 (51.190)\n",
      "Current Accuracy: 51.250\n",
      "The best accuracy: 51.250\n",
      "An epoch time: 62.1s\n",
      "********************81********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [81][ 0/87]\tLoss 0.9972 (0.9972)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [81][10/87]\tLoss 0.8907 (1.0274)\tAccuracy 65.625 (53.977)\n",
      "Epoch: [81][20/87]\tLoss 1.1219 (1.0889)\tAccuracy 40.625 (50.298)\n",
      "Epoch: [81][30/87]\tLoss 1.1284 (1.0833)\tAccuracy 46.875 (48.992)\n",
      "Epoch: [81][40/87]\tLoss 1.2152 (1.0711)\tAccuracy 31.250 (50.000)\n",
      "Epoch: [81][50/87]\tLoss 1.0618 (1.0648)\tAccuracy 53.125 (50.245)\n",
      "Epoch: [81][60/87]\tLoss 1.1835 (1.0624)\tAccuracy 53.125 (50.154)\n",
      "Epoch: [81][70/87]\tLoss 1.1979 (1.0565)\tAccuracy 34.375 (49.912)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [81][80/87]\tLoss 1.1867 (1.0586)\tAccuracy 40.625 (49.614)\n",
      "Test: [ 0/25]\tLoss 0.9908 (0.9908)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1902 (1.0029)\tAccuracy 50.000 (52.557)\n",
      "Test: [20/25]\tLoss 0.9309 (0.9859)\tAccuracy 50.000 (51.339)\n",
      "Current Accuracy: 51.375\n",
      "The best accuracy: 51.375\n",
      "An epoch time: 62.3s\n",
      "********************82********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [82][ 0/87]\tLoss 0.8698 (0.8698)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [82][10/87]\tLoss 0.9542 (1.0997)\tAccuracy 50.000 (46.591)\n",
      "Epoch: [82][20/87]\tLoss 0.8792 (1.0574)\tAccuracy 56.250 (50.298)\n",
      "Epoch: [82][30/87]\tLoss 1.1767 (1.0667)\tAccuracy 43.750 (50.302)\n",
      "Epoch: [82][40/87]\tLoss 1.2896 (1.0667)\tAccuracy 40.625 (50.152)\n",
      "Epoch: [82][50/87]\tLoss 1.0260 (1.0667)\tAccuracy 56.250 (50.368)\n",
      "Epoch: [82][60/87]\tLoss 1.1022 (1.0686)\tAccuracy 46.875 (50.051)\n",
      "Epoch: [82][70/87]\tLoss 1.1176 (1.0768)\tAccuracy 50.000 (49.736)\n",
      "Epoch: [82][80/87]\tLoss 1.0465 (1.0858)\tAccuracy 53.125 (49.498)\n",
      "Test: [ 0/25]\tLoss 0.9925 (0.9925)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.1852 (0.9984)\tAccuracy 53.125 (52.273)\n",
      "Test: [20/25]\tLoss 0.9237 (0.9812)\tAccuracy 50.000 (51.190)\n",
      "Current Accuracy: 51.250\n",
      "The best accuracy: 51.375\n",
      "An epoch time: 62.0s\n",
      "********************83********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [83][ 0/87]\tLoss 1.0462 (1.0462)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [83][10/87]\tLoss 1.0267 (1.0133)\tAccuracy 59.375 (55.114)\n",
      "Epoch: [83][20/87]\tLoss 1.0578 (1.0400)\tAccuracy 56.250 (52.976)\n",
      "Epoch: [83][30/87]\tLoss 1.0085 (1.0551)\tAccuracy 59.375 (52.419)\n",
      "Epoch: [83][40/87]\tLoss 1.0089 (1.0568)\tAccuracy 56.250 (52.439)\n",
      "Epoch: [83][50/87]\tLoss 0.9859 (1.0691)\tAccuracy 62.500 (50.735)\n",
      "Epoch: [83][60/87]\tLoss 1.1812 (1.0774)\tAccuracy 34.375 (49.846)\n",
      "Epoch: [83][70/87]\tLoss 0.8782 (1.0695)\tAccuracy 62.500 (49.956)\n",
      "Epoch: [83][80/87]\tLoss 1.0565 (1.0712)\tAccuracy 50.000 (49.923)\n",
      "Test: [ 0/25]\tLoss 0.9911 (0.9911)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.1751 (0.9982)\tAccuracy 50.000 (53.693)\n",
      "Test: [20/25]\tLoss 0.9260 (0.9813)\tAccuracy 50.000 (53.125)\n",
      "Current Accuracy: 52.875\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 62.0s\n",
      "********************84********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [84][ 0/87]\tLoss 1.1790 (1.1790)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [84][10/87]\tLoss 1.1907 (1.0823)\tAccuracy 46.875 (51.705)\n",
      "Epoch: [84][20/87]\tLoss 0.8732 (1.0398)\tAccuracy 59.375 (53.869)\n",
      "Epoch: [84][30/87]\tLoss 1.0687 (1.0478)\tAccuracy 43.750 (52.319)\n",
      "Epoch: [84][40/87]\tLoss 1.1279 (1.0454)\tAccuracy 46.875 (52.439)\n",
      "Epoch: [84][50/87]\tLoss 1.0469 (1.0639)\tAccuracy 43.750 (50.858)\n",
      "Epoch: [84][60/87]\tLoss 1.0821 (1.0693)\tAccuracy 43.750 (50.102)\n",
      "Epoch: [84][70/87]\tLoss 1.1585 (1.0699)\tAccuracy 53.125 (50.396)\n",
      "Epoch: [84][80/87]\tLoss 1.1276 (1.0738)\tAccuracy 46.875 (49.537)\n",
      "Test: [ 0/25]\tLoss 0.9848 (0.9848)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1806 (0.9924)\tAccuracy 43.750 (52.841)\n",
      "Test: [20/25]\tLoss 0.9156 (0.9770)\tAccuracy 53.125 (51.935)\n",
      "Current Accuracy: 51.750\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 61.6s\n",
      "********************85********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [85][ 0/87]\tLoss 1.0455 (1.0455)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [85][10/87]\tLoss 0.9647 (1.0428)\tAccuracy 59.375 (53.977)\n",
      "Epoch: [85][20/87]\tLoss 1.1521 (1.0476)\tAccuracy 50.000 (51.637)\n",
      "Epoch: [85][30/87]\tLoss 0.8005 (1.0436)\tAccuracy 75.000 (51.613)\n",
      "Epoch: [85][40/87]\tLoss 1.2130 (1.0497)\tAccuracy 43.750 (51.448)\n",
      "Epoch: [85][50/87]\tLoss 1.0526 (1.0622)\tAccuracy 53.125 (50.858)\n",
      "Epoch: [85][60/87]\tLoss 1.0230 (1.0717)\tAccuracy 50.000 (50.666)\n",
      "Epoch: [85][70/87]\tLoss 0.9907 (1.0634)\tAccuracy 56.250 (51.056)\n",
      "Epoch: [85][80/87]\tLoss 1.0820 (1.0654)\tAccuracy 34.375 (50.502)\n",
      "Test: [ 0/25]\tLoss 0.9872 (0.9872)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1699 (0.9922)\tAccuracy 46.875 (52.841)\n",
      "Test: [20/25]\tLoss 0.9144 (0.9775)\tAccuracy 53.125 (52.232)\n",
      "Current Accuracy: 52.000\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 61.6s\n",
      "********************86********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [86][ 0/87]\tLoss 1.1349 (1.1349)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [86][10/87]\tLoss 1.0380 (1.0807)\tAccuracy 50.000 (46.875)\n",
      "Epoch: [86][20/87]\tLoss 1.0115 (1.0847)\tAccuracy 46.875 (49.107)\n",
      "Epoch: [86][30/87]\tLoss 1.1954 (1.0903)\tAccuracy 53.125 (49.395)\n",
      "Epoch: [86][40/87]\tLoss 1.0237 (1.0931)\tAccuracy 50.000 (48.704)\n",
      "Epoch: [86][50/87]\tLoss 0.9898 (1.0887)\tAccuracy 65.625 (49.571)\n",
      "Epoch: [86][60/87]\tLoss 1.0853 (1.0799)\tAccuracy 50.000 (49.488)\n",
      "Epoch: [86][70/87]\tLoss 1.1822 (1.0767)\tAccuracy 43.750 (49.736)\n",
      "Epoch: [86][80/87]\tLoss 0.8619 (1.0711)\tAccuracy 68.750 (50.463)\n",
      "Test: [ 0/25]\tLoss 0.9822 (0.9822)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1577 (0.9920)\tAccuracy 46.875 (52.841)\n",
      "Test: [20/25]\tLoss 0.9169 (0.9758)\tAccuracy 50.000 (52.679)\n",
      "Current Accuracy: 52.500\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 61.6s\n",
      "********************87********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [87][ 0/87]\tLoss 1.1628 (1.1628)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [87][10/87]\tLoss 0.9986 (1.0834)\tAccuracy 43.750 (45.170)\n",
      "Epoch: [87][20/87]\tLoss 1.1577 (1.0815)\tAccuracy 37.500 (47.173)\n",
      "Epoch: [87][30/87]\tLoss 1.1602 (1.0887)\tAccuracy 46.875 (47.077)\n",
      "Epoch: [87][40/87]\tLoss 1.1496 (1.0739)\tAccuracy 46.875 (48.628)\n",
      "Epoch: [87][50/87]\tLoss 1.1038 (1.0719)\tAccuracy 50.000 (48.468)\n",
      "Epoch: [87][60/87]\tLoss 0.9796 (1.0738)\tAccuracy 59.375 (49.078)\n",
      "Epoch: [87][70/87]\tLoss 1.1318 (1.0670)\tAccuracy 43.750 (49.736)\n",
      "Epoch: [87][80/87]\tLoss 0.9736 (1.0599)\tAccuracy 50.000 (50.231)\n",
      "Test: [ 0/25]\tLoss 0.9769 (0.9769)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.1785 (0.9873)\tAccuracy 46.875 (53.409)\n",
      "Test: [20/25]\tLoss 0.8998 (0.9696)\tAccuracy 53.125 (52.530)\n",
      "Current Accuracy: 52.625\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 61.8s\n",
      "********************88********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [88][ 0/87]\tLoss 1.0866 (1.0866)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [88][10/87]\tLoss 1.1076 (1.1231)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [88][20/87]\tLoss 1.0180 (1.0862)\tAccuracy 53.125 (50.595)\n",
      "Epoch: [88][30/87]\tLoss 1.1745 (1.0774)\tAccuracy 40.625 (50.605)\n",
      "Epoch: [88][40/87]\tLoss 1.1227 (1.0686)\tAccuracy 50.000 (50.686)\n",
      "Epoch: [88][50/87]\tLoss 0.8171 (1.0707)\tAccuracy 68.750 (50.490)\n",
      "Epoch: [88][60/87]\tLoss 1.0854 (1.0712)\tAccuracy 50.000 (50.359)\n",
      "Epoch: [88][70/87]\tLoss 1.2172 (1.0779)\tAccuracy 31.250 (50.176)\n",
      "Epoch: [88][80/87]\tLoss 1.1084 (1.0787)\tAccuracy 46.875 (50.000)\n",
      "Test: [ 0/25]\tLoss 0.9646 (0.9646)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1750 (0.9867)\tAccuracy 50.000 (53.125)\n",
      "Test: [20/25]\tLoss 0.9205 (0.9730)\tAccuracy 50.000 (52.083)\n",
      "Current Accuracy: 51.750\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 61.6s\n",
      "********************89********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [89][ 0/87]\tLoss 0.9513 (0.9513)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [89][10/87]\tLoss 1.0809 (1.0516)\tAccuracy 50.000 (52.273)\n",
      "Epoch: [89][20/87]\tLoss 1.1574 (1.0609)\tAccuracy 53.125 (51.190)\n",
      "Epoch: [89][30/87]\tLoss 1.1233 (1.0753)\tAccuracy 53.125 (49.597)\n",
      "Epoch: [89][40/87]\tLoss 1.0274 (1.0573)\tAccuracy 50.000 (50.991)\n",
      "Epoch: [89][50/87]\tLoss 0.9735 (1.0651)\tAccuracy 65.625 (51.164)\n",
      "Epoch: [89][60/87]\tLoss 0.9816 (1.0659)\tAccuracy 56.250 (50.564)\n",
      "Epoch: [89][70/87]\tLoss 1.1170 (1.0708)\tAccuracy 46.875 (50.264)\n",
      "Epoch: [89][80/87]\tLoss 1.2198 (1.0684)\tAccuracy 40.625 (49.961)\n",
      "Test: [ 0/25]\tLoss 0.9667 (0.9667)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1659 (0.9899)\tAccuracy 37.500 (51.420)\n",
      "Test: [20/25]\tLoss 0.9036 (0.9749)\tAccuracy 53.125 (50.744)\n",
      "Current Accuracy: 50.750\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 61.6s\n",
      "********************90********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [90][ 0/87]\tLoss 1.1100 (1.1100)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [90][10/87]\tLoss 1.1342 (1.0794)\tAccuracy 40.625 (49.148)\n",
      "Epoch: [90][20/87]\tLoss 1.1690 (1.0739)\tAccuracy 46.875 (51.042)\n",
      "Epoch: [90][30/87]\tLoss 1.1432 (1.0788)\tAccuracy 53.125 (50.504)\n",
      "Epoch: [90][40/87]\tLoss 0.9049 (1.0659)\tAccuracy 50.000 (50.152)\n",
      "Epoch: [90][50/87]\tLoss 1.1357 (1.0787)\tAccuracy 59.375 (50.000)\n",
      "Epoch: [90][60/87]\tLoss 1.0875 (1.0726)\tAccuracy 46.875 (50.564)\n",
      "Epoch: [90][70/87]\tLoss 1.1673 (1.0742)\tAccuracy 43.750 (49.824)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [90][80/87]\tLoss 1.0359 (1.0699)\tAccuracy 53.125 (50.231)\n",
      "Test: [ 0/25]\tLoss 0.9747 (0.9747)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.1620 (0.9888)\tAccuracy 43.750 (52.557)\n",
      "Test: [20/25]\tLoss 0.9017 (0.9747)\tAccuracy 53.125 (51.637)\n",
      "Current Accuracy: 51.875\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 61.7s\n",
      "********************91********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [91][ 0/87]\tLoss 0.8890 (0.8890)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [91][10/87]\tLoss 1.2047 (1.0527)\tAccuracy 40.625 (48.580)\n",
      "Epoch: [91][20/87]\tLoss 1.1371 (1.0763)\tAccuracy 37.500 (48.065)\n",
      "Epoch: [91][30/87]\tLoss 0.9760 (1.0647)\tAccuracy 59.375 (49.899)\n",
      "Epoch: [91][40/87]\tLoss 1.1228 (1.0701)\tAccuracy 59.375 (49.771)\n",
      "Epoch: [91][50/87]\tLoss 1.0134 (1.0759)\tAccuracy 56.250 (49.632)\n",
      "Epoch: [91][60/87]\tLoss 1.1776 (1.0740)\tAccuracy 43.750 (50.102)\n",
      "Epoch: [91][70/87]\tLoss 1.0818 (1.0703)\tAccuracy 53.125 (50.176)\n",
      "Epoch: [91][80/87]\tLoss 1.0093 (1.0711)\tAccuracy 53.125 (50.077)\n",
      "Test: [ 0/25]\tLoss 0.9637 (0.9637)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1748 (0.9853)\tAccuracy 43.750 (52.557)\n",
      "Test: [20/25]\tLoss 0.8969 (0.9695)\tAccuracy 53.125 (51.786)\n",
      "Current Accuracy: 51.875\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 61.6s\n",
      "********************92********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [92][ 0/87]\tLoss 1.0416 (1.0416)\tAccuracy 59.375 (59.375)\n",
      "Epoch: [92][10/87]\tLoss 1.0525 (1.0862)\tAccuracy 53.125 (52.557)\n",
      "Epoch: [92][20/87]\tLoss 0.9751 (1.0798)\tAccuracy 56.250 (52.232)\n",
      "Epoch: [92][30/87]\tLoss 1.0760 (1.0805)\tAccuracy 50.000 (51.008)\n",
      "Epoch: [92][40/87]\tLoss 1.1448 (1.0805)\tAccuracy 37.500 (51.296)\n",
      "Epoch: [92][50/87]\tLoss 1.1821 (1.0814)\tAccuracy 40.625 (50.429)\n",
      "Epoch: [92][60/87]\tLoss 1.0271 (1.0702)\tAccuracy 40.625 (50.820)\n",
      "Epoch: [92][70/87]\tLoss 1.1197 (1.0611)\tAccuracy 46.875 (50.924)\n",
      "Epoch: [92][80/87]\tLoss 1.1767 (1.0583)\tAccuracy 37.500 (50.772)\n",
      "Test: [ 0/25]\tLoss 0.9712 (0.9712)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.1864 (0.9900)\tAccuracy 43.750 (53.125)\n",
      "Test: [20/25]\tLoss 0.8918 (0.9760)\tAccuracy 53.125 (52.083)\n",
      "Current Accuracy: 52.250\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 62.5s\n",
      "********************93********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [93][ 0/87]\tLoss 1.1044 (1.1044)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [93][10/87]\tLoss 1.0932 (1.0507)\tAccuracy 59.375 (51.136)\n",
      "Epoch: [93][20/87]\tLoss 0.9462 (1.0540)\tAccuracy 62.500 (50.149)\n",
      "Epoch: [93][30/87]\tLoss 1.2439 (1.0507)\tAccuracy 46.875 (50.605)\n",
      "Epoch: [93][40/87]\tLoss 0.9825 (1.0702)\tAccuracy 56.250 (50.305)\n",
      "Epoch: [93][50/87]\tLoss 1.1220 (1.0812)\tAccuracy 53.125 (49.449)\n",
      "Epoch: [93][60/87]\tLoss 1.1236 (1.0855)\tAccuracy 46.875 (48.514)\n",
      "Epoch: [93][70/87]\tLoss 1.2298 (1.0863)\tAccuracy 43.750 (48.371)\n",
      "Epoch: [93][80/87]\tLoss 1.0177 (1.0775)\tAccuracy 46.875 (48.534)\n",
      "Test: [ 0/25]\tLoss 0.9754 (0.9754)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.1598 (0.9857)\tAccuracy 43.750 (52.841)\n",
      "Test: [20/25]\tLoss 0.9003 (0.9713)\tAccuracy 53.125 (52.530)\n",
      "Current Accuracy: 52.500\n",
      "The best accuracy: 52.875\n",
      "An epoch time: 61.9s\n",
      "********************94********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [94][ 0/87]\tLoss 1.0204 (1.0204)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [94][10/87]\tLoss 0.7775 (1.0007)\tAccuracy 53.125 (51.989)\n",
      "Epoch: [94][20/87]\tLoss 1.1123 (1.0432)\tAccuracy 40.625 (52.232)\n",
      "Epoch: [94][30/87]\tLoss 0.8172 (1.0528)\tAccuracy 62.500 (51.915)\n",
      "Epoch: [94][40/87]\tLoss 1.0880 (1.0520)\tAccuracy 53.125 (51.524)\n",
      "Epoch: [94][50/87]\tLoss 0.8517 (1.0446)\tAccuracy 68.750 (52.206)\n",
      "Epoch: [94][60/87]\tLoss 1.1263 (1.0413)\tAccuracy 50.000 (52.203)\n",
      "Epoch: [94][70/87]\tLoss 1.1048 (1.0525)\tAccuracy 53.125 (51.629)\n",
      "Epoch: [94][80/87]\tLoss 0.8930 (1.0568)\tAccuracy 62.500 (50.887)\n",
      "Test: [ 0/25]\tLoss 0.9827 (0.9827)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.1543 (0.9918)\tAccuracy 46.875 (53.409)\n",
      "Test: [20/25]\tLoss 0.8971 (0.9765)\tAccuracy 53.125 (53.274)\n",
      "Current Accuracy: 53.250\n",
      "The best accuracy: 53.250\n",
      "An epoch time: 63.3s\n",
      "********************95********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [95][ 0/87]\tLoss 0.9191 (0.9191)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [95][10/87]\tLoss 0.8268 (1.0236)\tAccuracy 59.375 (51.136)\n",
      "Epoch: [95][20/87]\tLoss 1.2880 (1.0493)\tAccuracy 40.625 (50.446)\n",
      "Epoch: [95][30/87]\tLoss 1.1158 (1.0536)\tAccuracy 43.750 (50.000)\n",
      "Epoch: [95][40/87]\tLoss 1.0182 (1.0522)\tAccuracy 43.750 (49.619)\n",
      "Epoch: [95][50/87]\tLoss 1.1130 (1.0556)\tAccuracy 50.000 (49.694)\n",
      "Epoch: [95][60/87]\tLoss 1.0520 (1.0585)\tAccuracy 40.625 (49.232)\n",
      "Epoch: [95][70/87]\tLoss 1.0819 (1.0647)\tAccuracy 62.500 (48.900)\n",
      "Epoch: [95][80/87]\tLoss 1.1551 (1.0637)\tAccuracy 43.750 (49.113)\n",
      "Test: [ 0/25]\tLoss 0.9739 (0.9739)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1591 (0.9834)\tAccuracy 50.000 (53.693)\n",
      "Test: [20/25]\tLoss 0.9088 (0.9708)\tAccuracy 53.125 (52.976)\n",
      "Current Accuracy: 52.750\n",
      "The best accuracy: 53.250\n",
      "An epoch time: 61.7s\n",
      "********************96********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [96][ 0/87]\tLoss 1.1592 (1.1592)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [96][10/87]\tLoss 0.9036 (1.0529)\tAccuracy 65.625 (54.830)\n",
      "Epoch: [96][20/87]\tLoss 1.1853 (1.0473)\tAccuracy 50.000 (52.232)\n",
      "Epoch: [96][30/87]\tLoss 1.1756 (1.0422)\tAccuracy 43.750 (51.411)\n",
      "Epoch: [96][40/87]\tLoss 1.1851 (1.0454)\tAccuracy 37.500 (51.677)\n",
      "Epoch: [96][50/87]\tLoss 1.3020 (1.0507)\tAccuracy 46.875 (51.225)\n",
      "Epoch: [96][60/87]\tLoss 1.1627 (1.0523)\tAccuracy 37.500 (51.537)\n",
      "Epoch: [96][70/87]\tLoss 1.1131 (1.0515)\tAccuracy 46.875 (51.673)\n",
      "Epoch: [96][80/87]\tLoss 0.9080 (1.0583)\tAccuracy 56.250 (51.273)\n",
      "Test: [ 0/25]\tLoss 0.9746 (0.9746)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.1806 (0.9823)\tAccuracy 50.000 (53.977)\n",
      "Test: [20/25]\tLoss 0.8851 (0.9655)\tAccuracy 53.125 (52.827)\n",
      "Current Accuracy: 52.625\n",
      "The best accuracy: 53.250\n",
      "An epoch time: 61.9s\n",
      "********************97********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [97][ 0/87]\tLoss 0.9098 (0.9098)\tAccuracy 62.500 (62.500)\n",
      "Epoch: [97][10/87]\tLoss 1.0041 (1.0101)\tAccuracy 46.875 (52.841)\n",
      "Epoch: [97][20/87]\tLoss 0.9822 (1.0298)\tAccuracy 53.125 (50.744)\n",
      "Epoch: [97][30/87]\tLoss 1.0513 (1.0426)\tAccuracy 46.875 (49.798)\n",
      "Epoch: [97][40/87]\tLoss 1.0365 (1.0540)\tAccuracy 37.500 (48.857)\n",
      "Epoch: [97][50/87]\tLoss 1.0042 (1.0584)\tAccuracy 50.000 (49.387)\n",
      "Epoch: [97][60/87]\tLoss 1.1232 (1.0585)\tAccuracy 50.000 (49.488)\n",
      "Epoch: [97][70/87]\tLoss 1.2029 (1.0558)\tAccuracy 50.000 (49.956)\n",
      "Epoch: [97][80/87]\tLoss 0.9551 (1.0554)\tAccuracy 40.625 (50.193)\n",
      "Test: [ 0/25]\tLoss 0.9757 (0.9757)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1705 (0.9844)\tAccuracy 46.875 (53.409)\n",
      "Test: [20/25]\tLoss 0.8970 (0.9694)\tAccuracy 53.125 (52.083)\n",
      "Current Accuracy: 51.875\n",
      "The best accuracy: 53.250\n",
      "An epoch time: 61.8s\n",
      "********************98********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [98][ 0/87]\tLoss 1.0395 (1.0395)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [98][10/87]\tLoss 1.1492 (1.0481)\tAccuracy 37.500 (53.977)\n",
      "Epoch: [98][20/87]\tLoss 0.9966 (1.0269)\tAccuracy 53.125 (54.762)\n",
      "Epoch: [98][30/87]\tLoss 1.1309 (1.0425)\tAccuracy 46.875 (53.629)\n",
      "Epoch: [98][40/87]\tLoss 1.1304 (1.0601)\tAccuracy 46.875 (52.210)\n",
      "Epoch: [98][50/87]\tLoss 1.1676 (1.0717)\tAccuracy 37.500 (51.225)\n",
      "Epoch: [98][60/87]\tLoss 1.1147 (1.0680)\tAccuracy 46.875 (50.871)\n",
      "Epoch: [98][70/87]\tLoss 1.1548 (1.0630)\tAccuracy 40.625 (50.836)\n",
      "Epoch: [98][80/87]\tLoss 1.2137 (1.0634)\tAccuracy 37.500 (50.849)\n",
      "Test: [ 0/25]\tLoss 0.9685 (0.9685)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1652 (0.9796)\tAccuracy 50.000 (53.125)\n",
      "Test: [20/25]\tLoss 0.8968 (0.9632)\tAccuracy 53.125 (52.083)\n",
      "Current Accuracy: 52.125\n",
      "The best accuracy: 53.250\n",
      "An epoch time: 61.7s\n",
      "********************99********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [99][ 0/87]\tLoss 0.9982 (0.9982)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [99][10/87]\tLoss 0.9549 (1.0818)\tAccuracy 50.000 (49.432)\n",
      "Epoch: [99][20/87]\tLoss 1.0902 (1.0718)\tAccuracy 50.000 (49.702)\n",
      "Epoch: [99][30/87]\tLoss 1.1446 (1.0619)\tAccuracy 53.125 (50.806)\n",
      "Epoch: [99][40/87]\tLoss 1.2858 (1.0716)\tAccuracy 46.875 (50.534)\n",
      "Epoch: [99][50/87]\tLoss 1.3759 (1.0718)\tAccuracy 34.375 (50.184)\n",
      "Epoch: [99][60/87]\tLoss 1.0417 (1.0750)\tAccuracy 46.875 (49.488)\n",
      "Epoch: [99][70/87]\tLoss 1.0476 (1.0745)\tAccuracy 53.125 (49.648)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [99][80/87]\tLoss 1.0152 (1.0692)\tAccuracy 56.250 (49.537)\n",
      "Test: [ 0/25]\tLoss 0.9708 (0.9708)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1440 (0.9806)\tAccuracy 50.000 (53.409)\n",
      "Test: [20/25]\tLoss 0.8870 (0.9639)\tAccuracy 53.125 (52.530)\n",
      "Current Accuracy: 52.500\n",
      "The best accuracy: 53.250\n",
      "An epoch time: 61.8s\n"
     ]
    }
   ],
   "source": [
    "# Data loading code\n",
    "train_data = train_data_loader(project_dir=project_path, \n",
    "                               data_set=args.data_set)\n",
    "test_data = test_data_loader(project_dir=project_path,\n",
    "                             data_set=args.data_set)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=args.workers,\n",
    "                                           pin_memory=True,\n",
    "                                           drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                         batch_size=args.batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=args.workers,\n",
    "                                         pin_memory=True)\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    inf = '********************' + str(epoch) + '********************'\n",
    "    start_time = time.time()\n",
    "    current_learning_rate = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "    with open(log_txt_path, 'a') as f:\n",
    "        f.write(inf + '\\n')\n",
    "        f.write('Current learning rate: ' + str(current_learning_rate) + '\\n')\n",
    "\n",
    "    print(inf)\n",
    "    print('Current learning rate: ', current_learning_rate)\n",
    "\n",
    "    # train for one epoch\n",
    "    train_acc, train_los = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    val_acc, val_los = validate(val_loader, model, criterion, args)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # remember best acc and save checkpoint\n",
    "    is_best = val_acc > best_acc\n",
    "    best_acc = max(val_acc, best_acc)\n",
    "    save_checkpoint({'epoch': epoch + 1,\n",
    "                     'state_dict': model.state_dict(),\n",
    "                     'best_acc': best_acc,\n",
    "                     'optimizer': optimizer.state_dict(),\n",
    "                     'recorder': recorder}, is_best)\n",
    "\n",
    "    # print and save log\n",
    "    epoch_time = time.time() - start_time\n",
    "    recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n",
    "    recorder.plot_curve(log_curve_path)\n",
    "\n",
    "    print('The best accuracy: {:.3f}'.format(best_acc.item()))\n",
    "    print('An epoch time: {:.1f}s'.format(epoch_time))\n",
    "    with open(log_txt_path, 'a') as f:\n",
    "        f.write('The best accuracy: ' + str(best_acc.item()) + '\\n')\n",
    "        f.write('An epoch time: {:.1f}s' + str(epoch_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ad70557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/di/data/lee/nia/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3d4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
