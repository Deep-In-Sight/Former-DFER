{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322569ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b26c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from models.ST_Former import GenerateModel\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dataloader.dataset_NIA import train_data_loader, test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a8e3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from runner_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7cc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pseudoarg():\n",
    "    def __init__(self):\n",
    "        self.workers = 1\n",
    "        self.epochs = 100\n",
    "        self.start_epoch = 0\n",
    "        self.batch_size = 32\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.9\n",
    "        self.weight_decay = 1e-4\n",
    "        self.print_freq = 10\n",
    "        self.resume = None\n",
    "        self.data_set = 0\n",
    "        \n",
    "args = Pseudoarg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fddf0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "time_str = now.strftime(\"[%m-%d]-[%H:%M]-\")\n",
    "project_path = './nia/'\n",
    "log_txt_path = project_path + 'log/' + time_str + 'set' + str(args.data_set) + '-log.txt'\n",
    "log_curve_path = project_path + 'log/' + time_str + 'set' + str(args.data_set) + '-log.png'\n",
    "checkpoint_path = project_path + 'checkpoint/' + time_str + 'set' + str(args.data_set) + '-model.pth'\n",
    "best_checkpoint_path = project_path + 'checkpoint/' + time_str + 'set' + str(args.data_set) + '-model_best.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df3493a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_model = \"./nia/checkpoint/[08-25]-[08:08]-set0-model_best.pth\"\n",
    "args.resume = fn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f229715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def main():\n",
    "best_acc = 0\n",
    "#recorder = RecorderMeter(args.epochs)\n",
    "\n",
    "# create model and load pre_trained parameters\n",
    "model = GenerateModel()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf13e0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './nia/checkpoint/[08-25]-[08:08]-set0-model_best.pth'\n",
      "=> loaded checkpoint './nia/checkpoint/[08-25]-[08:08]-set0-model_best.pth' (epoch 48)\n"
     ]
    }
   ],
   "source": [
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc = checkpoint['best_acc']\n",
    "        recorder = checkpoint['recorder']\n",
    "        best_acc = best_acc.cuda()\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2534592f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video number:2800\n",
      "video number:799\n"
     ]
    }
   ],
   "source": [
    "# Data loading code\n",
    "train_data = train_data_loader(project_dir=project_path, \n",
    "                               data_set=args.data_set)\n",
    "test_data = test_data_loader(project_dir=project_path,\n",
    "                             data_set=args.data_set)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=args.workers,\n",
    "                                           pin_memory=True,\n",
    "                                           drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                         batch_size=args.batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=args.workers,\n",
    "                                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d37a7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt =[]\n",
    "for i, (images, target) in enumerate(val_loader):\n",
    "    tt.extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f20ab168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([213,   0, 130,   0,   0, 159,   0, 177,   0, 120]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(np.squeeze(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db00775c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "341f1dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************0********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [0][ 0/87]\tLoss 2.3868 (2.3868)\tAccuracy 12.500 (12.500)\n",
      "Epoch: [0][10/87]\tLoss 4.5241 (3.5132)\tAccuracy 15.625 (19.318)\n",
      "Epoch: [0][20/87]\tLoss 2.0793 (2.9263)\tAccuracy 21.875 (18.304)\n",
      "Epoch: [0][30/87]\tLoss 1.6212 (2.5622)\tAccuracy 31.250 (19.556)\n",
      "Epoch: [0][40/87]\tLoss 2.0750 (2.3503)\tAccuracy 21.875 (19.970)\n",
      "Epoch: [0][50/87]\tLoss 1.6269 (2.2201)\tAccuracy 25.000 (19.547)\n",
      "Epoch: [0][60/87]\tLoss 1.6939 (2.1245)\tAccuracy 18.750 (20.031)\n",
      "Epoch: [0][70/87]\tLoss 1.5758 (2.0535)\tAccuracy 28.125 (20.202)\n",
      "Epoch: [0][80/87]\tLoss 1.6554 (2.0040)\tAccuracy 12.500 (20.216)\n",
      "Test: [ 0/25]\tLoss 1.5443 (1.5443)\tAccuracy 31.250 (31.250)\n",
      "Test: [10/25]\tLoss 1.5183 (1.5857)\tAccuracy 12.500 (22.159)\n",
      "Test: [20/25]\tLoss 1.6525 (1.5996)\tAccuracy 15.625 (22.321)\n",
      "Current Accuracy: 23.029\n",
      "The best accuracy: 23.029\n",
      "An epoch time: 68.0s\n",
      "********************1********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [1][ 0/87]\tLoss 1.6111 (1.6111)\tAccuracy 21.875 (21.875)\n",
      "Epoch: [1][10/87]\tLoss 1.6557 (1.6210)\tAccuracy 21.875 (23.011)\n",
      "Epoch: [1][20/87]\tLoss 1.6683 (1.6373)\tAccuracy 28.125 (25.149)\n",
      "Epoch: [1][30/87]\tLoss 1.6191 (1.6456)\tAccuracy 25.000 (23.690)\n",
      "Epoch: [1][40/87]\tLoss 1.6226 (1.6482)\tAccuracy 25.000 (23.171)\n",
      "Epoch: [1][50/87]\tLoss 1.6486 (1.6466)\tAccuracy 28.125 (22.978)\n",
      "Epoch: [1][60/87]\tLoss 1.6507 (1.6409)\tAccuracy 21.875 (22.797)\n",
      "Epoch: [1][70/87]\tLoss 1.6475 (1.6413)\tAccuracy 15.625 (21.963)\n",
      "Epoch: [1][80/87]\tLoss 1.6133 (1.6410)\tAccuracy 25.000 (21.605)\n",
      "Test: [ 0/25]\tLoss 1.5607 (1.5607)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.4924 (1.5982)\tAccuracy 46.875 (29.545)\n",
      "Test: [20/25]\tLoss 1.6895 (1.6184)\tAccuracy 15.625 (26.488)\n",
      "Current Accuracy: 26.283\n",
      "The best accuracy: 26.283\n",
      "An epoch time: 64.3s\n",
      "********************2********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [2][ 0/87]\tLoss 1.7070 (1.7070)\tAccuracy 28.125 (28.125)\n",
      "Epoch: [2][10/87]\tLoss 1.5887 (1.6329)\tAccuracy 34.375 (21.307)\n",
      "Epoch: [2][20/87]\tLoss 1.6092 (1.6398)\tAccuracy 18.750 (19.792)\n",
      "Epoch: [2][30/87]\tLoss 1.6231 (1.6339)\tAccuracy 21.875 (20.363)\n",
      "Epoch: [2][40/87]\tLoss 1.6742 (1.6411)\tAccuracy 18.750 (19.512)\n",
      "Epoch: [2][50/87]\tLoss 1.5059 (1.6340)\tAccuracy 34.375 (20.343)\n",
      "Epoch: [2][60/87]\tLoss 1.5832 (1.6311)\tAccuracy 21.875 (20.748)\n",
      "Epoch: [2][70/87]\tLoss 1.6771 (1.6307)\tAccuracy 12.500 (20.555)\n",
      "Epoch: [2][80/87]\tLoss 1.5620 (1.6290)\tAccuracy 31.250 (20.910)\n",
      "Test: [ 0/25]\tLoss 1.6205 (1.6205)\tAccuracy 15.625 (15.625)\n",
      "Test: [10/25]\tLoss 1.8373 (1.7354)\tAccuracy 12.500 (15.057)\n",
      "Test: [20/25]\tLoss 1.6392 (1.7133)\tAccuracy 18.750 (16.518)\n",
      "Current Accuracy: 16.521\n",
      "The best accuracy: 26.283\n",
      "An epoch time: 64.1s\n",
      "********************3********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [3][ 0/87]\tLoss 1.7974 (1.7974)\tAccuracy  9.375 ( 9.375)\n",
      "Epoch: [3][10/87]\tLoss 1.6258 (1.6379)\tAccuracy 18.750 (20.455)\n",
      "Epoch: [3][20/87]\tLoss 1.5974 (1.6281)\tAccuracy 18.750 (21.577)\n",
      "Epoch: [3][30/87]\tLoss 1.6431 (1.6294)\tAccuracy 15.625 (20.262)\n",
      "Epoch: [3][40/87]\tLoss 1.5937 (1.6244)\tAccuracy 18.750 (20.274)\n",
      "Epoch: [3][50/87]\tLoss 1.6713 (1.6234)\tAccuracy  9.375 (19.914)\n",
      "Epoch: [3][60/87]\tLoss 1.6891 (1.6240)\tAccuracy 12.500 (20.543)\n",
      "Epoch: [3][70/87]\tLoss 1.5901 (1.6210)\tAccuracy 28.125 (20.775)\n",
      "Epoch: [3][80/87]\tLoss 1.5996 (1.6202)\tAccuracy 21.875 (21.219)\n",
      "Test: [ 0/25]\tLoss 1.6461 (1.6461)\tAccuracy 25.000 (25.000)\n",
      "Test: [10/25]\tLoss 1.5958 (1.6066)\tAccuracy 25.000 (20.455)\n",
      "Test: [20/25]\tLoss 1.6101 (1.6061)\tAccuracy 18.750 (22.024)\n",
      "Current Accuracy: 22.278\n",
      "The best accuracy: 26.283\n",
      "An epoch time: 64.0s\n",
      "********************4********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [4][ 0/87]\tLoss 1.5859 (1.5859)\tAccuracy 21.875 (21.875)\n",
      "Epoch: [4][10/87]\tLoss 1.6060 (1.6060)\tAccuracy 15.625 (19.034)\n",
      "Epoch: [4][20/87]\tLoss 1.5863 (1.6176)\tAccuracy 21.875 (20.685)\n",
      "Epoch: [4][30/87]\tLoss 1.6625 (1.6235)\tAccuracy 25.000 (21.673)\n",
      "Epoch: [4][40/87]\tLoss 1.7365 (1.6242)\tAccuracy 15.625 (21.646)\n",
      "Epoch: [4][50/87]\tLoss 1.6260 (1.6246)\tAccuracy 28.125 (21.324)\n",
      "Epoch: [4][60/87]\tLoss 1.5766 (1.6257)\tAccuracy 31.250 (21.721)\n",
      "Epoch: [4][70/87]\tLoss 1.5524 (1.6230)\tAccuracy 21.875 (21.303)\n",
      "Epoch: [4][80/87]\tLoss 1.6833 (1.6249)\tAccuracy 12.500 (21.103)\n",
      "Test: [ 0/25]\tLoss 1.6299 (1.6299)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.4790 (1.5719)\tAccuracy 46.875 (29.830)\n",
      "Test: [20/25]\tLoss 1.6505 (1.5840)\tAccuracy 15.625 (26.935)\n",
      "Current Accuracy: 26.658\n",
      "The best accuracy: 26.658\n",
      "An epoch time: 64.1s\n",
      "********************5********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [5][ 0/87]\tLoss 1.6588 (1.6588)\tAccuracy 21.875 (21.875)\n",
      "Epoch: [5][10/87]\tLoss 1.6120 (1.6163)\tAccuracy 15.625 (22.443)\n",
      "Epoch: [5][20/87]\tLoss 1.6225 (1.6227)\tAccuracy 15.625 (20.833)\n",
      "Epoch: [5][30/87]\tLoss 1.4744 (1.6099)\tAccuracy 28.125 (22.177)\n",
      "Epoch: [5][40/87]\tLoss 1.6014 (1.6214)\tAccuracy 28.125 (21.037)\n",
      "Epoch: [5][50/87]\tLoss 1.5469 (1.6163)\tAccuracy 21.875 (22.059)\n",
      "Epoch: [5][60/87]\tLoss 1.7126 (1.6169)\tAccuracy 12.500 (21.568)\n",
      "Epoch: [5][70/87]\tLoss 1.5471 (1.6161)\tAccuracy 25.000 (21.831)\n",
      "Epoch: [5][80/87]\tLoss 1.5797 (1.6164)\tAccuracy 25.000 (22.145)\n",
      "Test: [ 0/25]\tLoss 1.6181 (1.6181)\tAccuracy 12.500 (12.500)\n",
      "Test: [10/25]\tLoss 1.6334 (1.6144)\tAccuracy 12.500 (17.898)\n",
      "Test: [20/25]\tLoss 1.5827 (1.6096)\tAccuracy 21.875 (19.345)\n",
      "Current Accuracy: 20.025\n",
      "The best accuracy: 26.658\n",
      "An epoch time: 64.1s\n",
      "********************6********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [6][ 0/87]\tLoss 1.5413 (1.5413)\tAccuracy 25.000 (25.000)\n",
      "Epoch: [6][10/87]\tLoss 1.6946 (1.6263)\tAccuracy 15.625 (23.295)\n",
      "Epoch: [6][20/87]\tLoss 1.6165 (1.6172)\tAccuracy 12.500 (20.089)\n",
      "Epoch: [6][30/87]\tLoss 1.6428 (1.6128)\tAccuracy 15.625 (21.875)\n",
      "Epoch: [6][40/87]\tLoss 1.5236 (1.6109)\tAccuracy 37.500 (22.104)\n",
      "Epoch: [6][50/87]\tLoss 1.6164 (1.6066)\tAccuracy 15.625 (21.936)\n",
      "Epoch: [6][60/87]\tLoss 1.6268 (1.6064)\tAccuracy 21.875 (22.131)\n",
      "Epoch: [6][70/87]\tLoss 1.6084 (1.6057)\tAccuracy 28.125 (21.831)\n",
      "Epoch: [6][80/87]\tLoss 1.6479 (1.6048)\tAccuracy 15.625 (21.798)\n",
      "Test: [ 0/25]\tLoss 1.6734 (1.6734)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.4462 (1.6236)\tAccuracy 46.875 (29.830)\n",
      "Test: [20/25]\tLoss 1.7519 (1.6433)\tAccuracy 15.625 (26.935)\n",
      "Current Accuracy: 26.658\n",
      "The best accuracy: 26.658\n",
      "An epoch time: 64.1s\n",
      "********************7********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [7][ 0/87]\tLoss 1.5969 (1.5969)\tAccuracy 18.750 (18.750)\n",
      "Epoch: [7][10/87]\tLoss 1.5759 (1.5972)\tAccuracy 31.250 (24.716)\n",
      "Epoch: [7][20/87]\tLoss 1.5867 (1.5932)\tAccuracy 15.625 (25.000)\n",
      "Epoch: [7][30/87]\tLoss 1.5978 (1.5925)\tAccuracy 28.125 (24.496)\n",
      "Epoch: [7][40/87]\tLoss 1.6632 (1.5933)\tAccuracy 18.750 (24.771)\n",
      "Epoch: [7][50/87]\tLoss 1.5869 (1.5974)\tAccuracy 28.125 (23.958)\n",
      "Epoch: [7][60/87]\tLoss 1.6398 (1.5998)\tAccuracy 21.875 (23.617)\n",
      "Epoch: [7][70/87]\tLoss 1.6323 (1.5991)\tAccuracy 28.125 (23.371)\n",
      "Epoch: [7][80/87]\tLoss 1.5924 (1.5998)\tAccuracy 18.750 (22.878)\n",
      "Test: [ 0/25]\tLoss 1.6058 (1.6058)\tAccuracy 15.625 (15.625)\n",
      "Test: [10/25]\tLoss 1.5400 (1.5782)\tAccuracy 15.625 (20.739)\n",
      "Test: [20/25]\tLoss 1.6070 (1.5915)\tAccuracy 18.750 (20.387)\n",
      "Current Accuracy: 20.776\n",
      "The best accuracy: 26.658\n",
      "An epoch time: 64.1s\n",
      "********************8********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [8][ 0/87]\tLoss 1.7321 (1.7321)\tAccuracy 21.875 (21.875)\n",
      "Epoch: [8][10/87]\tLoss 1.5085 (1.6088)\tAccuracy 40.625 (23.580)\n",
      "Epoch: [8][20/87]\tLoss 1.6639 (1.6017)\tAccuracy 25.000 (24.554)\n",
      "Epoch: [8][30/87]\tLoss 1.6276 (1.6036)\tAccuracy 31.250 (24.899)\n",
      "Epoch: [8][40/87]\tLoss 1.6548 (1.6023)\tAccuracy 21.875 (24.771)\n",
      "Epoch: [8][50/87]\tLoss 1.5541 (1.6049)\tAccuracy 34.375 (23.529)\n",
      "Epoch: [8][60/87]\tLoss 1.5481 (1.6060)\tAccuracy 18.750 (22.643)\n",
      "Epoch: [8][70/87]\tLoss 1.7050 (1.6037)\tAccuracy  9.375 (22.447)\n",
      "Epoch: [8][80/87]\tLoss 1.6650 (1.6037)\tAccuracy 25.000 (22.454)\n",
      "Test: [ 0/25]\tLoss 1.5938 (1.5938)\tAccuracy 12.500 (12.500)\n",
      "Test: [10/25]\tLoss 1.6747 (1.6370)\tAccuracy 15.625 (17.898)\n",
      "Test: [20/25]\tLoss 1.5964 (1.6363)\tAccuracy 34.375 (20.982)\n",
      "Current Accuracy: 20.776\n",
      "The best accuracy: 26.658\n",
      "An epoch time: 64.0s\n",
      "********************9********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [9][ 0/87]\tLoss 1.6045 (1.6045)\tAccuracy  9.375 ( 9.375)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][10/87]\tLoss 1.5804 (1.5999)\tAccuracy 21.875 (22.159)\n",
      "Epoch: [9][20/87]\tLoss 1.5926 (1.5983)\tAccuracy 25.000 (21.429)\n",
      "Epoch: [9][30/87]\tLoss 1.5335 (1.5984)\tAccuracy 28.125 (21.774)\n",
      "Epoch: [9][40/87]\tLoss 1.6392 (1.6020)\tAccuracy 15.625 (21.418)\n",
      "Epoch: [9][50/87]\tLoss 1.5473 (1.5974)\tAccuracy 25.000 (22.304)\n",
      "Epoch: [9][60/87]\tLoss 1.5688 (1.5956)\tAccuracy 28.125 (23.156)\n",
      "Epoch: [9][70/87]\tLoss 1.5821 (1.5971)\tAccuracy 34.375 (22.931)\n",
      "Epoch: [9][80/87]\tLoss 1.5919 (1.5967)\tAccuracy 21.875 (22.762)\n",
      "Test: [ 0/25]\tLoss 1.6214 (1.6214)\tAccuracy 18.750 (18.750)\n",
      "Test: [10/25]\tLoss 1.4297 (1.5780)\tAccuracy 53.125 (30.966)\n",
      "Test: [20/25]\tLoss 1.7708 (1.6144)\tAccuracy 15.625 (25.595)\n",
      "Current Accuracy: 24.781\n",
      "The best accuracy: 26.658\n",
      "An epoch time: 64.5s\n",
      "********************10********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [10][ 0/87]\tLoss 1.6374 (1.6374)\tAccuracy 25.000 (25.000)\n",
      "Epoch: [10][10/87]\tLoss 1.5728 (1.5910)\tAccuracy 18.750 (23.011)\n",
      "Epoch: [10][20/87]\tLoss 1.6636 (1.5897)\tAccuracy 12.500 (22.173)\n",
      "Epoch: [10][30/87]\tLoss 1.6781 (1.5886)\tAccuracy 15.625 (22.278)\n",
      "Epoch: [10][40/87]\tLoss 1.6456 (1.5845)\tAccuracy 18.750 (22.790)\n",
      "Epoch: [10][50/87]\tLoss 1.6759 (1.5891)\tAccuracy 21.875 (22.794)\n",
      "Epoch: [10][60/87]\tLoss 1.6354 (1.5962)\tAccuracy 15.625 (22.490)\n",
      "Epoch: [10][70/87]\tLoss 1.6249 (1.5960)\tAccuracy 18.750 (22.271)\n",
      "Epoch: [10][80/87]\tLoss 1.5937 (1.5920)\tAccuracy 18.750 (22.840)\n",
      "Test: [ 0/25]\tLoss 1.5847 (1.5847)\tAccuracy 25.000 (25.000)\n",
      "Test: [10/25]\tLoss 1.4747 (1.5497)\tAccuracy 43.750 (28.693)\n",
      "Test: [20/25]\tLoss 1.5735 (1.5619)\tAccuracy 28.125 (28.125)\n",
      "Current Accuracy: 27.660\n",
      "The best accuracy: 27.660\n",
      "An epoch time: 64.6s\n",
      "********************11********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [11][ 0/87]\tLoss 1.5495 (1.5495)\tAccuracy 25.000 (25.000)\n",
      "Epoch: [11][10/87]\tLoss 1.5338 (1.5757)\tAccuracy 31.250 (25.852)\n",
      "Epoch: [11][20/87]\tLoss 1.5041 (1.5883)\tAccuracy 43.750 (23.512)\n",
      "Epoch: [11][30/87]\tLoss 1.5628 (1.5895)\tAccuracy 28.125 (24.194)\n",
      "Epoch: [11][40/87]\tLoss 1.6148 (1.5858)\tAccuracy 18.750 (24.848)\n",
      "Epoch: [11][50/87]\tLoss 1.6605 (1.5811)\tAccuracy 18.750 (24.877)\n",
      "Epoch: [11][60/87]\tLoss 1.5124 (1.5787)\tAccuracy 31.250 (24.846)\n",
      "Epoch: [11][70/87]\tLoss 1.4243 (1.5676)\tAccuracy 40.625 (25.572)\n",
      "Epoch: [11][80/87]\tLoss 1.4281 (1.5599)\tAccuracy 28.125 (25.656)\n",
      "Test: [ 0/25]\tLoss 1.4916 (1.4916)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.7200 (1.6071)\tAccuracy 21.875 (26.420)\n",
      "Test: [20/25]\tLoss 1.5021 (1.5933)\tAccuracy 34.375 (25.893)\n",
      "Current Accuracy: 26.283\n",
      "The best accuracy: 27.660\n",
      "An epoch time: 64.4s\n",
      "********************12********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [12][ 0/87]\tLoss 1.5366 (1.5366)\tAccuracy 31.250 (31.250)\n",
      "Epoch: [12][10/87]\tLoss 1.4627 (1.4866)\tAccuracy 28.125 (30.682)\n",
      "Epoch: [12][20/87]\tLoss 1.4899 (1.4853)\tAccuracy 34.375 (33.185)\n",
      "Epoch: [12][30/87]\tLoss 1.4409 (1.4734)\tAccuracy 25.000 (31.855)\n",
      "Epoch: [12][40/87]\tLoss 1.4430 (1.4604)\tAccuracy 28.125 (31.479)\n",
      "Epoch: [12][50/87]\tLoss 1.2880 (1.4415)\tAccuracy 21.875 (31.434)\n",
      "Epoch: [12][60/87]\tLoss 1.5360 (1.4344)\tAccuracy 34.375 (31.557)\n",
      "Epoch: [12][70/87]\tLoss 1.5803 (1.4444)\tAccuracy 15.625 (30.810)\n",
      "Epoch: [12][80/87]\tLoss 1.2554 (1.4299)\tAccuracy 37.500 (31.057)\n",
      "Test: [ 0/25]\tLoss 1.4719 (1.4719)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.4399 (1.5158)\tAccuracy 25.000 (27.557)\n",
      "Test: [20/25]\tLoss 1.6446 (1.5223)\tAccuracy 28.125 (27.679)\n",
      "Current Accuracy: 27.409\n",
      "The best accuracy: 27.660\n",
      "An epoch time: 64.5s\n",
      "********************13********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [13][ 0/87]\tLoss 1.4700 (1.4700)\tAccuracy 34.375 (34.375)\n",
      "Epoch: [13][10/87]\tLoss 1.2236 (1.3823)\tAccuracy 46.875 (32.955)\n",
      "Epoch: [13][20/87]\tLoss 1.3288 (1.3629)\tAccuracy 34.375 (33.780)\n",
      "Epoch: [13][30/87]\tLoss 1.3220 (1.3292)\tAccuracy 40.625 (35.081)\n",
      "Epoch: [13][40/87]\tLoss 1.1540 (1.3390)\tAccuracy 43.750 (35.290)\n",
      "Epoch: [13][50/87]\tLoss 1.1316 (1.3341)\tAccuracy 43.750 (34.988)\n",
      "Epoch: [13][60/87]\tLoss 1.4275 (1.3346)\tAccuracy 37.500 (34.939)\n",
      "Epoch: [13][70/87]\tLoss 1.6122 (1.3469)\tAccuracy 18.750 (34.419)\n",
      "Epoch: [13][80/87]\tLoss 1.3816 (1.3423)\tAccuracy 31.250 (34.722)\n",
      "Test: [ 0/25]\tLoss 1.4875 (1.4875)\tAccuracy 31.250 (31.250)\n",
      "Test: [10/25]\tLoss 1.3842 (1.4061)\tAccuracy 50.000 (40.341)\n",
      "Test: [20/25]\tLoss 1.4913 (1.3998)\tAccuracy 31.250 (38.839)\n",
      "Current Accuracy: 38.673\n",
      "The best accuracy: 38.673\n",
      "An epoch time: 64.5s\n",
      "********************14********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [14][ 0/87]\tLoss 1.2823 (1.2823)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [14][10/87]\tLoss 1.4779 (1.3242)\tAccuracy 21.875 (35.511)\n",
      "Epoch: [14][20/87]\tLoss 1.3612 (1.3602)\tAccuracy 34.375 (33.631)\n",
      "Epoch: [14][30/87]\tLoss 1.2240 (1.3333)\tAccuracy 34.375 (34.879)\n",
      "Epoch: [14][40/87]\tLoss 1.1055 (1.3240)\tAccuracy 40.625 (34.832)\n",
      "Epoch: [14][50/87]\tLoss 1.3871 (1.3262)\tAccuracy 31.250 (35.172)\n",
      "Epoch: [14][60/87]\tLoss 1.3087 (1.3121)\tAccuracy 31.250 (36.168)\n",
      "Epoch: [14][70/87]\tLoss 1.6547 (1.3075)\tAccuracy 37.500 (37.016)\n",
      "Epoch: [14][80/87]\tLoss 1.1063 (1.3157)\tAccuracy 53.125 (36.806)\n",
      "Test: [ 0/25]\tLoss 1.1737 (1.1737)\tAccuracy 56.250 (56.250)\n",
      "Test: [10/25]\tLoss 1.2994 (1.2153)\tAccuracy 28.125 (38.352)\n",
      "Test: [20/25]\tLoss 1.1688 (1.2152)\tAccuracy 46.875 (38.839)\n",
      "Current Accuracy: 38.924\n",
      "The best accuracy: 38.924\n",
      "An epoch time: 64.4s\n",
      "********************15********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [15][ 0/87]\tLoss 1.3305 (1.3305)\tAccuracy 25.000 (25.000)\n",
      "Epoch: [15][10/87]\tLoss 1.5795 (1.2572)\tAccuracy 18.750 (36.364)\n",
      "Epoch: [15][20/87]\tLoss 1.1923 (1.2487)\tAccuracy 43.750 (38.542)\n",
      "Epoch: [15][30/87]\tLoss 1.2946 (1.2599)\tAccuracy 34.375 (38.609)\n",
      "Epoch: [15][40/87]\tLoss 1.4241 (1.2586)\tAccuracy 37.500 (39.177)\n",
      "Epoch: [15][50/87]\tLoss 1.6667 (1.2724)\tAccuracy 34.375 (39.154)\n",
      "Epoch: [15][60/87]\tLoss 1.2281 (1.2771)\tAccuracy 46.875 (38.576)\n",
      "Epoch: [15][70/87]\tLoss 1.2471 (1.2781)\tAccuracy 31.250 (38.248)\n",
      "Epoch: [15][80/87]\tLoss 1.1622 (1.2743)\tAccuracy 43.750 (38.927)\n",
      "Test: [ 0/25]\tLoss 1.2450 (1.2450)\tAccuracy 21.875 (21.875)\n",
      "Test: [10/25]\tLoss 1.2925 (1.2292)\tAccuracy 18.750 (32.386)\n",
      "Test: [20/25]\tLoss 1.2341 (1.2025)\tAccuracy 37.500 (35.714)\n",
      "Current Accuracy: 35.795\n",
      "The best accuracy: 38.924\n",
      "An epoch time: 64.1s\n",
      "********************16********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [16][ 0/87]\tLoss 1.2729 (1.2729)\tAccuracy 31.250 (31.250)\n",
      "Epoch: [16][10/87]\tLoss 1.3423 (1.2950)\tAccuracy 40.625 (38.636)\n",
      "Epoch: [16][20/87]\tLoss 1.3231 (1.2789)\tAccuracy 43.750 (39.286)\n",
      "Epoch: [16][30/87]\tLoss 1.2357 (1.2659)\tAccuracy 43.750 (39.617)\n",
      "Epoch: [16][40/87]\tLoss 0.9901 (1.2489)\tAccuracy 56.250 (40.777)\n",
      "Epoch: [16][50/87]\tLoss 1.0530 (1.2389)\tAccuracy 46.875 (41.544)\n",
      "Epoch: [16][60/87]\tLoss 1.1076 (1.2343)\tAccuracy 43.750 (41.342)\n",
      "Epoch: [16][70/87]\tLoss 1.0160 (1.2183)\tAccuracy 56.250 (42.386)\n",
      "Epoch: [16][80/87]\tLoss 1.1574 (1.2040)\tAccuracy 43.750 (43.056)\n",
      "Test: [ 0/25]\tLoss 0.9721 (0.9721)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.2254 (1.0914)\tAccuracy 37.500 (44.886)\n",
      "Test: [20/25]\tLoss 1.0952 (1.0435)\tAccuracy 50.000 (48.512)\n",
      "Current Accuracy: 47.935\n",
      "The best accuracy: 47.935\n",
      "An epoch time: 63.7s\n",
      "********************17********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [17][ 0/87]\tLoss 1.1065 (1.1065)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [17][10/87]\tLoss 1.4537 (1.1785)\tAccuracy 28.125 (43.466)\n",
      "Epoch: [17][20/87]\tLoss 1.1201 (1.1537)\tAccuracy 50.000 (45.238)\n",
      "Epoch: [17][30/87]\tLoss 1.3389 (1.1679)\tAccuracy 25.000 (44.153)\n",
      "Epoch: [17][40/87]\tLoss 0.9056 (1.1500)\tAccuracy 50.000 (45.579)\n",
      "Epoch: [17][50/87]\tLoss 1.0807 (1.1356)\tAccuracy 65.625 (46.140)\n",
      "Epoch: [17][60/87]\tLoss 1.2513 (1.1410)\tAccuracy 34.375 (45.799)\n",
      "Epoch: [17][70/87]\tLoss 1.0834 (1.1488)\tAccuracy 43.750 (45.202)\n",
      "Epoch: [17][80/87]\tLoss 0.7085 (1.1405)\tAccuracy 68.750 (45.332)\n",
      "Test: [ 0/25]\tLoss 1.1095 (1.1095)\tAccuracy 34.375 (34.375)\n",
      "Test: [10/25]\tLoss 1.1134 (1.1063)\tAccuracy 59.375 (50.852)\n",
      "Test: [20/25]\tLoss 1.2639 (1.0994)\tAccuracy 34.375 (49.256)\n",
      "Current Accuracy: 48.436\n",
      "The best accuracy: 48.436\n",
      "An epoch time: 64.0s\n",
      "********************18********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [18][ 0/87]\tLoss 1.2554 (1.2554)\tAccuracy 34.375 (34.375)\n",
      "Epoch: [18][10/87]\tLoss 1.3032 (1.0825)\tAccuracy 28.125 (43.750)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [18][20/87]\tLoss 1.3855 (1.0954)\tAccuracy 28.125 (45.685)\n",
      "Epoch: [18][30/87]\tLoss 1.0655 (1.1565)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [18][40/87]\tLoss 1.3343 (1.1628)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [18][50/87]\tLoss 1.2647 (1.1649)\tAccuracy 43.750 (43.995)\n",
      "Epoch: [18][60/87]\tLoss 1.1902 (1.1525)\tAccuracy 37.500 (45.031)\n",
      "Epoch: [18][70/87]\tLoss 1.0865 (1.1526)\tAccuracy 50.000 (45.114)\n",
      "Epoch: [18][80/87]\tLoss 1.1941 (1.1456)\tAccuracy 43.750 (45.216)\n",
      "Test: [ 0/25]\tLoss 0.8570 (0.8570)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.0433 (1.0248)\tAccuracy 50.000 (48.295)\n",
      "Test: [20/25]\tLoss 1.1731 (1.0068)\tAccuracy 53.125 (50.000)\n",
      "Current Accuracy: 49.437\n",
      "The best accuracy: 49.437\n",
      "An epoch time: 64.0s\n",
      "********************19********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [19][ 0/87]\tLoss 1.2433 (1.2433)\tAccuracy 40.625 (40.625)\n",
      "Epoch: [19][10/87]\tLoss 1.0753 (1.0820)\tAccuracy 53.125 (50.000)\n",
      "Epoch: [19][20/87]\tLoss 1.1841 (1.0769)\tAccuracy 43.750 (50.446)\n",
      "Epoch: [19][30/87]\tLoss 1.2875 (1.0561)\tAccuracy 40.625 (50.504)\n",
      "Epoch: [19][40/87]\tLoss 1.1142 (1.0690)\tAccuracy 50.000 (49.009)\n",
      "Epoch: [19][50/87]\tLoss 1.1257 (1.0715)\tAccuracy 43.750 (48.958)\n",
      "Epoch: [19][60/87]\tLoss 1.0685 (1.0888)\tAccuracy 53.125 (48.822)\n",
      "Epoch: [19][70/87]\tLoss 1.0381 (1.1014)\tAccuracy 46.875 (48.460)\n",
      "Epoch: [19][80/87]\tLoss 1.1902 (1.1044)\tAccuracy 50.000 (48.611)\n",
      "Test: [ 0/25]\tLoss 0.9771 (0.9771)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1022 (0.9877)\tAccuracy 46.875 (48.580)\n",
      "Test: [20/25]\tLoss 0.9601 (0.9629)\tAccuracy 46.875 (49.405)\n",
      "Current Accuracy: 48.436\n",
      "The best accuracy: 49.437\n",
      "An epoch time: 63.9s\n",
      "********************20********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [20][ 0/87]\tLoss 1.0954 (1.0954)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [20][10/87]\tLoss 1.1518 (1.0829)\tAccuracy 53.125 (47.443)\n",
      "Epoch: [20][20/87]\tLoss 1.0013 (1.0911)\tAccuracy 53.125 (46.131)\n",
      "Epoch: [20][30/87]\tLoss 1.0791 (1.0959)\tAccuracy 46.875 (46.673)\n",
      "Epoch: [20][40/87]\tLoss 1.1318 (1.0843)\tAccuracy 34.375 (46.113)\n",
      "Epoch: [20][50/87]\tLoss 1.0866 (1.0839)\tAccuracy 50.000 (46.262)\n",
      "Epoch: [20][60/87]\tLoss 1.4690 (1.0756)\tAccuracy 28.125 (46.875)\n",
      "Epoch: [20][70/87]\tLoss 0.9862 (1.0855)\tAccuracy 40.625 (46.479)\n",
      "Epoch: [20][80/87]\tLoss 1.3756 (1.0941)\tAccuracy 15.625 (45.872)\n",
      "Test: [ 0/25]\tLoss 0.8429 (0.8429)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.2059 (0.9976)\tAccuracy 40.625 (53.409)\n",
      "Test: [20/25]\tLoss 0.9338 (0.9614)\tAccuracy 62.500 (54.613)\n",
      "Current Accuracy: 53.817\n",
      "The best accuracy: 53.817\n",
      "An epoch time: 64.3s\n",
      "********************21********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [21][ 0/87]\tLoss 1.3221 (1.3221)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [21][10/87]\tLoss 0.9728 (1.1445)\tAccuracy 56.250 (44.034)\n",
      "Epoch: [21][20/87]\tLoss 1.0576 (1.1118)\tAccuracy 46.875 (47.173)\n",
      "Epoch: [21][30/87]\tLoss 1.0701 (1.1097)\tAccuracy 37.500 (47.782)\n",
      "Epoch: [21][40/87]\tLoss 1.1331 (1.1119)\tAccuracy 40.625 (48.399)\n",
      "Epoch: [21][50/87]\tLoss 1.1756 (1.1155)\tAccuracy 40.625 (47.549)\n",
      "Epoch: [21][60/87]\tLoss 1.1686 (1.1068)\tAccuracy 43.750 (48.309)\n",
      "Epoch: [21][70/87]\tLoss 1.2250 (1.0991)\tAccuracy 34.375 (48.327)\n",
      "Epoch: [21][80/87]\tLoss 0.9948 (1.0942)\tAccuracy 46.875 (48.187)\n",
      "Test: [ 0/25]\tLoss 0.9924 (0.9924)\tAccuracy 50.000 (50.000)\n",
      "Test: [10/25]\tLoss 1.1456 (1.0835)\tAccuracy 34.375 (45.170)\n",
      "Test: [20/25]\tLoss 1.1064 (1.0465)\tAccuracy 53.125 (47.470)\n",
      "Current Accuracy: 47.810\n",
      "The best accuracy: 53.817\n",
      "An epoch time: 64.0s\n",
      "********************22********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [22][ 0/87]\tLoss 1.0986 (1.0986)\tAccuracy 43.750 (43.750)\n",
      "Epoch: [22][10/87]\tLoss 1.0174 (1.0795)\tAccuracy 59.375 (49.148)\n",
      "Epoch: [22][20/87]\tLoss 1.0557 (1.0702)\tAccuracy 46.875 (48.214)\n",
      "Epoch: [22][30/87]\tLoss 1.0418 (1.0639)\tAccuracy 46.875 (47.782)\n",
      "Epoch: [22][40/87]\tLoss 0.9958 (1.0537)\tAccuracy 50.000 (49.162)\n",
      "Epoch: [22][50/87]\tLoss 0.9778 (1.0474)\tAccuracy 37.500 (49.203)\n",
      "Epoch: [22][60/87]\tLoss 1.3934 (1.0681)\tAccuracy 28.125 (48.514)\n",
      "Epoch: [22][70/87]\tLoss 0.8293 (1.0540)\tAccuracy 62.500 (49.384)\n",
      "Epoch: [22][80/87]\tLoss 1.3572 (1.0663)\tAccuracy 37.500 (49.344)\n",
      "Test: [ 0/25]\tLoss 0.9449 (0.9449)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/25]\tLoss 1.0521 (0.9541)\tAccuracy 56.250 (54.261)\n",
      "Test: [20/25]\tLoss 0.9234 (0.9407)\tAccuracy 50.000 (53.274)\n",
      "Current Accuracy: 53.317\n",
      "The best accuracy: 53.817\n",
      "An epoch time: 64.0s\n",
      "********************23********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [23][ 0/87]\tLoss 1.0289 (1.0289)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [23][10/87]\tLoss 0.8966 (1.0404)\tAccuracy 53.125 (51.136)\n",
      "Epoch: [23][20/87]\tLoss 1.1750 (1.0524)\tAccuracy 50.000 (50.446)\n",
      "Epoch: [23][30/87]\tLoss 1.0180 (1.0631)\tAccuracy 59.375 (50.101)\n",
      "Epoch: [23][40/87]\tLoss 1.1210 (1.0609)\tAccuracy 43.750 (49.848)\n",
      "Epoch: [23][50/87]\tLoss 0.8985 (1.0621)\tAccuracy 46.875 (49.755)\n",
      "Epoch: [23][60/87]\tLoss 1.0943 (1.0582)\tAccuracy 53.125 (49.795)\n",
      "Epoch: [23][70/87]\tLoss 1.2221 (1.0607)\tAccuracy 40.625 (49.076)\n",
      "Epoch: [23][80/87]\tLoss 1.3807 (1.0638)\tAccuracy 46.875 (49.035)\n",
      "Test: [ 0/25]\tLoss 0.8575 (0.8575)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.0534 (0.9136)\tAccuracy 46.875 (54.830)\n",
      "Test: [20/25]\tLoss 0.8341 (0.8968)\tAccuracy 59.375 (55.655)\n",
      "Current Accuracy: 55.444\n",
      "The best accuracy: 55.444\n",
      "An epoch time: 64.2s\n",
      "********************24********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [24][ 0/87]\tLoss 1.0023 (1.0023)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [24][10/87]\tLoss 1.0370 (1.1018)\tAccuracy 46.875 (48.011)\n",
      "Epoch: [24][20/87]\tLoss 1.3401 (1.1077)\tAccuracy 37.500 (46.726)\n",
      "Epoch: [24][30/87]\tLoss 0.8358 (1.1007)\tAccuracy 65.625 (47.984)\n",
      "Epoch: [24][40/87]\tLoss 1.0250 (1.0712)\tAccuracy 46.875 (48.857)\n",
      "Epoch: [24][50/87]\tLoss 1.0302 (1.0607)\tAccuracy 56.250 (50.735)\n",
      "Epoch: [24][60/87]\tLoss 0.8879 (1.0559)\tAccuracy 53.125 (50.512)\n",
      "Epoch: [24][70/87]\tLoss 1.0661 (1.0370)\tAccuracy 53.125 (51.100)\n",
      "Epoch: [24][80/87]\tLoss 0.8684 (1.0384)\tAccuracy 56.250 (51.157)\n",
      "Test: [ 0/25]\tLoss 0.9775 (0.9775)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.2543 (1.0923)\tAccuracy 34.375 (44.886)\n",
      "Test: [20/25]\tLoss 1.1218 (1.0376)\tAccuracy 50.000 (49.107)\n",
      "Current Accuracy: 49.312\n",
      "The best accuracy: 55.444\n",
      "An epoch time: 63.8s\n",
      "********************25********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [25][ 0/87]\tLoss 1.1907 (1.1907)\tAccuracy 31.250 (31.250)\n",
      "Epoch: [25][10/87]\tLoss 0.9208 (1.0452)\tAccuracy 62.500 (48.011)\n",
      "Epoch: [25][20/87]\tLoss 1.2796 (1.0735)\tAccuracy 40.625 (47.470)\n",
      "Epoch: [25][30/87]\tLoss 1.0161 (1.0649)\tAccuracy 62.500 (48.790)\n",
      "Epoch: [25][40/87]\tLoss 0.9860 (1.0535)\tAccuracy 46.875 (49.771)\n",
      "Epoch: [25][50/87]\tLoss 1.4251 (1.0537)\tAccuracy 31.250 (49.326)\n",
      "Epoch: [25][60/87]\tLoss 1.1332 (1.0537)\tAccuracy 56.250 (49.283)\n",
      "Epoch: [25][70/87]\tLoss 1.2003 (1.0541)\tAccuracy 53.125 (49.120)\n",
      "Epoch: [25][80/87]\tLoss 1.0220 (1.0431)\tAccuracy 53.125 (49.653)\n",
      "Test: [ 0/25]\tLoss 0.8958 (0.8958)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/25]\tLoss 0.9807 (0.9032)\tAccuracy 40.625 (51.136)\n",
      "Test: [20/25]\tLoss 0.8377 (0.8744)\tAccuracy 56.250 (53.423)\n",
      "Current Accuracy: 52.816\n",
      "The best accuracy: 55.444\n",
      "An epoch time: 64.2s\n",
      "********************26********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [26][ 0/87]\tLoss 0.9475 (0.9475)\tAccuracy 62.500 (62.500)\n",
      "Epoch: [26][10/87]\tLoss 1.0097 (1.0036)\tAccuracy 50.000 (52.841)\n",
      "Epoch: [26][20/87]\tLoss 1.0752 (0.9826)\tAccuracy 43.750 (53.274)\n",
      "Epoch: [26][30/87]\tLoss 0.9989 (0.9981)\tAccuracy 37.500 (51.512)\n",
      "Epoch: [26][40/87]\tLoss 0.8765 (1.0077)\tAccuracy 56.250 (51.372)\n",
      "Epoch: [26][50/87]\tLoss 1.3563 (1.0438)\tAccuracy 46.875 (49.816)\n",
      "Epoch: [26][60/87]\tLoss 1.1059 (1.0487)\tAccuracy 59.375 (50.102)\n",
      "Epoch: [26][70/87]\tLoss 0.9464 (1.0421)\tAccuracy 56.250 (51.100)\n",
      "Epoch: [26][80/87]\tLoss 0.9611 (1.0424)\tAccuracy 50.000 (50.965)\n",
      "Test: [ 0/25]\tLoss 0.8979 (0.8979)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.0804 (0.9521)\tAccuracy 46.875 (56.250)\n",
      "Test: [20/25]\tLoss 0.8572 (0.9176)\tAccuracy 53.125 (57.292)\n",
      "Current Accuracy: 57.071\n",
      "The best accuracy: 57.071\n",
      "An epoch time: 63.9s\n",
      "********************27********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [27][ 0/87]\tLoss 1.0655 (1.0655)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [27][10/87]\tLoss 0.9529 (1.0238)\tAccuracy 50.000 (50.852)\n",
      "Epoch: [27][20/87]\tLoss 0.9521 (1.0509)\tAccuracy 65.625 (50.149)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [27][30/87]\tLoss 1.1034 (1.0482)\tAccuracy 37.500 (49.899)\n",
      "Epoch: [27][40/87]\tLoss 1.0579 (1.0293)\tAccuracy 50.000 (50.991)\n",
      "Epoch: [27][50/87]\tLoss 1.0741 (1.0279)\tAccuracy 34.375 (50.919)\n",
      "Epoch: [27][60/87]\tLoss 1.2411 (1.0258)\tAccuracy 40.625 (50.820)\n",
      "Epoch: [27][70/87]\tLoss 0.9543 (1.0250)\tAccuracy 50.000 (50.836)\n",
      "Epoch: [27][80/87]\tLoss 1.0814 (1.0243)\tAccuracy 50.000 (51.003)\n",
      "Test: [ 0/25]\tLoss 1.0299 (1.0299)\tAccuracy 43.750 (43.750)\n",
      "Test: [10/25]\tLoss 1.0889 (1.0313)\tAccuracy 37.500 (47.159)\n",
      "Test: [20/25]\tLoss 1.0959 (1.0035)\tAccuracy 46.875 (49.851)\n",
      "Current Accuracy: 49.937\n",
      "The best accuracy: 57.071\n",
      "An epoch time: 63.9s\n",
      "********************28********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [28][ 0/87]\tLoss 1.1982 (1.1982)\tAccuracy 40.625 (40.625)\n",
      "Epoch: [28][10/87]\tLoss 1.0837 (1.0010)\tAccuracy 43.750 (51.136)\n",
      "Epoch: [28][20/87]\tLoss 1.1249 (0.9852)\tAccuracy 46.875 (53.571)\n",
      "Epoch: [28][30/87]\tLoss 1.0089 (1.0080)\tAccuracy 56.250 (53.327)\n",
      "Epoch: [28][40/87]\tLoss 0.8644 (1.0158)\tAccuracy 56.250 (52.439)\n",
      "Epoch: [28][50/87]\tLoss 0.9497 (1.0088)\tAccuracy 56.250 (52.267)\n",
      "Epoch: [28][60/87]\tLoss 1.1844 (1.0169)\tAccuracy 40.625 (51.588)\n",
      "Epoch: [28][70/87]\tLoss 0.9275 (1.0060)\tAccuracy 46.875 (52.113)\n",
      "Epoch: [28][80/87]\tLoss 0.8309 (1.0064)\tAccuracy 53.125 (52.122)\n",
      "Test: [ 0/25]\tLoss 0.9907 (0.9907)\tAccuracy 56.250 (56.250)\n",
      "Test: [10/25]\tLoss 0.9178 (0.9291)\tAccuracy 62.500 (56.534)\n",
      "Test: [20/25]\tLoss 0.9311 (0.8857)\tAccuracy 50.000 (57.738)\n",
      "Current Accuracy: 57.196\n",
      "The best accuracy: 57.196\n",
      "An epoch time: 64.0s\n",
      "********************29********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [29][ 0/87]\tLoss 0.9651 (0.9651)\tAccuracy 46.875 (46.875)\n",
      "Epoch: [29][10/87]\tLoss 0.7102 (0.9841)\tAccuracy 71.875 (56.250)\n",
      "Epoch: [29][20/87]\tLoss 0.8751 (0.9723)\tAccuracy 53.125 (54.464)\n",
      "Epoch: [29][30/87]\tLoss 0.8302 (0.9811)\tAccuracy 59.375 (54.738)\n",
      "Epoch: [29][40/87]\tLoss 1.0307 (0.9897)\tAccuracy 37.500 (53.887)\n",
      "Epoch: [29][50/87]\tLoss 1.0729 (1.0051)\tAccuracy 53.125 (52.757)\n",
      "Epoch: [29][60/87]\tLoss 1.0752 (1.0097)\tAccuracy 50.000 (52.664)\n",
      "Epoch: [29][70/87]\tLoss 1.1407 (1.0159)\tAccuracy 56.250 (52.509)\n",
      "Epoch: [29][80/87]\tLoss 0.9130 (1.0196)\tAccuracy 59.375 (52.083)\n",
      "Test: [ 0/25]\tLoss 0.9063 (0.9063)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.0300 (0.9315)\tAccuracy 56.250 (53.977)\n",
      "Test: [20/25]\tLoss 0.9166 (0.9055)\tAccuracy 59.375 (55.804)\n",
      "Current Accuracy: 55.945\n",
      "The best accuracy: 57.196\n",
      "An epoch time: 64.0s\n",
      "********************30********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [30][ 0/87]\tLoss 0.8460 (0.8460)\tAccuracy 59.375 (59.375)\n",
      "Epoch: [30][10/87]\tLoss 1.0415 (0.9595)\tAccuracy 62.500 (51.989)\n",
      "Epoch: [30][20/87]\tLoss 1.0913 (0.9729)\tAccuracy 50.000 (52.381)\n",
      "Epoch: [30][30/87]\tLoss 1.0567 (0.9910)\tAccuracy 46.875 (51.915)\n",
      "Epoch: [30][40/87]\tLoss 0.9179 (0.9846)\tAccuracy 50.000 (52.210)\n",
      "Epoch: [30][50/87]\tLoss 0.9758 (0.9824)\tAccuracy 75.000 (53.370)\n",
      "Epoch: [30][60/87]\tLoss 0.9437 (0.9896)\tAccuracy 50.000 (53.125)\n",
      "Epoch: [30][70/87]\tLoss 1.3372 (0.9958)\tAccuracy 46.875 (53.125)\n",
      "Epoch: [30][80/87]\tLoss 0.9181 (0.9919)\tAccuracy 65.625 (53.704)\n",
      "Test: [ 0/25]\tLoss 0.8127 (0.8127)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.1433 (0.9674)\tAccuracy 37.500 (51.989)\n",
      "Test: [20/25]\tLoss 0.9857 (0.9344)\tAccuracy 50.000 (51.339)\n",
      "Current Accuracy: 51.690\n",
      "The best accuracy: 57.196\n",
      "An epoch time: 64.2s\n",
      "********************31********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [31][ 0/87]\tLoss 1.1296 (1.1296)\tAccuracy 37.500 (37.500)\n",
      "Epoch: [31][10/87]\tLoss 1.2167 (1.0695)\tAccuracy 40.625 (49.716)\n",
      "Epoch: [31][20/87]\tLoss 0.9428 (1.0810)\tAccuracy 50.000 (48.512)\n",
      "Epoch: [31][30/87]\tLoss 0.9473 (1.0366)\tAccuracy 50.000 (49.194)\n",
      "Epoch: [31][40/87]\tLoss 0.7855 (1.0108)\tAccuracy 68.750 (50.610)\n",
      "Epoch: [31][50/87]\tLoss 1.2043 (1.0079)\tAccuracy 46.875 (51.532)\n",
      "Epoch: [31][60/87]\tLoss 0.9997 (1.0045)\tAccuracy 53.125 (51.998)\n",
      "Epoch: [31][70/87]\tLoss 1.0890 (0.9988)\tAccuracy 50.000 (52.729)\n",
      "Epoch: [31][80/87]\tLoss 0.7691 (0.9964)\tAccuracy 62.500 (52.816)\n",
      "Test: [ 0/25]\tLoss 0.9262 (0.9262)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.1860 (1.0286)\tAccuracy 46.875 (51.420)\n",
      "Test: [20/25]\tLoss 0.9213 (1.0056)\tAccuracy 56.250 (51.935)\n",
      "Current Accuracy: 51.815\n",
      "The best accuracy: 57.196\n",
      "An epoch time: 63.6s\n",
      "********************32********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [32][ 0/87]\tLoss 0.9407 (0.9407)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [32][10/87]\tLoss 0.7712 (0.9254)\tAccuracy 56.250 (53.125)\n",
      "Epoch: [32][20/87]\tLoss 0.8509 (0.9570)\tAccuracy 71.875 (53.720)\n",
      "Epoch: [32][30/87]\tLoss 0.8271 (0.9244)\tAccuracy 62.500 (55.746)\n",
      "Epoch: [32][40/87]\tLoss 0.9316 (0.9396)\tAccuracy 65.625 (56.021)\n",
      "Epoch: [32][50/87]\tLoss 0.9321 (0.9449)\tAccuracy 59.375 (54.841)\n",
      "Epoch: [32][60/87]\tLoss 1.1009 (0.9471)\tAccuracy 46.875 (54.713)\n",
      "Epoch: [32][70/87]\tLoss 1.2502 (0.9534)\tAccuracy 53.125 (54.401)\n",
      "Epoch: [32][80/87]\tLoss 1.0533 (0.9575)\tAccuracy 46.875 (54.321)\n",
      "Test: [ 0/25]\tLoss 0.8420 (0.8420)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.3069 (1.1083)\tAccuracy 50.000 (48.864)\n",
      "Test: [20/25]\tLoss 0.9290 (1.0517)\tAccuracy 59.375 (51.042)\n",
      "Current Accuracy: 51.189\n",
      "The best accuracy: 57.196\n",
      "An epoch time: 64.1s\n",
      "********************33********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [33][ 0/87]\tLoss 1.0085 (1.0085)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [33][10/87]\tLoss 0.9013 (0.9399)\tAccuracy 53.125 (55.966)\n",
      "Epoch: [33][20/87]\tLoss 1.2064 (0.9834)\tAccuracy 56.250 (53.720)\n",
      "Epoch: [33][30/87]\tLoss 0.8300 (0.9746)\tAccuracy 59.375 (55.343)\n",
      "Epoch: [33][40/87]\tLoss 1.0256 (0.9817)\tAccuracy 59.375 (54.954)\n",
      "Epoch: [33][50/87]\tLoss 0.9193 (0.9803)\tAccuracy 59.375 (55.270)\n",
      "Epoch: [33][60/87]\tLoss 0.8445 (0.9821)\tAccuracy 65.625 (54.508)\n",
      "Epoch: [33][70/87]\tLoss 1.3133 (0.9810)\tAccuracy 37.500 (54.093)\n",
      "Epoch: [33][80/87]\tLoss 0.8940 (0.9753)\tAccuracy 50.000 (54.244)\n",
      "Test: [ 0/25]\tLoss 0.9264 (0.9264)\tAccuracy 59.375 (59.375)\n",
      "Test: [10/25]\tLoss 1.0778 (0.9375)\tAccuracy 53.125 (60.795)\n",
      "Test: [20/25]\tLoss 0.8820 (0.9058)\tAccuracy 53.125 (61.458)\n",
      "Current Accuracy: 61.202\n",
      "The best accuracy: 61.202\n",
      "An epoch time: 64.2s\n",
      "********************34********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [34][ 0/87]\tLoss 0.8221 (0.8221)\tAccuracy 62.500 (62.500)\n",
      "Epoch: [34][10/87]\tLoss 0.9721 (0.9161)\tAccuracy 56.250 (60.795)\n",
      "Epoch: [34][20/87]\tLoss 0.7489 (0.9267)\tAccuracy 71.875 (59.524)\n",
      "Epoch: [34][30/87]\tLoss 0.8848 (0.9407)\tAccuracy 62.500 (58.770)\n",
      "Epoch: [34][40/87]\tLoss 1.0520 (0.9392)\tAccuracy 50.000 (58.765)\n",
      "Epoch: [34][50/87]\tLoss 0.9413 (0.9374)\tAccuracy 46.875 (57.843)\n",
      "Epoch: [34][60/87]\tLoss 1.0685 (0.9459)\tAccuracy 62.500 (57.787)\n",
      "Epoch: [34][70/87]\tLoss 0.8526 (0.9493)\tAccuracy 68.750 (57.394)\n",
      "Epoch: [34][80/87]\tLoss 1.0394 (0.9572)\tAccuracy 40.625 (56.674)\n",
      "Test: [ 0/25]\tLoss 0.7638 (0.7638)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.3385 (0.9819)\tAccuracy 40.625 (52.273)\n",
      "Test: [20/25]\tLoss 0.8155 (0.9440)\tAccuracy 62.500 (54.167)\n",
      "Current Accuracy: 54.568\n",
      "The best accuracy: 61.202\n",
      "An epoch time: 64.2s\n",
      "********************35********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [35][ 0/87]\tLoss 0.8144 (0.8144)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [35][10/87]\tLoss 0.8618 (0.9335)\tAccuracy 65.625 (57.386)\n",
      "Epoch: [35][20/87]\tLoss 0.9593 (0.9302)\tAccuracy 50.000 (57.143)\n",
      "Epoch: [35][30/87]\tLoss 0.9497 (0.9394)\tAccuracy 68.750 (56.653)\n",
      "Epoch: [35][40/87]\tLoss 0.9613 (0.9373)\tAccuracy 65.625 (57.546)\n",
      "Epoch: [35][50/87]\tLoss 0.9078 (0.9483)\tAccuracy 65.625 (57.414)\n",
      "Epoch: [35][60/87]\tLoss 1.0169 (0.9565)\tAccuracy 43.750 (56.814)\n",
      "Epoch: [35][70/87]\tLoss 1.0302 (0.9627)\tAccuracy 59.375 (56.646)\n",
      "Epoch: [35][80/87]\tLoss 0.8420 (0.9554)\tAccuracy 65.625 (56.674)\n",
      "Test: [ 0/25]\tLoss 0.7233 (0.7233)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.0453 (0.8948)\tAccuracy 43.750 (50.852)\n",
      "Test: [20/25]\tLoss 0.7885 (0.8597)\tAccuracy 62.500 (55.952)\n",
      "Current Accuracy: 55.194\n",
      "The best accuracy: 61.202\n",
      "An epoch time: 63.8s\n",
      "********************36********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [36][ 0/87]\tLoss 0.8446 (0.8446)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [36][10/87]\tLoss 0.7172 (0.9813)\tAccuracy 68.750 (52.273)\n",
      "Epoch: [36][20/87]\tLoss 1.2015 (0.9697)\tAccuracy 43.750 (55.506)\n",
      "Epoch: [36][30/87]\tLoss 1.0250 (0.9405)\tAccuracy 62.500 (57.762)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [36][40/87]\tLoss 1.1470 (0.9427)\tAccuracy 43.750 (57.470)\n",
      "Epoch: [36][50/87]\tLoss 0.8186 (0.9296)\tAccuracy 68.750 (58.027)\n",
      "Epoch: [36][60/87]\tLoss 0.9978 (0.9184)\tAccuracy 53.125 (58.402)\n",
      "Epoch: [36][70/87]\tLoss 1.1411 (0.9337)\tAccuracy 56.250 (57.614)\n",
      "Epoch: [36][80/87]\tLoss 0.9803 (0.9409)\tAccuracy 46.875 (57.253)\n",
      "Test: [ 0/25]\tLoss 0.8911 (0.8911)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.4177 (1.0333)\tAccuracy 31.250 (48.580)\n",
      "Test: [20/25]\tLoss 0.8566 (0.9822)\tAccuracy 56.250 (51.042)\n",
      "Current Accuracy: 51.189\n",
      "The best accuracy: 61.202\n",
      "An epoch time: 64.2s\n",
      "********************37********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [37][ 0/87]\tLoss 0.9037 (0.9037)\tAccuracy 62.500 (62.500)\n",
      "Epoch: [37][10/87]\tLoss 0.7495 (0.9359)\tAccuracy 65.625 (55.114)\n",
      "Epoch: [37][20/87]\tLoss 0.8312 (0.9331)\tAccuracy 68.750 (57.589)\n",
      "Epoch: [37][30/87]\tLoss 1.3173 (0.9372)\tAccuracy 43.750 (57.359)\n",
      "Epoch: [37][40/87]\tLoss 1.0828 (0.9516)\tAccuracy 43.750 (56.326)\n",
      "Epoch: [37][50/87]\tLoss 0.9373 (0.9478)\tAccuracy 59.375 (57.108)\n",
      "Epoch: [37][60/87]\tLoss 0.7101 (0.9386)\tAccuracy 65.625 (57.428)\n",
      "Epoch: [37][70/87]\tLoss 0.7566 (0.9300)\tAccuracy 68.750 (57.614)\n",
      "Epoch: [37][80/87]\tLoss 1.0981 (0.9355)\tAccuracy 53.125 (57.716)\n",
      "Test: [ 0/25]\tLoss 1.0624 (1.0624)\tAccuracy 46.875 (46.875)\n",
      "Test: [10/25]\tLoss 1.3842 (1.1346)\tAccuracy 34.375 (42.330)\n",
      "Test: [20/25]\tLoss 1.0026 (1.0675)\tAccuracy 43.750 (47.024)\n",
      "Current Accuracy: 46.683\n",
      "The best accuracy: 61.202\n",
      "An epoch time: 64.2s\n",
      "********************38********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [38][ 0/87]\tLoss 0.7307 (0.7307)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [38][10/87]\tLoss 0.9439 (0.9007)\tAccuracy 53.125 (60.795)\n",
      "Epoch: [38][20/87]\tLoss 1.1572 (0.9250)\tAccuracy 53.125 (59.821)\n",
      "Epoch: [38][30/87]\tLoss 0.8419 (0.9274)\tAccuracy 65.625 (58.266)\n",
      "Epoch: [38][40/87]\tLoss 1.0155 (0.9328)\tAccuracy 50.000 (57.851)\n",
      "Epoch: [38][50/87]\tLoss 0.8514 (0.9353)\tAccuracy 59.375 (57.659)\n",
      "Epoch: [38][60/87]\tLoss 0.9990 (0.9257)\tAccuracy 50.000 (57.889)\n",
      "Epoch: [38][70/87]\tLoss 0.9749 (0.9235)\tAccuracy 65.625 (58.011)\n",
      "Epoch: [38][80/87]\tLoss 1.0698 (0.9274)\tAccuracy 62.500 (58.835)\n",
      "Test: [ 0/25]\tLoss 0.8362 (0.8362)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.1981 (0.9741)\tAccuracy 46.875 (53.693)\n",
      "Test: [20/25]\tLoss 0.8080 (0.9145)\tAccuracy 56.250 (56.696)\n",
      "Current Accuracy: 56.571\n",
      "The best accuracy: 61.202\n",
      "An epoch time: 64.1s\n",
      "********************39********************\n",
      "Current learning rate:  0.01\n",
      "Epoch: [39][ 0/87]\tLoss 0.7735 (0.7735)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [39][10/87]\tLoss 0.8233 (0.8930)\tAccuracy 62.500 (56.534)\n",
      "Epoch: [39][20/87]\tLoss 0.8935 (0.8904)\tAccuracy 56.250 (58.780)\n",
      "Epoch: [39][30/87]\tLoss 0.9904 (0.8872)\tAccuracy 59.375 (60.081)\n",
      "Epoch: [39][40/87]\tLoss 1.0013 (0.9110)\tAccuracy 56.250 (59.527)\n",
      "Epoch: [39][50/87]\tLoss 0.8980 (0.9181)\tAccuracy 53.125 (59.130)\n",
      "Epoch: [39][60/87]\tLoss 0.6088 (0.9194)\tAccuracy 75.000 (59.016)\n",
      "Epoch: [39][70/87]\tLoss 0.7858 (0.9138)\tAccuracy 59.375 (59.463)\n",
      "Epoch: [39][80/87]\tLoss 1.0972 (0.9175)\tAccuracy 46.875 (59.182)\n",
      "Test: [ 0/25]\tLoss 0.8815 (0.8815)\tAccuracy 71.875 (71.875)\n",
      "Test: [10/25]\tLoss 1.2503 (1.0023)\tAccuracy 50.000 (55.682)\n",
      "Test: [20/25]\tLoss 0.7971 (0.9593)\tAccuracy 62.500 (57.589)\n",
      "Current Accuracy: 58.073\n",
      "The best accuracy: 61.202\n",
      "An epoch time: 64.0s\n",
      "********************40********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [40][ 0/87]\tLoss 0.8504 (0.8504)\tAccuracy 50.000 (50.000)\n",
      "Epoch: [40][10/87]\tLoss 0.9389 (0.8092)\tAccuracy 65.625 (62.216)\n",
      "Epoch: [40][20/87]\tLoss 0.8986 (0.8538)\tAccuracy 59.375 (61.310)\n",
      "Epoch: [40][30/87]\tLoss 0.8638 (0.8487)\tAccuracy 56.250 (62.298)\n",
      "Epoch: [40][40/87]\tLoss 1.0742 (0.8531)\tAccuracy 50.000 (62.348)\n",
      "Epoch: [40][50/87]\tLoss 0.6847 (0.8415)\tAccuracy 75.000 (62.806)\n",
      "Epoch: [40][60/87]\tLoss 0.8101 (0.8493)\tAccuracy 62.500 (62.244)\n",
      "Epoch: [40][70/87]\tLoss 0.7261 (0.8488)\tAccuracy 62.500 (62.236)\n",
      "Epoch: [40][80/87]\tLoss 0.8222 (0.8428)\tAccuracy 68.750 (61.998)\n",
      "Test: [ 0/25]\tLoss 0.7306 (0.7306)\tAccuracy 71.875 (71.875)\n",
      "Test: [10/25]\tLoss 1.0235 (0.9037)\tAccuracy 56.250 (58.807)\n",
      "Test: [20/25]\tLoss 0.7834 (0.8636)\tAccuracy 56.250 (61.161)\n",
      "Current Accuracy: 61.702\n",
      "The best accuracy: 61.702\n",
      "An epoch time: 64.2s\n",
      "********************41********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [41][ 0/87]\tLoss 0.6794 (0.6794)\tAccuracy 75.000 (75.000)\n",
      "Epoch: [41][10/87]\tLoss 0.6962 (0.8020)\tAccuracy 68.750 (63.636)\n",
      "Epoch: [41][20/87]\tLoss 0.7599 (0.8252)\tAccuracy 59.375 (62.202)\n",
      "Epoch: [41][30/87]\tLoss 0.7902 (0.8326)\tAccuracy 75.000 (62.702)\n",
      "Epoch: [41][40/87]\tLoss 0.7983 (0.8108)\tAccuracy 65.625 (64.177)\n",
      "Epoch: [41][50/87]\tLoss 0.9147 (0.8200)\tAccuracy 65.625 (63.848)\n",
      "Epoch: [41][60/87]\tLoss 0.6263 (0.8117)\tAccuracy 78.125 (63.422)\n",
      "Epoch: [41][70/87]\tLoss 0.5986 (0.8103)\tAccuracy 87.500 (63.776)\n",
      "Epoch: [41][80/87]\tLoss 0.8767 (0.8126)\tAccuracy 53.125 (63.542)\n",
      "Test: [ 0/25]\tLoss 0.7229 (0.7229)\tAccuracy 75.000 (75.000)\n",
      "Test: [10/25]\tLoss 1.1484 (0.9394)\tAccuracy 59.375 (58.239)\n",
      "Test: [20/25]\tLoss 0.7863 (0.8901)\tAccuracy 62.500 (60.119)\n",
      "Current Accuracy: 60.451\n",
      "The best accuracy: 61.702\n",
      "An epoch time: 64.2s\n",
      "********************42********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [42][ 0/87]\tLoss 0.6522 (0.6522)\tAccuracy 75.000 (75.000)\n",
      "Epoch: [42][10/87]\tLoss 0.6220 (0.7592)\tAccuracy 68.750 (66.477)\n",
      "Epoch: [42][20/87]\tLoss 0.8441 (0.7958)\tAccuracy 56.250 (64.286)\n",
      "Epoch: [42][30/87]\tLoss 0.8935 (0.7798)\tAccuracy 56.250 (65.020)\n",
      "Epoch: [42][40/87]\tLoss 0.7355 (0.7846)\tAccuracy 53.125 (65.015)\n",
      "Epoch: [42][50/87]\tLoss 0.8019 (0.7999)\tAccuracy 62.500 (64.277)\n",
      "Epoch: [42][60/87]\tLoss 0.8183 (0.8055)\tAccuracy 62.500 (63.627)\n",
      "Epoch: [42][70/87]\tLoss 0.7468 (0.7952)\tAccuracy 62.500 (63.908)\n",
      "Epoch: [42][80/87]\tLoss 0.9489 (0.8041)\tAccuracy 68.750 (63.580)\n",
      "Test: [ 0/25]\tLoss 0.6851 (0.6851)\tAccuracy 78.125 (78.125)\n",
      "Test: [10/25]\tLoss 1.1620 (0.9311)\tAccuracy 59.375 (59.943)\n",
      "Test: [20/25]\tLoss 0.8157 (0.8810)\tAccuracy 59.375 (61.607)\n",
      "Current Accuracy: 61.952\n",
      "The best accuracy: 61.952\n",
      "An epoch time: 64.2s\n",
      "********************43********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [43][ 0/87]\tLoss 0.7583 (0.7583)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [43][10/87]\tLoss 0.8401 (0.8805)\tAccuracy 56.250 (57.670)\n",
      "Epoch: [43][20/87]\tLoss 0.6208 (0.8371)\tAccuracy 75.000 (60.268)\n",
      "Epoch: [43][30/87]\tLoss 0.4962 (0.8246)\tAccuracy 87.500 (61.694)\n",
      "Epoch: [43][40/87]\tLoss 0.6966 (0.8081)\tAccuracy 78.125 (63.948)\n",
      "Epoch: [43][50/87]\tLoss 0.9369 (0.8211)\tAccuracy 56.250 (63.542)\n",
      "Epoch: [43][60/87]\tLoss 0.7953 (0.8205)\tAccuracy 59.375 (63.883)\n",
      "Epoch: [43][70/87]\tLoss 0.7811 (0.8129)\tAccuracy 62.500 (64.040)\n",
      "Epoch: [43][80/87]\tLoss 1.0276 (0.8107)\tAccuracy 59.375 (64.468)\n",
      "Test: [ 0/25]\tLoss 0.6952 (0.6952)\tAccuracy 78.125 (78.125)\n",
      "Test: [10/25]\tLoss 1.1113 (0.9222)\tAccuracy 53.125 (59.943)\n",
      "Test: [20/25]\tLoss 0.8093 (0.8751)\tAccuracy 59.375 (61.458)\n",
      "Current Accuracy: 61.452\n",
      "The best accuracy: 61.952\n",
      "An epoch time: 63.8s\n",
      "********************44********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [44][ 0/87]\tLoss 0.8435 (0.8435)\tAccuracy 59.375 (59.375)\n",
      "Epoch: [44][10/87]\tLoss 0.6230 (0.7109)\tAccuracy 71.875 (68.750)\n",
      "Epoch: [44][20/87]\tLoss 0.9761 (0.7611)\tAccuracy 40.625 (65.923)\n",
      "Epoch: [44][30/87]\tLoss 0.6673 (0.7626)\tAccuracy 75.000 (66.331)\n",
      "Epoch: [44][40/87]\tLoss 0.8153 (0.7623)\tAccuracy 59.375 (66.768)\n",
      "Epoch: [44][50/87]\tLoss 0.5749 (0.7692)\tAccuracy 75.000 (65.993)\n",
      "Epoch: [44][60/87]\tLoss 0.8440 (0.7719)\tAccuracy 65.625 (65.984)\n",
      "Epoch: [44][70/87]\tLoss 0.9194 (0.7751)\tAccuracy 56.250 (65.669)\n",
      "Epoch: [44][80/87]\tLoss 0.5620 (0.7795)\tAccuracy 75.000 (65.741)\n",
      "Test: [ 0/25]\tLoss 0.7429 (0.7429)\tAccuracy 78.125 (78.125)\n",
      "Test: [10/25]\tLoss 1.0987 (0.9167)\tAccuracy 53.125 (60.795)\n",
      "Test: [20/25]\tLoss 0.8147 (0.8674)\tAccuracy 56.250 (62.798)\n",
      "Current Accuracy: 62.954\n",
      "The best accuracy: 62.954\n",
      "An epoch time: 64.0s\n",
      "********************45********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [45][ 0/87]\tLoss 0.7775 (0.7775)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [45][10/87]\tLoss 0.9484 (0.8032)\tAccuracy 62.500 (64.489)\n",
      "Epoch: [45][20/87]\tLoss 0.9388 (0.7788)\tAccuracy 56.250 (65.774)\n",
      "Epoch: [45][30/87]\tLoss 0.6859 (0.7786)\tAccuracy 68.750 (65.827)\n",
      "Epoch: [45][40/87]\tLoss 0.7618 (0.7863)\tAccuracy 68.750 (65.091)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [45][50/87]\tLoss 0.5904 (0.7898)\tAccuracy 78.125 (64.828)\n",
      "Epoch: [45][60/87]\tLoss 0.7971 (0.7927)\tAccuracy 59.375 (64.600)\n",
      "Epoch: [45][70/87]\tLoss 0.5212 (0.7895)\tAccuracy 78.125 (65.229)\n",
      "Epoch: [45][80/87]\tLoss 0.7021 (0.7843)\tAccuracy 75.000 (65.702)\n",
      "Test: [ 0/25]\tLoss 0.7087 (0.7087)\tAccuracy 75.000 (75.000)\n",
      "Test: [10/25]\tLoss 1.0618 (0.9003)\tAccuracy 53.125 (59.943)\n",
      "Test: [20/25]\tLoss 0.7917 (0.8516)\tAccuracy 59.375 (61.310)\n",
      "Current Accuracy: 61.202\n",
      "The best accuracy: 62.954\n",
      "An epoch time: 63.9s\n",
      "********************46********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [46][ 0/87]\tLoss 0.8343 (0.8343)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [46][10/87]\tLoss 0.9526 (0.8005)\tAccuracy 46.875 (63.068)\n",
      "Epoch: [46][20/87]\tLoss 0.7853 (0.8436)\tAccuracy 59.375 (61.607)\n",
      "Epoch: [46][30/87]\tLoss 0.6743 (0.8024)\tAccuracy 65.625 (64.113)\n",
      "Epoch: [46][40/87]\tLoss 0.6900 (0.8074)\tAccuracy 71.875 (64.253)\n",
      "Epoch: [46][50/87]\tLoss 0.7532 (0.8023)\tAccuracy 71.875 (64.400)\n",
      "Epoch: [46][60/87]\tLoss 0.7196 (0.7913)\tAccuracy 71.875 (64.600)\n",
      "Epoch: [46][70/87]\tLoss 0.7546 (0.7871)\tAccuracy 71.875 (64.481)\n",
      "Epoch: [46][80/87]\tLoss 0.7523 (0.7900)\tAccuracy 65.625 (64.506)\n",
      "Test: [ 0/25]\tLoss 0.7335 (0.7335)\tAccuracy 78.125 (78.125)\n",
      "Test: [10/25]\tLoss 1.0732 (0.8919)\tAccuracy 53.125 (59.943)\n",
      "Test: [20/25]\tLoss 0.7964 (0.8489)\tAccuracy 59.375 (62.202)\n",
      "Current Accuracy: 62.328\n",
      "The best accuracy: 62.954\n",
      "An epoch time: 63.9s\n",
      "********************47********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [47][ 0/87]\tLoss 0.5519 (0.5519)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [47][10/87]\tLoss 0.6510 (0.7607)\tAccuracy 71.875 (64.773)\n",
      "Epoch: [47][20/87]\tLoss 0.7831 (0.7784)\tAccuracy 65.625 (64.286)\n",
      "Epoch: [47][30/87]\tLoss 0.6293 (0.7699)\tAccuracy 71.875 (64.415)\n",
      "Epoch: [47][40/87]\tLoss 0.6464 (0.7841)\tAccuracy 65.625 (63.872)\n",
      "Epoch: [47][50/87]\tLoss 0.5657 (0.7716)\tAccuracy 81.250 (64.645)\n",
      "Epoch: [47][60/87]\tLoss 0.6077 (0.7611)\tAccuracy 68.750 (64.805)\n",
      "Epoch: [47][70/87]\tLoss 0.7703 (0.7613)\tAccuracy 68.750 (65.317)\n",
      "Epoch: [47][80/87]\tLoss 0.6720 (0.7560)\tAccuracy 62.500 (65.741)\n",
      "Test: [ 0/25]\tLoss 0.6873 (0.6873)\tAccuracy 78.125 (78.125)\n",
      "Test: [10/25]\tLoss 1.0539 (0.9011)\tAccuracy 62.500 (61.932)\n",
      "Test: [20/25]\tLoss 0.8362 (0.8595)\tAccuracy 56.250 (63.542)\n",
      "Current Accuracy: 63.579\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.1s\n",
      "********************48********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [48][ 0/87]\tLoss 0.6861 (0.6861)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [48][10/87]\tLoss 0.7846 (0.7461)\tAccuracy 78.125 (65.625)\n",
      "Epoch: [48][20/87]\tLoss 0.6743 (0.7452)\tAccuracy 62.500 (65.476)\n",
      "Epoch: [48][30/87]\tLoss 0.6081 (0.7388)\tAccuracy 68.750 (66.431)\n",
      "Epoch: [48][40/87]\tLoss 0.9195 (0.7581)\tAccuracy 62.500 (66.082)\n",
      "Epoch: [48][50/87]\tLoss 0.7448 (0.7497)\tAccuracy 65.625 (66.483)\n",
      "Epoch: [48][60/87]\tLoss 0.6698 (0.7483)\tAccuracy 75.000 (66.752)\n",
      "Epoch: [48][70/87]\tLoss 1.1209 (0.7643)\tAccuracy 53.125 (65.845)\n",
      "Epoch: [48][80/87]\tLoss 1.0838 (0.7706)\tAccuracy 59.375 (65.586)\n",
      "Test: [ 0/25]\tLoss 0.7321 (0.7321)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.1551 (0.9248)\tAccuracy 53.125 (58.239)\n",
      "Test: [20/25]\tLoss 0.8107 (0.8725)\tAccuracy 56.250 (60.417)\n",
      "Current Accuracy: 60.576\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************49********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [49][ 0/87]\tLoss 0.6347 (0.6347)\tAccuracy 62.500 (62.500)\n",
      "Epoch: [49][10/87]\tLoss 0.6446 (0.7661)\tAccuracy 71.875 (64.489)\n",
      "Epoch: [49][20/87]\tLoss 0.4443 (0.7244)\tAccuracy 90.625 (67.411)\n",
      "Epoch: [49][30/87]\tLoss 0.7819 (0.7317)\tAccuracy 68.750 (67.641)\n",
      "Epoch: [49][40/87]\tLoss 0.4918 (0.7319)\tAccuracy 78.125 (67.683)\n",
      "Epoch: [49][50/87]\tLoss 0.8773 (0.7460)\tAccuracy 56.250 (67.157)\n",
      "Epoch: [49][60/87]\tLoss 0.6836 (0.7461)\tAccuracy 71.875 (67.316)\n",
      "Epoch: [49][70/87]\tLoss 0.9957 (0.7570)\tAccuracy 59.375 (66.725)\n",
      "Epoch: [49][80/87]\tLoss 0.9311 (0.7612)\tAccuracy 59.375 (66.551)\n",
      "Test: [ 0/25]\tLoss 0.7145 (0.7145)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.0674 (0.8999)\tAccuracy 50.000 (56.818)\n",
      "Test: [20/25]\tLoss 0.8231 (0.8564)\tAccuracy 56.250 (58.780)\n",
      "Current Accuracy: 59.199\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************50********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [50][ 0/87]\tLoss 0.7642 (0.7642)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [50][10/87]\tLoss 0.7312 (0.6818)\tAccuracy 62.500 (69.886)\n",
      "Epoch: [50][20/87]\tLoss 0.7099 (0.7419)\tAccuracy 75.000 (67.113)\n",
      "Epoch: [50][30/87]\tLoss 0.7214 (0.7511)\tAccuracy 68.750 (66.935)\n",
      "Epoch: [50][40/87]\tLoss 0.8754 (0.7527)\tAccuracy 56.250 (66.921)\n",
      "Epoch: [50][50/87]\tLoss 0.6683 (0.7425)\tAccuracy 71.875 (66.728)\n",
      "Epoch: [50][60/87]\tLoss 0.5091 (0.7478)\tAccuracy 84.375 (66.803)\n",
      "Epoch: [50][70/87]\tLoss 0.7821 (0.7475)\tAccuracy 62.500 (66.945)\n",
      "Epoch: [50][80/87]\tLoss 0.6402 (0.7516)\tAccuracy 78.125 (66.474)\n",
      "Test: [ 0/25]\tLoss 0.7076 (0.7076)\tAccuracy 75.000 (75.000)\n",
      "Test: [10/25]\tLoss 1.0976 (0.9497)\tAccuracy 56.250 (57.670)\n",
      "Test: [20/25]\tLoss 0.8326 (0.8983)\tAccuracy 56.250 (59.077)\n",
      "Current Accuracy: 59.574\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************51********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [51][ 0/87]\tLoss 0.9577 (0.9577)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [51][10/87]\tLoss 0.6133 (0.7130)\tAccuracy 68.750 (69.034)\n",
      "Epoch: [51][20/87]\tLoss 0.8596 (0.7202)\tAccuracy 59.375 (67.411)\n",
      "Epoch: [51][30/87]\tLoss 0.8792 (0.7259)\tAccuracy 46.875 (66.633)\n",
      "Epoch: [51][40/87]\tLoss 0.5998 (0.7297)\tAccuracy 71.875 (66.845)\n",
      "Epoch: [51][50/87]\tLoss 1.2046 (0.7438)\tAccuracy 46.875 (66.422)\n",
      "Epoch: [51][60/87]\tLoss 0.8681 (0.7470)\tAccuracy 68.750 (65.830)\n",
      "Epoch: [51][70/87]\tLoss 0.6919 (0.7525)\tAccuracy 68.750 (65.713)\n",
      "Epoch: [51][80/87]\tLoss 0.6770 (0.7580)\tAccuracy 75.000 (65.239)\n",
      "Test: [ 0/25]\tLoss 0.7205 (0.7205)\tAccuracy 78.125 (78.125)\n",
      "Test: [10/25]\tLoss 1.1065 (0.9564)\tAccuracy 53.125 (57.386)\n",
      "Test: [20/25]\tLoss 0.8772 (0.9083)\tAccuracy 56.250 (58.482)\n",
      "Current Accuracy: 58.448\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.7s\n",
      "********************52********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [52][ 0/87]\tLoss 0.6037 (0.6037)\tAccuracy 75.000 (75.000)\n",
      "Epoch: [52][10/87]\tLoss 0.7052 (0.7152)\tAccuracy 62.500 (69.318)\n",
      "Epoch: [52][20/87]\tLoss 0.8668 (0.7425)\tAccuracy 65.625 (67.113)\n",
      "Epoch: [52][30/87]\tLoss 1.0692 (0.7602)\tAccuracy 56.250 (66.431)\n",
      "Epoch: [52][40/87]\tLoss 0.7001 (0.7643)\tAccuracy 65.625 (65.777)\n",
      "Epoch: [52][50/87]\tLoss 0.8385 (0.7634)\tAccuracy 50.000 (65.809)\n",
      "Epoch: [52][60/87]\tLoss 0.8000 (0.7643)\tAccuracy 62.500 (65.830)\n",
      "Epoch: [52][70/87]\tLoss 0.7369 (0.7561)\tAccuracy 68.750 (66.373)\n",
      "Epoch: [52][80/87]\tLoss 0.5019 (0.7584)\tAccuracy 75.000 (66.397)\n",
      "Test: [ 0/25]\tLoss 0.6990 (0.6990)\tAccuracy 71.875 (71.875)\n",
      "Test: [10/25]\tLoss 1.1219 (0.9350)\tAccuracy 53.125 (57.670)\n",
      "Test: [20/25]\tLoss 0.8442 (0.8840)\tAccuracy 56.250 (60.417)\n",
      "Current Accuracy: 60.951\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.5s\n",
      "********************53********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [53][ 0/87]\tLoss 0.6124 (0.6124)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [53][10/87]\tLoss 0.6233 (0.7321)\tAccuracy 75.000 (69.034)\n",
      "Epoch: [53][20/87]\tLoss 0.7260 (0.7211)\tAccuracy 62.500 (69.345)\n",
      "Epoch: [53][30/87]\tLoss 0.6594 (0.7319)\tAccuracy 75.000 (68.548)\n",
      "Epoch: [53][40/87]\tLoss 0.6244 (0.7363)\tAccuracy 75.000 (68.064)\n",
      "Epoch: [53][50/87]\tLoss 0.6059 (0.7261)\tAccuracy 68.750 (68.137)\n",
      "Epoch: [53][60/87]\tLoss 0.6249 (0.7250)\tAccuracy 75.000 (68.033)\n",
      "Epoch: [53][70/87]\tLoss 0.6879 (0.7298)\tAccuracy 68.750 (68.090)\n",
      "Epoch: [53][80/87]\tLoss 0.6992 (0.7297)\tAccuracy 62.500 (67.785)\n",
      "Test: [ 0/25]\tLoss 0.6847 (0.6847)\tAccuracy 78.125 (78.125)\n",
      "Test: [10/25]\tLoss 1.0596 (0.9150)\tAccuracy 53.125 (56.534)\n",
      "Test: [20/25]\tLoss 0.8447 (0.8675)\tAccuracy 53.125 (58.780)\n",
      "Current Accuracy: 59.074\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************54********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [54][ 0/87]\tLoss 1.1210 (1.1210)\tAccuracy 59.375 (59.375)\n",
      "Epoch: [54][10/87]\tLoss 0.5330 (0.7774)\tAccuracy 71.875 (65.341)\n",
      "Epoch: [54][20/87]\tLoss 0.7054 (0.7717)\tAccuracy 75.000 (66.964)\n",
      "Epoch: [54][30/87]\tLoss 0.7433 (0.7507)\tAccuracy 68.750 (67.440)\n",
      "Epoch: [54][40/87]\tLoss 0.7781 (0.7505)\tAccuracy 65.625 (66.845)\n",
      "Epoch: [54][50/87]\tLoss 0.9736 (0.7540)\tAccuracy 56.250 (66.544)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [54][60/87]\tLoss 0.7635 (0.7490)\tAccuracy 62.500 (66.342)\n",
      "Epoch: [54][70/87]\tLoss 0.7577 (0.7374)\tAccuracy 59.375 (66.681)\n",
      "Epoch: [54][80/87]\tLoss 0.7498 (0.7374)\tAccuracy 65.625 (66.782)\n",
      "Test: [ 0/25]\tLoss 0.7276 (0.7276)\tAccuracy 75.000 (75.000)\n",
      "Test: [10/25]\tLoss 1.0743 (0.9421)\tAccuracy 59.375 (60.511)\n",
      "Test: [20/25]\tLoss 0.8390 (0.8946)\tAccuracy 59.375 (62.202)\n",
      "Current Accuracy: 62.078\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************55********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [55][ 0/87]\tLoss 0.8346 (0.8346)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [55][10/87]\tLoss 0.6612 (0.7392)\tAccuracy 78.125 (69.318)\n",
      "Epoch: [55][20/87]\tLoss 0.8001 (0.7669)\tAccuracy 56.250 (68.155)\n",
      "Epoch: [55][30/87]\tLoss 0.5605 (0.7605)\tAccuracy 75.000 (67.742)\n",
      "Epoch: [55][40/87]\tLoss 0.8604 (0.7672)\tAccuracy 65.625 (66.921)\n",
      "Epoch: [55][50/87]\tLoss 0.7041 (0.7616)\tAccuracy 59.375 (66.605)\n",
      "Epoch: [55][60/87]\tLoss 0.6615 (0.7412)\tAccuracy 75.000 (67.469)\n",
      "Epoch: [55][70/87]\tLoss 0.5455 (0.7436)\tAccuracy 71.875 (66.989)\n",
      "Epoch: [55][80/87]\tLoss 0.8468 (0.7445)\tAccuracy 68.750 (66.898)\n",
      "Test: [ 0/25]\tLoss 0.7115 (0.7115)\tAccuracy 75.000 (75.000)\n",
      "Test: [10/25]\tLoss 1.1180 (0.9332)\tAccuracy 53.125 (57.102)\n",
      "Test: [20/25]\tLoss 0.8160 (0.8891)\tAccuracy 56.250 (59.524)\n",
      "Current Accuracy: 59.950\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************56********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [56][ 0/87]\tLoss 0.6985 (0.6985)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [56][10/87]\tLoss 0.7881 (0.6860)\tAccuracy 62.500 (68.466)\n",
      "Epoch: [56][20/87]\tLoss 0.8257 (0.7373)\tAccuracy 68.750 (67.113)\n",
      "Epoch: [56][30/87]\tLoss 0.7336 (0.7363)\tAccuracy 62.500 (67.137)\n",
      "Epoch: [56][40/87]\tLoss 0.6043 (0.7373)\tAccuracy 75.000 (67.607)\n",
      "Epoch: [56][50/87]\tLoss 1.0968 (0.7487)\tAccuracy 56.250 (68.137)\n",
      "Epoch: [56][60/87]\tLoss 0.7690 (0.7538)\tAccuracy 65.625 (67.264)\n",
      "Epoch: [56][70/87]\tLoss 0.8214 (0.7479)\tAccuracy 71.875 (67.254)\n",
      "Epoch: [56][80/87]\tLoss 0.7143 (0.7413)\tAccuracy 75.000 (67.515)\n",
      "Test: [ 0/25]\tLoss 0.7165 (0.7165)\tAccuracy 78.125 (78.125)\n",
      "Test: [10/25]\tLoss 1.2098 (0.9937)\tAccuracy 53.125 (56.818)\n",
      "Test: [20/25]\tLoss 0.8699 (0.9435)\tAccuracy 56.250 (58.333)\n",
      "Current Accuracy: 58.698\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************57********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [57][ 0/87]\tLoss 0.7595 (0.7595)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [57][10/87]\tLoss 0.6810 (0.7158)\tAccuracy 71.875 (69.318)\n",
      "Epoch: [57][20/87]\tLoss 0.6922 (0.7101)\tAccuracy 68.750 (68.899)\n",
      "Epoch: [57][30/87]\tLoss 0.7434 (0.7134)\tAccuracy 75.000 (68.548)\n",
      "Epoch: [57][40/87]\tLoss 0.6028 (0.7186)\tAccuracy 71.875 (67.759)\n",
      "Epoch: [57][50/87]\tLoss 0.8944 (0.7207)\tAccuracy 56.250 (68.015)\n",
      "Epoch: [57][60/87]\tLoss 0.9353 (0.7230)\tAccuracy 50.000 (68.084)\n",
      "Epoch: [57][70/87]\tLoss 0.6261 (0.7171)\tAccuracy 71.875 (68.662)\n",
      "Epoch: [57][80/87]\tLoss 0.5172 (0.7161)\tAccuracy 87.500 (68.827)\n",
      "Test: [ 0/25]\tLoss 0.6922 (0.6922)\tAccuracy 78.125 (78.125)\n",
      "Test: [10/25]\tLoss 1.1133 (0.9425)\tAccuracy 53.125 (57.102)\n",
      "Test: [20/25]\tLoss 0.8642 (0.8994)\tAccuracy 56.250 (58.631)\n",
      "Current Accuracy: 59.199\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************58********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [58][ 0/87]\tLoss 0.5938 (0.5938)\tAccuracy 75.000 (75.000)\n",
      "Epoch: [58][10/87]\tLoss 0.7403 (0.6854)\tAccuracy 68.750 (69.602)\n",
      "Epoch: [58][20/87]\tLoss 0.6188 (0.6889)\tAccuracy 68.750 (69.643)\n",
      "Epoch: [58][30/87]\tLoss 0.7150 (0.6890)\tAccuracy 65.625 (70.060)\n",
      "Epoch: [58][40/87]\tLoss 0.7827 (0.7017)\tAccuracy 62.500 (69.055)\n",
      "Epoch: [58][50/87]\tLoss 0.6969 (0.7096)\tAccuracy 65.625 (68.934)\n",
      "Epoch: [58][60/87]\tLoss 0.6850 (0.7176)\tAccuracy 78.125 (68.596)\n",
      "Epoch: [58][70/87]\tLoss 0.7024 (0.7149)\tAccuracy 62.500 (68.266)\n",
      "Epoch: [58][80/87]\tLoss 0.6427 (0.7128)\tAccuracy 65.625 (68.056)\n",
      "Test: [ 0/25]\tLoss 0.7476 (0.7476)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.0576 (0.9063)\tAccuracy 50.000 (57.386)\n",
      "Test: [20/25]\tLoss 0.7815 (0.8599)\tAccuracy 59.375 (59.524)\n",
      "Current Accuracy: 60.075\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.6s\n",
      "********************59********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [59][ 0/87]\tLoss 0.7889 (0.7889)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [59][10/87]\tLoss 0.7938 (0.7911)\tAccuracy 62.500 (66.193)\n",
      "Epoch: [59][20/87]\tLoss 0.7864 (0.8139)\tAccuracy 65.625 (64.583)\n",
      "Epoch: [59][30/87]\tLoss 0.6077 (0.7823)\tAccuracy 71.875 (66.129)\n",
      "Epoch: [59][40/87]\tLoss 0.5250 (0.7407)\tAccuracy 75.000 (68.216)\n",
      "Epoch: [59][50/87]\tLoss 0.5715 (0.7228)\tAccuracy 75.000 (69.056)\n",
      "Epoch: [59][60/87]\tLoss 0.8331 (0.7213)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [59][70/87]\tLoss 0.6205 (0.7242)\tAccuracy 75.000 (68.794)\n",
      "Epoch: [59][80/87]\tLoss 0.6555 (0.7158)\tAccuracy 78.125 (69.367)\n",
      "Test: [ 0/25]\tLoss 0.7160 (0.7160)\tAccuracy 71.875 (71.875)\n",
      "Test: [10/25]\tLoss 1.0321 (0.9045)\tAccuracy 59.375 (59.091)\n",
      "Test: [20/25]\tLoss 0.8274 (0.8675)\tAccuracy 62.500 (60.268)\n",
      "Current Accuracy: 60.701\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************60********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [60][ 0/87]\tLoss 0.8893 (0.8893)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [60][10/87]\tLoss 0.6402 (0.7469)\tAccuracy 71.875 (63.636)\n",
      "Epoch: [60][20/87]\tLoss 0.7533 (0.7150)\tAccuracy 62.500 (66.518)\n",
      "Epoch: [60][30/87]\tLoss 0.7799 (0.7273)\tAccuracy 65.625 (66.331)\n",
      "Epoch: [60][40/87]\tLoss 0.9054 (0.7347)\tAccuracy 59.375 (65.930)\n",
      "Epoch: [60][50/87]\tLoss 0.5268 (0.7289)\tAccuracy 81.250 (66.667)\n",
      "Epoch: [60][60/87]\tLoss 0.4997 (0.7149)\tAccuracy 78.125 (67.572)\n",
      "Epoch: [60][70/87]\tLoss 0.9312 (0.7260)\tAccuracy 68.750 (67.165)\n",
      "Epoch: [60][80/87]\tLoss 0.6454 (0.7203)\tAccuracy 68.750 (67.438)\n",
      "Test: [ 0/25]\tLoss 0.7542 (0.7542)\tAccuracy 71.875 (71.875)\n",
      "Test: [10/25]\tLoss 1.1105 (0.9815)\tAccuracy 56.250 (56.818)\n",
      "Test: [20/25]\tLoss 0.8666 (0.9329)\tAccuracy 56.250 (57.887)\n",
      "Current Accuracy: 58.949\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.2s\n",
      "********************61********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [61][ 0/87]\tLoss 0.7002 (0.7002)\tAccuracy 75.000 (75.000)\n",
      "Epoch: [61][10/87]\tLoss 0.6021 (0.7378)\tAccuracy 78.125 (69.034)\n",
      "Epoch: [61][20/87]\tLoss 0.5296 (0.7445)\tAccuracy 81.250 (68.155)\n",
      "Epoch: [61][30/87]\tLoss 0.8318 (0.7457)\tAccuracy 68.750 (67.540)\n",
      "Epoch: [61][40/87]\tLoss 0.6758 (0.7311)\tAccuracy 65.625 (67.912)\n",
      "Epoch: [61][50/87]\tLoss 1.2198 (0.7268)\tAccuracy 53.125 (68.015)\n",
      "Epoch: [61][60/87]\tLoss 0.8609 (0.7166)\tAccuracy 62.500 (68.545)\n",
      "Epoch: [61][70/87]\tLoss 0.9246 (0.7137)\tAccuracy 53.125 (68.442)\n",
      "Epoch: [61][80/87]\tLoss 0.6196 (0.7097)\tAccuracy 71.875 (68.634)\n",
      "Test: [ 0/25]\tLoss 0.7272 (0.7272)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 0.9934 (0.9003)\tAccuracy 65.625 (58.523)\n",
      "Test: [20/25]\tLoss 0.8238 (0.8620)\tAccuracy 62.500 (61.161)\n",
      "Current Accuracy: 61.327\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************62********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [62][ 0/87]\tLoss 0.6922 (0.6922)\tAccuracy 62.500 (62.500)\n",
      "Epoch: [62][10/87]\tLoss 0.8188 (0.7137)\tAccuracy 65.625 (68.750)\n",
      "Epoch: [62][20/87]\tLoss 0.9908 (0.7315)\tAccuracy 62.500 (68.452)\n",
      "Epoch: [62][30/87]\tLoss 0.7103 (0.7179)\tAccuracy 71.875 (68.750)\n",
      "Epoch: [62][40/87]\tLoss 0.5736 (0.7232)\tAccuracy 68.750 (68.064)\n",
      "Epoch: [62][50/87]\tLoss 0.6948 (0.7201)\tAccuracy 71.875 (68.505)\n",
      "Epoch: [62][60/87]\tLoss 0.6577 (0.7139)\tAccuracy 68.750 (68.801)\n",
      "Epoch: [62][70/87]\tLoss 0.5719 (0.7082)\tAccuracy 75.000 (68.970)\n",
      "Epoch: [62][80/87]\tLoss 0.5613 (0.7066)\tAccuracy 81.250 (69.483)\n",
      "Test: [ 0/25]\tLoss 0.7331 (0.7331)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.0231 (0.8501)\tAccuracy 53.125 (57.955)\n",
      "Test: [20/25]\tLoss 0.7946 (0.8137)\tAccuracy 59.375 (61.607)\n",
      "Current Accuracy: 62.078\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************63********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [63][ 0/87]\tLoss 0.8190 (0.8190)\tAccuracy 59.375 (59.375)\n",
      "Epoch: [63][10/87]\tLoss 0.6878 (0.7122)\tAccuracy 75.000 (69.602)\n",
      "Epoch: [63][20/87]\tLoss 0.6999 (0.7019)\tAccuracy 68.750 (68.899)\n",
      "Epoch: [63][30/87]\tLoss 0.7771 (0.7266)\tAccuracy 62.500 (67.036)\n",
      "Epoch: [63][40/87]\tLoss 0.6245 (0.7137)\tAccuracy 56.250 (67.835)\n",
      "Epoch: [63][50/87]\tLoss 0.5896 (0.7031)\tAccuracy 68.750 (68.137)\n",
      "Epoch: [63][60/87]\tLoss 0.6796 (0.6984)\tAccuracy 71.875 (68.186)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63][70/87]\tLoss 0.7946 (0.6974)\tAccuracy 75.000 (68.882)\n",
      "Epoch: [63][80/87]\tLoss 0.5405 (0.6909)\tAccuracy 75.000 (69.213)\n",
      "Test: [ 0/25]\tLoss 0.7804 (0.7804)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.0437 (0.9451)\tAccuracy 53.125 (58.807)\n",
      "Test: [20/25]\tLoss 0.8062 (0.8854)\tAccuracy 56.250 (61.012)\n",
      "Current Accuracy: 61.327\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.7s\n",
      "********************64********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [64][ 0/87]\tLoss 0.9003 (0.9003)\tAccuracy 53.125 (53.125)\n",
      "Epoch: [64][10/87]\tLoss 0.6145 (0.7373)\tAccuracy 71.875 (67.045)\n",
      "Epoch: [64][20/87]\tLoss 0.7329 (0.7094)\tAccuracy 68.750 (68.601)\n",
      "Epoch: [64][30/87]\tLoss 0.8472 (0.7172)\tAccuracy 62.500 (68.044)\n",
      "Epoch: [64][40/87]\tLoss 0.7192 (0.7055)\tAccuracy 56.250 (69.207)\n",
      "Epoch: [64][50/87]\tLoss 0.5911 (0.6998)\tAccuracy 71.875 (69.485)\n",
      "Epoch: [64][60/87]\tLoss 0.9848 (0.7147)\tAccuracy 43.750 (69.057)\n",
      "Epoch: [64][70/87]\tLoss 0.8522 (0.7035)\tAccuracy 62.500 (69.938)\n",
      "Epoch: [64][80/87]\tLoss 0.7168 (0.7016)\tAccuracy 71.875 (69.830)\n",
      "Test: [ 0/25]\tLoss 0.7767 (0.7767)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.1415 (0.9379)\tAccuracy 53.125 (56.818)\n",
      "Test: [20/25]\tLoss 0.8063 (0.8907)\tAccuracy 56.250 (58.631)\n",
      "Current Accuracy: 59.074\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************65********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [65][ 0/87]\tLoss 0.5440 (0.5440)\tAccuracy 87.500 (87.500)\n",
      "Epoch: [65][10/87]\tLoss 0.6845 (0.7493)\tAccuracy 65.625 (70.455)\n",
      "Epoch: [65][20/87]\tLoss 0.7941 (0.7106)\tAccuracy 68.750 (70.833)\n",
      "Epoch: [65][30/87]\tLoss 0.5382 (0.7089)\tAccuracy 78.125 (70.464)\n",
      "Epoch: [65][40/87]\tLoss 0.6801 (0.7046)\tAccuracy 71.875 (69.741)\n",
      "Epoch: [65][50/87]\tLoss 1.1028 (0.7124)\tAccuracy 65.625 (69.363)\n",
      "Epoch: [65][60/87]\tLoss 0.6178 (0.7000)\tAccuracy 71.875 (69.826)\n",
      "Epoch: [65][70/87]\tLoss 0.7942 (0.6995)\tAccuracy 62.500 (69.762)\n",
      "Epoch: [65][80/87]\tLoss 0.6706 (0.7072)\tAccuracy 71.875 (69.174)\n",
      "Test: [ 0/25]\tLoss 0.7212 (0.7212)\tAccuracy 71.875 (71.875)\n",
      "Test: [10/25]\tLoss 1.0919 (0.9518)\tAccuracy 59.375 (58.523)\n",
      "Test: [20/25]\tLoss 0.8505 (0.9036)\tAccuracy 59.375 (59.524)\n",
      "Current Accuracy: 60.075\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.7s\n",
      "********************66********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [66][ 0/87]\tLoss 0.7213 (0.7213)\tAccuracy 62.500 (62.500)\n",
      "Epoch: [66][10/87]\tLoss 0.4499 (0.6530)\tAccuracy 81.250 (70.739)\n",
      "Epoch: [66][20/87]\tLoss 0.5648 (0.6405)\tAccuracy 68.750 (71.875)\n",
      "Epoch: [66][30/87]\tLoss 0.9611 (0.6638)\tAccuracy 59.375 (71.573)\n",
      "Epoch: [66][40/87]\tLoss 0.8005 (0.6796)\tAccuracy 56.250 (70.122)\n",
      "Epoch: [66][50/87]\tLoss 0.6607 (0.6834)\tAccuracy 59.375 (69.792)\n",
      "Epoch: [66][60/87]\tLoss 0.6380 (0.6851)\tAccuracy 65.625 (70.287)\n",
      "Epoch: [66][70/87]\tLoss 0.8312 (0.6907)\tAccuracy 53.125 (70.114)\n",
      "Epoch: [66][80/87]\tLoss 0.5937 (0.6905)\tAccuracy 75.000 (69.985)\n",
      "Test: [ 0/25]\tLoss 0.7359 (0.7359)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 0.9380 (0.8758)\tAccuracy 65.625 (61.648)\n",
      "Test: [20/25]\tLoss 0.8038 (0.8284)\tAccuracy 62.500 (62.946)\n",
      "Current Accuracy: 63.204\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.6s\n",
      "********************67********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [67][ 0/87]\tLoss 0.6246 (0.6246)\tAccuracy 75.000 (75.000)\n",
      "Epoch: [67][10/87]\tLoss 0.8454 (0.7681)\tAccuracy 62.500 (67.330)\n",
      "Epoch: [67][20/87]\tLoss 0.5214 (0.7338)\tAccuracy 78.125 (67.411)\n",
      "Epoch: [67][30/87]\tLoss 0.6877 (0.7297)\tAccuracy 71.875 (68.548)\n",
      "Epoch: [67][40/87]\tLoss 0.5867 (0.7333)\tAccuracy 78.125 (68.750)\n",
      "Epoch: [67][50/87]\tLoss 0.5854 (0.7147)\tAccuracy 75.000 (69.975)\n",
      "Epoch: [67][60/87]\tLoss 0.6783 (0.7024)\tAccuracy 53.125 (70.082)\n",
      "Epoch: [67][70/87]\tLoss 0.7575 (0.6987)\tAccuracy 62.500 (70.026)\n",
      "Epoch: [67][80/87]\tLoss 0.8015 (0.7002)\tAccuracy 62.500 (69.946)\n",
      "Test: [ 0/25]\tLoss 0.7849 (0.7849)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 0.9683 (0.8649)\tAccuracy 53.125 (57.386)\n",
      "Test: [20/25]\tLoss 0.7942 (0.8191)\tAccuracy 62.500 (61.012)\n",
      "Current Accuracy: 61.327\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************68********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [68][ 0/87]\tLoss 0.6334 (0.6334)\tAccuracy 75.000 (75.000)\n",
      "Epoch: [68][10/87]\tLoss 0.7096 (0.6737)\tAccuracy 65.625 (70.455)\n",
      "Epoch: [68][20/87]\tLoss 0.9290 (0.6981)\tAccuracy 59.375 (69.345)\n",
      "Epoch: [68][30/87]\tLoss 0.9499 (0.6790)\tAccuracy 59.375 (70.161)\n",
      "Epoch: [68][40/87]\tLoss 0.6249 (0.6851)\tAccuracy 75.000 (69.284)\n",
      "Epoch: [68][50/87]\tLoss 0.6806 (0.6907)\tAccuracy 65.625 (69.056)\n",
      "Epoch: [68][60/87]\tLoss 0.9396 (0.6992)\tAccuracy 59.375 (68.750)\n",
      "Epoch: [68][70/87]\tLoss 0.6652 (0.6955)\tAccuracy 65.625 (68.838)\n",
      "Epoch: [68][80/87]\tLoss 0.7921 (0.6954)\tAccuracy 71.875 (68.827)\n",
      "Test: [ 0/25]\tLoss 0.7169 (0.7169)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.0417 (0.9203)\tAccuracy 53.125 (56.534)\n",
      "Test: [20/25]\tLoss 0.8565 (0.8671)\tAccuracy 62.500 (58.929)\n",
      "Current Accuracy: 59.449\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************69********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [69][ 0/87]\tLoss 0.6178 (0.6178)\tAccuracy 78.125 (78.125)\n",
      "Epoch: [69][10/87]\tLoss 0.5479 (0.6563)\tAccuracy 78.125 (70.170)\n",
      "Epoch: [69][20/87]\tLoss 0.5258 (0.6870)\tAccuracy 81.250 (70.238)\n",
      "Epoch: [69][30/87]\tLoss 0.7890 (0.6754)\tAccuracy 65.625 (70.161)\n",
      "Epoch: [69][40/87]\tLoss 0.7783 (0.6980)\tAccuracy 65.625 (69.588)\n",
      "Epoch: [69][50/87]\tLoss 0.6816 (0.7021)\tAccuracy 68.750 (69.118)\n",
      "Epoch: [69][60/87]\tLoss 0.8502 (0.6936)\tAccuracy 71.875 (69.826)\n",
      "Epoch: [69][70/87]\tLoss 0.7221 (0.6899)\tAccuracy 71.875 (69.894)\n",
      "Epoch: [69][80/87]\tLoss 0.6699 (0.6870)\tAccuracy 65.625 (69.483)\n",
      "Test: [ 0/25]\tLoss 0.7292 (0.7292)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.0061 (0.8985)\tAccuracy 62.500 (58.523)\n",
      "Test: [20/25]\tLoss 0.8218 (0.8552)\tAccuracy 53.125 (59.821)\n",
      "Current Accuracy: 59.950\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.0s\n",
      "********************70********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [70][ 0/87]\tLoss 0.5321 (0.5321)\tAccuracy 78.125 (78.125)\n",
      "Epoch: [70][10/87]\tLoss 0.6515 (0.6363)\tAccuracy 71.875 (72.727)\n",
      "Epoch: [70][20/87]\tLoss 0.5948 (0.6882)\tAccuracy 75.000 (70.982)\n",
      "Epoch: [70][30/87]\tLoss 0.6341 (0.6917)\tAccuracy 75.000 (70.968)\n",
      "Epoch: [70][40/87]\tLoss 0.7566 (0.6972)\tAccuracy 65.625 (70.122)\n",
      "Epoch: [70][50/87]\tLoss 0.5146 (0.6941)\tAccuracy 81.250 (70.343)\n",
      "Epoch: [70][60/87]\tLoss 0.7751 (0.7056)\tAccuracy 75.000 (70.133)\n",
      "Epoch: [70][70/87]\tLoss 0.7328 (0.7016)\tAccuracy 68.750 (70.379)\n",
      "Epoch: [70][80/87]\tLoss 0.7116 (0.7068)\tAccuracy 71.875 (69.869)\n",
      "Test: [ 0/25]\tLoss 0.7995 (0.7995)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.0805 (0.9080)\tAccuracy 56.250 (57.386)\n",
      "Test: [20/25]\tLoss 0.8312 (0.8617)\tAccuracy 56.250 (58.631)\n",
      "Current Accuracy: 59.199\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.6s\n",
      "********************71********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [71][ 0/87]\tLoss 0.5774 (0.5774)\tAccuracy 75.000 (75.000)\n",
      "Epoch: [71][10/87]\tLoss 0.8265 (0.6929)\tAccuracy 56.250 (66.761)\n",
      "Epoch: [71][20/87]\tLoss 0.7012 (0.6948)\tAccuracy 75.000 (68.006)\n",
      "Epoch: [71][30/87]\tLoss 0.8939 (0.6795)\tAccuracy 56.250 (68.952)\n",
      "Epoch: [71][40/87]\tLoss 0.6299 (0.6777)\tAccuracy 68.750 (69.436)\n",
      "Epoch: [71][50/87]\tLoss 0.5501 (0.6859)\tAccuracy 78.125 (69.853)\n",
      "Epoch: [71][60/87]\tLoss 0.7047 (0.6805)\tAccuracy 62.500 (69.980)\n",
      "Epoch: [71][70/87]\tLoss 0.7066 (0.6819)\tAccuracy 59.375 (69.322)\n",
      "Epoch: [71][80/87]\tLoss 0.7657 (0.6846)\tAccuracy 65.625 (69.444)\n",
      "Test: [ 0/25]\tLoss 0.7484 (0.7484)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.0168 (0.8862)\tAccuracy 59.375 (59.943)\n",
      "Test: [20/25]\tLoss 0.8634 (0.8425)\tAccuracy 59.375 (60.863)\n",
      "Current Accuracy: 61.327\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.7s\n",
      "********************72********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [72][ 0/87]\tLoss 0.5799 (0.5799)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [72][10/87]\tLoss 0.5535 (0.6821)\tAccuracy 78.125 (69.318)\n",
      "Epoch: [72][20/87]\tLoss 0.9835 (0.7090)\tAccuracy 53.125 (68.155)\n",
      "Epoch: [72][30/87]\tLoss 0.6900 (0.6842)\tAccuracy 59.375 (69.153)\n",
      "Epoch: [72][40/87]\tLoss 0.6930 (0.6888)\tAccuracy 68.750 (69.741)\n",
      "Epoch: [72][50/87]\tLoss 0.7460 (0.6908)\tAccuracy 68.750 (69.363)\n",
      "Epoch: [72][60/87]\tLoss 0.6586 (0.6892)\tAccuracy 75.000 (69.518)\n",
      "Epoch: [72][70/87]\tLoss 0.6872 (0.6849)\tAccuracy 71.875 (69.630)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [72][80/87]\tLoss 0.9402 (0.6869)\tAccuracy 68.750 (69.753)\n",
      "Test: [ 0/25]\tLoss 0.7460 (0.7460)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.1418 (0.9845)\tAccuracy 50.000 (56.534)\n",
      "Test: [20/25]\tLoss 0.9281 (0.9307)\tAccuracy 56.250 (58.185)\n",
      "Current Accuracy: 58.448\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************73********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [73][ 0/87]\tLoss 0.9373 (0.9373)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [73][10/87]\tLoss 0.5622 (0.7450)\tAccuracy 81.250 (67.898)\n",
      "Epoch: [73][20/87]\tLoss 0.5977 (0.6910)\tAccuracy 78.125 (71.429)\n",
      "Epoch: [73][30/87]\tLoss 0.6183 (0.6853)\tAccuracy 71.875 (70.766)\n",
      "Epoch: [73][40/87]\tLoss 0.8068 (0.6819)\tAccuracy 62.500 (70.274)\n",
      "Epoch: [73][50/87]\tLoss 0.5414 (0.6850)\tAccuracy 78.125 (70.282)\n",
      "Epoch: [73][60/87]\tLoss 0.6007 (0.6807)\tAccuracy 71.875 (70.441)\n",
      "Epoch: [73][70/87]\tLoss 0.5420 (0.6726)\tAccuracy 75.000 (70.863)\n",
      "Epoch: [73][80/87]\tLoss 0.6534 (0.6802)\tAccuracy 71.875 (70.563)\n",
      "Test: [ 0/25]\tLoss 0.7506 (0.7506)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.0984 (0.9842)\tAccuracy 59.375 (58.239)\n",
      "Test: [20/25]\tLoss 0.9143 (0.9266)\tAccuracy 65.625 (59.077)\n",
      "Current Accuracy: 60.075\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************74********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [74][ 0/87]\tLoss 0.7813 (0.7813)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [74][10/87]\tLoss 0.4392 (0.6654)\tAccuracy 90.625 (71.591)\n",
      "Epoch: [74][20/87]\tLoss 0.8550 (0.6699)\tAccuracy 71.875 (71.131)\n",
      "Epoch: [74][30/87]\tLoss 0.6833 (0.6521)\tAccuracy 71.875 (72.480)\n",
      "Epoch: [74][40/87]\tLoss 0.8487 (0.6709)\tAccuracy 65.625 (71.875)\n",
      "Epoch: [74][50/87]\tLoss 0.6411 (0.6711)\tAccuracy 71.875 (71.814)\n",
      "Epoch: [74][60/87]\tLoss 0.6190 (0.6783)\tAccuracy 75.000 (70.748)\n",
      "Epoch: [74][70/87]\tLoss 0.7992 (0.6746)\tAccuracy 65.625 (70.731)\n",
      "Epoch: [74][80/87]\tLoss 0.5761 (0.6648)\tAccuracy 75.000 (71.142)\n",
      "Test: [ 0/25]\tLoss 0.8302 (0.8302)\tAccuracy 56.250 (56.250)\n",
      "Test: [10/25]\tLoss 1.2591 (1.0308)\tAccuracy 46.875 (53.693)\n",
      "Test: [20/25]\tLoss 0.8900 (0.9657)\tAccuracy 62.500 (56.696)\n",
      "Current Accuracy: 56.696\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************75********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [75][ 0/87]\tLoss 0.5303 (0.5303)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [75][10/87]\tLoss 0.4640 (0.6461)\tAccuracy 78.125 (69.034)\n",
      "Epoch: [75][20/87]\tLoss 0.5632 (0.6483)\tAccuracy 78.125 (69.940)\n",
      "Epoch: [75][30/87]\tLoss 0.4992 (0.6687)\tAccuracy 81.250 (69.556)\n",
      "Epoch: [75][40/87]\tLoss 0.6334 (0.6580)\tAccuracy 75.000 (70.427)\n",
      "Epoch: [75][50/87]\tLoss 0.7556 (0.6598)\tAccuracy 62.500 (70.282)\n",
      "Epoch: [75][60/87]\tLoss 0.6176 (0.6652)\tAccuracy 78.125 (70.850)\n",
      "Epoch: [75][70/87]\tLoss 0.5387 (0.6642)\tAccuracy 78.125 (70.863)\n",
      "Epoch: [75][80/87]\tLoss 0.5667 (0.6607)\tAccuracy 78.125 (71.412)\n",
      "Test: [ 0/25]\tLoss 0.7397 (0.7397)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.0254 (0.8909)\tAccuracy 56.250 (61.080)\n",
      "Test: [20/25]\tLoss 0.8044 (0.8429)\tAccuracy 56.250 (62.054)\n",
      "Current Accuracy: 62.954\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************76********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [76][ 0/87]\tLoss 0.5388 (0.5388)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [76][10/87]\tLoss 1.0284 (0.6982)\tAccuracy 56.250 (69.602)\n",
      "Epoch: [76][20/87]\tLoss 0.5494 (0.6638)\tAccuracy 75.000 (72.024)\n",
      "Epoch: [76][30/87]\tLoss 0.6789 (0.6571)\tAccuracy 68.750 (71.371)\n",
      "Epoch: [76][40/87]\tLoss 0.6726 (0.6593)\tAccuracy 62.500 (70.884)\n",
      "Epoch: [76][50/87]\tLoss 0.5441 (0.6569)\tAccuracy 75.000 (71.078)\n",
      "Epoch: [76][60/87]\tLoss 0.5289 (0.6583)\tAccuracy 71.875 (70.902)\n",
      "Epoch: [76][70/87]\tLoss 1.0116 (0.6768)\tAccuracy 59.375 (70.158)\n",
      "Epoch: [76][80/87]\tLoss 0.9232 (0.6684)\tAccuracy 62.500 (70.640)\n",
      "Test: [ 0/25]\tLoss 0.7634 (0.7634)\tAccuracy 71.875 (71.875)\n",
      "Test: [10/25]\tLoss 1.0005 (0.9071)\tAccuracy 53.125 (58.523)\n",
      "Test: [20/25]\tLoss 0.8394 (0.8526)\tAccuracy 65.625 (60.268)\n",
      "Current Accuracy: 60.200\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.2s\n",
      "********************77********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [77][ 0/87]\tLoss 0.7731 (0.7731)\tAccuracy 56.250 (56.250)\n",
      "Epoch: [77][10/87]\tLoss 0.6249 (0.6814)\tAccuracy 78.125 (71.307)\n",
      "Epoch: [77][20/87]\tLoss 0.5981 (0.7073)\tAccuracy 68.750 (69.048)\n",
      "Epoch: [77][30/87]\tLoss 0.5625 (0.6849)\tAccuracy 78.125 (69.758)\n",
      "Epoch: [77][40/87]\tLoss 0.7646 (0.6808)\tAccuracy 62.500 (69.665)\n",
      "Epoch: [77][50/87]\tLoss 1.0058 (0.6798)\tAccuracy 53.125 (69.424)\n",
      "Epoch: [77][60/87]\tLoss 0.5322 (0.6759)\tAccuracy 71.875 (69.621)\n",
      "Epoch: [77][70/87]\tLoss 0.5972 (0.6687)\tAccuracy 65.625 (69.938)\n",
      "Epoch: [77][80/87]\tLoss 0.7935 (0.6678)\tAccuracy 68.750 (70.139)\n",
      "Test: [ 0/25]\tLoss 0.8361 (0.8361)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.0568 (0.8753)\tAccuracy 53.125 (59.375)\n",
      "Test: [20/25]\tLoss 0.8721 (0.8313)\tAccuracy 62.500 (62.649)\n",
      "Current Accuracy: 62.328\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.0s\n",
      "********************78********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [78][ 0/87]\tLoss 0.6780 (0.6780)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [78][10/87]\tLoss 1.1034 (0.7401)\tAccuracy 59.375 (69.318)\n",
      "Epoch: [78][20/87]\tLoss 0.6959 (0.6930)\tAccuracy 62.500 (70.833)\n",
      "Epoch: [78][30/87]\tLoss 0.5317 (0.6863)\tAccuracy 65.625 (70.665)\n",
      "Epoch: [78][40/87]\tLoss 0.5183 (0.6772)\tAccuracy 81.250 (70.884)\n",
      "Epoch: [78][50/87]\tLoss 0.8421 (0.6830)\tAccuracy 68.750 (70.466)\n",
      "Epoch: [78][60/87]\tLoss 0.5745 (0.6747)\tAccuracy 78.125 (70.697)\n",
      "Epoch: [78][70/87]\tLoss 0.8199 (0.6832)\tAccuracy 62.500 (69.982)\n",
      "Epoch: [78][80/87]\tLoss 0.5474 (0.6788)\tAccuracy 84.375 (70.177)\n",
      "Test: [ 0/25]\tLoss 0.7522 (0.7522)\tAccuracy 71.875 (71.875)\n",
      "Test: [10/25]\tLoss 0.9844 (0.8977)\tAccuracy 65.625 (60.227)\n",
      "Test: [20/25]\tLoss 0.8476 (0.8497)\tAccuracy 59.375 (61.161)\n",
      "Current Accuracy: 61.702\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************79********************\n",
      "Current learning rate:  0.001\n",
      "Epoch: [79][ 0/87]\tLoss 0.8388 (0.8388)\tAccuracy 59.375 (59.375)\n",
      "Epoch: [79][10/87]\tLoss 0.5050 (0.6029)\tAccuracy 78.125 (71.023)\n",
      "Epoch: [79][20/87]\tLoss 0.8067 (0.6493)\tAccuracy 65.625 (70.089)\n",
      "Epoch: [79][30/87]\tLoss 0.6394 (0.6573)\tAccuracy 71.875 (69.960)\n",
      "Epoch: [79][40/87]\tLoss 0.6000 (0.6600)\tAccuracy 59.375 (69.741)\n",
      "Epoch: [79][50/87]\tLoss 0.5654 (0.6568)\tAccuracy 68.750 (70.159)\n",
      "Epoch: [79][60/87]\tLoss 0.5778 (0.6640)\tAccuracy 75.000 (69.621)\n",
      "Epoch: [79][70/87]\tLoss 0.6460 (0.6605)\tAccuracy 75.000 (69.806)\n",
      "Epoch: [79][80/87]\tLoss 0.4637 (0.6652)\tAccuracy 78.125 (69.676)\n",
      "Test: [ 0/25]\tLoss 0.8179 (0.8179)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.1609 (0.9690)\tAccuracy 56.250 (57.102)\n",
      "Test: [20/25]\tLoss 0.8613 (0.9060)\tAccuracy 62.500 (59.673)\n",
      "Current Accuracy: 60.075\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************80********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [80][ 0/87]\tLoss 0.6245 (0.6245)\tAccuracy 78.125 (78.125)\n",
      "Epoch: [80][10/87]\tLoss 0.8230 (0.6436)\tAccuracy 59.375 (74.148)\n",
      "Epoch: [80][20/87]\tLoss 0.7889 (0.6674)\tAccuracy 59.375 (70.238)\n",
      "Epoch: [80][30/87]\tLoss 0.6415 (0.6794)\tAccuracy 71.875 (70.867)\n",
      "Epoch: [80][40/87]\tLoss 0.7312 (0.6716)\tAccuracy 59.375 (71.189)\n",
      "Epoch: [80][50/87]\tLoss 0.7410 (0.6664)\tAccuracy 62.500 (71.262)\n",
      "Epoch: [80][60/87]\tLoss 0.7315 (0.6637)\tAccuracy 59.375 (71.158)\n",
      "Epoch: [80][70/87]\tLoss 0.6925 (0.6550)\tAccuracy 56.250 (71.303)\n",
      "Epoch: [80][80/87]\tLoss 0.6224 (0.6547)\tAccuracy 68.750 (71.451)\n",
      "Test: [ 0/25]\tLoss 0.7752 (0.7752)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.1188 (0.9452)\tAccuracy 53.125 (56.250)\n",
      "Test: [20/25]\tLoss 0.8750 (0.8866)\tAccuracy 62.500 (58.929)\n",
      "Current Accuracy: 59.449\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.1s\n",
      "********************81********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [81][ 0/87]\tLoss 0.5757 (0.5757)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [81][10/87]\tLoss 0.5876 (0.6217)\tAccuracy 68.750 (70.455)\n",
      "Epoch: [81][20/87]\tLoss 0.5439 (0.6018)\tAccuracy 78.125 (72.470)\n",
      "Epoch: [81][30/87]\tLoss 0.5750 (0.6101)\tAccuracy 75.000 (71.875)\n",
      "Epoch: [81][40/87]\tLoss 0.8654 (0.6229)\tAccuracy 65.625 (72.027)\n",
      "Epoch: [81][50/87]\tLoss 0.5669 (0.6309)\tAccuracy 71.875 (71.814)\n",
      "Epoch: [81][60/87]\tLoss 0.7047 (0.6353)\tAccuracy 65.625 (71.465)\n",
      "Epoch: [81][70/87]\tLoss 0.5059 (0.6416)\tAccuracy 87.500 (71.743)\n",
      "Epoch: [81][80/87]\tLoss 0.7141 (0.6434)\tAccuracy 62.500 (71.335)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/25]\tLoss 0.7518 (0.7518)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.1313 (0.9627)\tAccuracy 50.000 (57.386)\n",
      "Test: [20/25]\tLoss 0.9032 (0.9018)\tAccuracy 62.500 (59.226)\n",
      "Current Accuracy: 59.700\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************82********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [82][ 0/87]\tLoss 0.5751 (0.5751)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [82][10/87]\tLoss 0.8466 (0.6778)\tAccuracy 65.625 (70.455)\n",
      "Epoch: [82][20/87]\tLoss 0.7997 (0.6708)\tAccuracy 62.500 (69.196)\n",
      "Epoch: [82][30/87]\tLoss 0.8147 (0.6564)\tAccuracy 65.625 (70.665)\n",
      "Epoch: [82][40/87]\tLoss 0.6808 (0.6508)\tAccuracy 71.875 (71.113)\n",
      "Epoch: [82][50/87]\tLoss 0.7730 (0.6495)\tAccuracy 71.875 (71.752)\n",
      "Epoch: [82][60/87]\tLoss 0.6555 (0.6559)\tAccuracy 75.000 (71.516)\n",
      "Epoch: [82][70/87]\tLoss 0.7114 (0.6470)\tAccuracy 65.625 (71.523)\n",
      "Epoch: [82][80/87]\tLoss 0.7771 (0.6417)\tAccuracy 71.875 (71.335)\n",
      "Test: [ 0/25]\tLoss 0.7660 (0.7660)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.1165 (0.9382)\tAccuracy 53.125 (56.250)\n",
      "Test: [20/25]\tLoss 0.8647 (0.8773)\tAccuracy 62.500 (58.631)\n",
      "Current Accuracy: 59.074\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.0s\n",
      "********************83********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [83][ 0/87]\tLoss 0.7299 (0.7299)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [83][10/87]\tLoss 0.8443 (0.6070)\tAccuracy 62.500 (72.443)\n",
      "Epoch: [83][20/87]\tLoss 0.6800 (0.6113)\tAccuracy 65.625 (72.321)\n",
      "Epoch: [83][30/87]\tLoss 0.7544 (0.6279)\tAccuracy 65.625 (71.472)\n",
      "Epoch: [83][40/87]\tLoss 0.5190 (0.6287)\tAccuracy 78.125 (71.570)\n",
      "Epoch: [83][50/87]\tLoss 0.7508 (0.6176)\tAccuracy 65.625 (73.039)\n",
      "Epoch: [83][60/87]\tLoss 0.7299 (0.6346)\tAccuracy 71.875 (71.773)\n",
      "Epoch: [83][70/87]\tLoss 0.4688 (0.6328)\tAccuracy 84.375 (72.579)\n",
      "Epoch: [83][80/87]\tLoss 0.6015 (0.6239)\tAccuracy 71.875 (72.955)\n",
      "Test: [ 0/25]\tLoss 0.7582 (0.7582)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.1749 (0.9711)\tAccuracy 53.125 (57.386)\n",
      "Test: [20/25]\tLoss 0.8831 (0.9041)\tAccuracy 62.500 (59.970)\n",
      "Current Accuracy: 60.451\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.0s\n",
      "********************84********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [84][ 0/87]\tLoss 0.5221 (0.5221)\tAccuracy 84.375 (84.375)\n",
      "Epoch: [84][10/87]\tLoss 0.7239 (0.6556)\tAccuracy 68.750 (73.295)\n",
      "Epoch: [84][20/87]\tLoss 0.5212 (0.6584)\tAccuracy 71.875 (71.577)\n",
      "Epoch: [84][30/87]\tLoss 0.7744 (0.6474)\tAccuracy 59.375 (73.286)\n",
      "Epoch: [84][40/87]\tLoss 0.5055 (0.6539)\tAccuracy 81.250 (72.180)\n",
      "Epoch: [84][50/87]\tLoss 0.8989 (0.6614)\tAccuracy 53.125 (71.691)\n",
      "Epoch: [84][60/87]\tLoss 0.3973 (0.6486)\tAccuracy 81.250 (71.977)\n",
      "Epoch: [84][70/87]\tLoss 0.6473 (0.6404)\tAccuracy 81.250 (72.623)\n",
      "Epoch: [84][80/87]\tLoss 0.6413 (0.6416)\tAccuracy 71.875 (72.415)\n",
      "Test: [ 0/25]\tLoss 0.7528 (0.7528)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.1718 (0.9624)\tAccuracy 53.125 (57.386)\n",
      "Test: [20/25]\tLoss 0.8798 (0.8966)\tAccuracy 62.500 (59.970)\n",
      "Current Accuracy: 60.451\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************85********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [85][ 0/87]\tLoss 0.5265 (0.5265)\tAccuracy 81.250 (81.250)\n",
      "Epoch: [85][10/87]\tLoss 0.8303 (0.6302)\tAccuracy 71.875 (74.432)\n",
      "Epoch: [85][20/87]\tLoss 0.7484 (0.6460)\tAccuracy 65.625 (72.619)\n",
      "Epoch: [85][30/87]\tLoss 0.5134 (0.6363)\tAccuracy 81.250 (72.681)\n",
      "Epoch: [85][40/87]\tLoss 0.7343 (0.6382)\tAccuracy 68.750 (72.256)\n",
      "Epoch: [85][50/87]\tLoss 0.5687 (0.6371)\tAccuracy 75.000 (72.304)\n",
      "Epoch: [85][60/87]\tLoss 0.5647 (0.6386)\tAccuracy 78.125 (72.131)\n",
      "Epoch: [85][70/87]\tLoss 0.7346 (0.6322)\tAccuracy 68.750 (72.623)\n",
      "Epoch: [85][80/87]\tLoss 0.5897 (0.6322)\tAccuracy 75.000 (73.110)\n",
      "Test: [ 0/25]\tLoss 0.7593 (0.7593)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.2085 (0.9929)\tAccuracy 53.125 (55.682)\n",
      "Test: [20/25]\tLoss 0.9124 (0.9236)\tAccuracy 62.500 (58.780)\n",
      "Current Accuracy: 59.074\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.8s\n",
      "********************86********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [86][ 0/87]\tLoss 0.7092 (0.7092)\tAccuracy 75.000 (75.000)\n",
      "Epoch: [86][10/87]\tLoss 0.5957 (0.7122)\tAccuracy 71.875 (66.477)\n",
      "Epoch: [86][20/87]\tLoss 0.5728 (0.6637)\tAccuracy 75.000 (69.494)\n",
      "Epoch: [86][30/87]\tLoss 0.3588 (0.6152)\tAccuracy 87.500 (71.774)\n",
      "Epoch: [86][40/87]\tLoss 0.4561 (0.6203)\tAccuracy 81.250 (72.256)\n",
      "Epoch: [86][50/87]\tLoss 0.6698 (0.6305)\tAccuracy 68.750 (72.426)\n",
      "Epoch: [86][60/87]\tLoss 0.4996 (0.6151)\tAccuracy 78.125 (72.900)\n",
      "Epoch: [86][70/87]\tLoss 0.8211 (0.6204)\tAccuracy 71.875 (73.019)\n",
      "Epoch: [86][80/87]\tLoss 0.4772 (0.6242)\tAccuracy 81.250 (72.492)\n",
      "Test: [ 0/25]\tLoss 0.7533 (0.7533)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.1803 (0.9674)\tAccuracy 56.250 (57.670)\n",
      "Test: [20/25]\tLoss 0.8929 (0.9002)\tAccuracy 62.500 (60.119)\n",
      "Current Accuracy: 60.451\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.0s\n",
      "********************87********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [87][ 0/87]\tLoss 0.5013 (0.5013)\tAccuracy 87.500 (87.500)\n",
      "Epoch: [87][10/87]\tLoss 0.6002 (0.6297)\tAccuracy 71.875 (71.591)\n",
      "Epoch: [87][20/87]\tLoss 0.8378 (0.6496)\tAccuracy 65.625 (72.173)\n",
      "Epoch: [87][30/87]\tLoss 0.4526 (0.6342)\tAccuracy 78.125 (71.976)\n",
      "Epoch: [87][40/87]\tLoss 0.7932 (0.6319)\tAccuracy 53.125 (71.799)\n",
      "Epoch: [87][50/87]\tLoss 0.7020 (0.6273)\tAccuracy 62.500 (72.304)\n",
      "Epoch: [87][60/87]\tLoss 0.8953 (0.6320)\tAccuracy 65.625 (72.234)\n",
      "Epoch: [87][70/87]\tLoss 0.5185 (0.6298)\tAccuracy 78.125 (72.271)\n",
      "Epoch: [87][80/87]\tLoss 0.6474 (0.6303)\tAccuracy 78.125 (72.338)\n",
      "Test: [ 0/25]\tLoss 0.7420 (0.7420)\tAccuracy 68.750 (68.750)\n",
      "Test: [10/25]\tLoss 1.1872 (0.9798)\tAccuracy 53.125 (57.670)\n",
      "Test: [20/25]\tLoss 0.9069 (0.9138)\tAccuracy 65.625 (59.226)\n",
      "Current Accuracy: 59.449\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.3s\n",
      "********************88********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [88][ 0/87]\tLoss 0.5804 (0.5804)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [88][10/87]\tLoss 0.5276 (0.6033)\tAccuracy 68.750 (71.875)\n",
      "Epoch: [88][20/87]\tLoss 0.7134 (0.6000)\tAccuracy 65.625 (73.065)\n",
      "Epoch: [88][30/87]\tLoss 0.6514 (0.6004)\tAccuracy 71.875 (73.790)\n",
      "Epoch: [88][40/87]\tLoss 0.8338 (0.6220)\tAccuracy 59.375 (72.180)\n",
      "Epoch: [88][50/87]\tLoss 0.5957 (0.6105)\tAccuracy 78.125 (72.733)\n",
      "Epoch: [88][60/87]\tLoss 0.5175 (0.6159)\tAccuracy 78.125 (72.541)\n",
      "Epoch: [88][70/87]\tLoss 0.7460 (0.6212)\tAccuracy 62.500 (72.315)\n",
      "Epoch: [88][80/87]\tLoss 0.6410 (0.6224)\tAccuracy 78.125 (72.184)\n",
      "Test: [ 0/25]\tLoss 0.7589 (0.7589)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.1460 (0.9605)\tAccuracy 56.250 (57.670)\n",
      "Test: [20/25]\tLoss 0.8806 (0.8957)\tAccuracy 62.500 (59.821)\n",
      "Current Accuracy: 60.075\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.3s\n",
      "********************89********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [89][ 0/87]\tLoss 0.7230 (0.7230)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [89][10/87]\tLoss 0.8712 (0.6633)\tAccuracy 59.375 (70.739)\n",
      "Epoch: [89][20/87]\tLoss 0.4476 (0.6212)\tAccuracy 87.500 (73.214)\n",
      "Epoch: [89][30/87]\tLoss 0.6685 (0.6155)\tAccuracy 81.250 (74.698)\n",
      "Epoch: [89][40/87]\tLoss 0.5169 (0.6255)\tAccuracy 75.000 (74.085)\n",
      "Epoch: [89][50/87]\tLoss 0.7590 (0.6453)\tAccuracy 68.750 (72.978)\n",
      "Epoch: [89][60/87]\tLoss 0.5174 (0.6341)\tAccuracy 68.750 (73.156)\n",
      "Epoch: [89][70/87]\tLoss 0.6764 (0.6318)\tAccuracy 65.625 (72.975)\n",
      "Epoch: [89][80/87]\tLoss 0.4147 (0.6313)\tAccuracy 81.250 (72.917)\n",
      "Test: [ 0/25]\tLoss 0.7595 (0.7595)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.1601 (0.9625)\tAccuracy 56.250 (56.534)\n",
      "Test: [20/25]\tLoss 0.8940 (0.8973)\tAccuracy 65.625 (59.524)\n",
      "Current Accuracy: 59.700\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.2s\n",
      "********************90********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [90][ 0/87]\tLoss 0.7713 (0.7713)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [90][10/87]\tLoss 0.7429 (0.6393)\tAccuracy 65.625 (73.864)\n",
      "Epoch: [90][20/87]\tLoss 0.4651 (0.6491)\tAccuracy 78.125 (72.173)\n",
      "Epoch: [90][30/87]\tLoss 0.6842 (0.6413)\tAccuracy 68.750 (72.177)\n",
      "Epoch: [90][40/87]\tLoss 0.6659 (0.6488)\tAccuracy 68.750 (71.799)\n",
      "Epoch: [90][50/87]\tLoss 0.5478 (0.6509)\tAccuracy 71.875 (72.243)\n",
      "Epoch: [90][60/87]\tLoss 0.7490 (0.6487)\tAccuracy 78.125 (72.797)\n",
      "Epoch: [90][70/87]\tLoss 0.5492 (0.6534)\tAccuracy 78.125 (72.315)\n",
      "Epoch: [90][80/87]\tLoss 0.4981 (0.6551)\tAccuracy 87.500 (72.029)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/25]\tLoss 0.7561 (0.7561)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.1514 (0.9447)\tAccuracy 56.250 (58.239)\n",
      "Test: [20/25]\tLoss 0.8588 (0.8811)\tAccuracy 62.500 (60.565)\n",
      "Current Accuracy: 60.451\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.2s\n",
      "********************91********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [91][ 0/87]\tLoss 0.4445 (0.4445)\tAccuracy 84.375 (84.375)\n",
      "Epoch: [91][10/87]\tLoss 0.5779 (0.6080)\tAccuracy 68.750 (73.864)\n",
      "Epoch: [91][20/87]\tLoss 0.7065 (0.6032)\tAccuracy 71.875 (73.363)\n",
      "Epoch: [91][30/87]\tLoss 0.7234 (0.6382)\tAccuracy 78.125 (72.379)\n",
      "Epoch: [91][40/87]\tLoss 0.9303 (0.6461)\tAccuracy 59.375 (72.104)\n",
      "Epoch: [91][50/87]\tLoss 0.6845 (0.6372)\tAccuracy 68.750 (72.488)\n",
      "Epoch: [91][60/87]\tLoss 0.6733 (0.6380)\tAccuracy 65.625 (72.336)\n",
      "Epoch: [91][70/87]\tLoss 1.0818 (0.6404)\tAccuracy 62.500 (72.491)\n",
      "Epoch: [91][80/87]\tLoss 0.4746 (0.6290)\tAccuracy 78.125 (72.917)\n",
      "Test: [ 0/25]\tLoss 0.7584 (0.7584)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.1563 (0.9521)\tAccuracy 56.250 (57.955)\n",
      "Test: [20/25]\tLoss 0.8725 (0.8889)\tAccuracy 65.625 (60.119)\n",
      "Current Accuracy: 60.451\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.2s\n",
      "********************92********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [92][ 0/87]\tLoss 0.6971 (0.6971)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [92][10/87]\tLoss 0.7351 (0.6881)\tAccuracy 68.750 (72.159)\n",
      "Epoch: [92][20/87]\tLoss 0.6524 (0.6541)\tAccuracy 65.625 (72.470)\n",
      "Epoch: [92][30/87]\tLoss 0.7487 (0.6602)\tAccuracy 62.500 (71.371)\n",
      "Epoch: [92][40/87]\tLoss 0.6457 (0.6724)\tAccuracy 75.000 (71.265)\n",
      "Epoch: [92][50/87]\tLoss 0.4757 (0.6631)\tAccuracy 78.125 (71.078)\n",
      "Epoch: [92][60/87]\tLoss 0.4454 (0.6579)\tAccuracy 78.125 (70.902)\n",
      "Epoch: [92][70/87]\tLoss 0.7298 (0.6482)\tAccuracy 68.750 (71.171)\n",
      "Epoch: [92][80/87]\tLoss 0.7898 (0.6561)\tAccuracy 50.000 (70.679)\n",
      "Test: [ 0/25]\tLoss 0.7580 (0.7580)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.1208 (0.9403)\tAccuracy 56.250 (58.239)\n",
      "Test: [20/25]\tLoss 0.8611 (0.8749)\tAccuracy 62.500 (60.565)\n",
      "Current Accuracy: 60.576\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.3s\n",
      "********************93********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [93][ 0/87]\tLoss 0.8045 (0.8045)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [93][10/87]\tLoss 0.3781 (0.6472)\tAccuracy 81.250 (72.159)\n",
      "Epoch: [93][20/87]\tLoss 0.5978 (0.6783)\tAccuracy 78.125 (70.089)\n",
      "Epoch: [93][30/87]\tLoss 0.6433 (0.6767)\tAccuracy 78.125 (70.262)\n",
      "Epoch: [93][40/87]\tLoss 0.6621 (0.6858)\tAccuracy 78.125 (70.427)\n",
      "Epoch: [93][50/87]\tLoss 0.6879 (0.6584)\tAccuracy 62.500 (71.569)\n",
      "Epoch: [93][60/87]\tLoss 0.6562 (0.6539)\tAccuracy 68.750 (71.465)\n",
      "Epoch: [93][70/87]\tLoss 0.7241 (0.6527)\tAccuracy 62.500 (71.215)\n",
      "Epoch: [93][80/87]\tLoss 0.5849 (0.6510)\tAccuracy 78.125 (71.682)\n",
      "Test: [ 0/25]\tLoss 0.7473 (0.7473)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.1363 (0.9455)\tAccuracy 53.125 (56.818)\n",
      "Test: [20/25]\tLoss 0.8597 (0.8795)\tAccuracy 62.500 (59.673)\n",
      "Current Accuracy: 59.825\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.0s\n",
      "********************94********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [94][ 0/87]\tLoss 0.5644 (0.5644)\tAccuracy 75.000 (75.000)\n",
      "Epoch: [94][10/87]\tLoss 0.8881 (0.6483)\tAccuracy 65.625 (69.886)\n",
      "Epoch: [94][20/87]\tLoss 0.4512 (0.6297)\tAccuracy 84.375 (71.875)\n",
      "Epoch: [94][30/87]\tLoss 0.7441 (0.6253)\tAccuracy 59.375 (71.673)\n",
      "Epoch: [94][40/87]\tLoss 0.7983 (0.6313)\tAccuracy 65.625 (71.189)\n",
      "Epoch: [94][50/87]\tLoss 0.5861 (0.6300)\tAccuracy 78.125 (71.446)\n",
      "Epoch: [94][60/87]\tLoss 0.6332 (0.6263)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [94][70/87]\tLoss 0.5012 (0.6240)\tAccuracy 68.750 (72.227)\n",
      "Epoch: [94][80/87]\tLoss 0.5570 (0.6189)\tAccuracy 78.125 (72.569)\n",
      "Test: [ 0/25]\tLoss 0.7397 (0.7397)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.1190 (0.9393)\tAccuracy 53.125 (57.955)\n",
      "Test: [20/25]\tLoss 0.8486 (0.8754)\tAccuracy 65.625 (60.268)\n",
      "Current Accuracy: 60.325\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.2s\n",
      "********************95********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [95][ 0/87]\tLoss 0.6308 (0.6308)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [95][10/87]\tLoss 0.6891 (0.6577)\tAccuracy 65.625 (71.023)\n",
      "Epoch: [95][20/87]\tLoss 0.3879 (0.6206)\tAccuracy 87.500 (72.470)\n",
      "Epoch: [95][30/87]\tLoss 0.4460 (0.6184)\tAccuracy 84.375 (72.883)\n",
      "Epoch: [95][40/87]\tLoss 0.6656 (0.6156)\tAccuracy 71.875 (73.552)\n",
      "Epoch: [95][50/87]\tLoss 0.4297 (0.6332)\tAccuracy 84.375 (73.223)\n",
      "Epoch: [95][60/87]\tLoss 0.5055 (0.6293)\tAccuracy 78.125 (73.053)\n",
      "Epoch: [95][70/87]\tLoss 0.4907 (0.6151)\tAccuracy 75.000 (73.548)\n",
      "Epoch: [95][80/87]\tLoss 0.8402 (0.6151)\tAccuracy 62.500 (73.534)\n",
      "Test: [ 0/25]\tLoss 0.7410 (0.7410)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.1151 (0.9407)\tAccuracy 56.250 (57.386)\n",
      "Test: [20/25]\tLoss 0.8521 (0.8751)\tAccuracy 65.625 (60.417)\n",
      "Current Accuracy: 60.576\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.1s\n",
      "********************96********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [96][ 0/87]\tLoss 0.7233 (0.7233)\tAccuracy 71.875 (71.875)\n",
      "Epoch: [96][10/87]\tLoss 0.7996 (0.6445)\tAccuracy 56.250 (72.727)\n",
      "Epoch: [96][20/87]\tLoss 0.5595 (0.6033)\tAccuracy 75.000 (73.958)\n",
      "Epoch: [96][30/87]\tLoss 0.5959 (0.6230)\tAccuracy 68.750 (73.085)\n",
      "Epoch: [96][40/87]\tLoss 0.4739 (0.6192)\tAccuracy 84.375 (73.552)\n",
      "Epoch: [96][50/87]\tLoss 0.8699 (0.6282)\tAccuracy 62.500 (73.100)\n",
      "Epoch: [96][60/87]\tLoss 0.6161 (0.6195)\tAccuracy 75.000 (73.668)\n",
      "Epoch: [96][70/87]\tLoss 0.5925 (0.6214)\tAccuracy 71.875 (73.239)\n",
      "Epoch: [96][80/87]\tLoss 0.6759 (0.6187)\tAccuracy 68.750 (73.650)\n",
      "Test: [ 0/25]\tLoss 0.7159 (0.7159)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.1001 (0.9347)\tAccuracy 56.250 (58.239)\n",
      "Test: [20/25]\tLoss 0.8537 (0.8698)\tAccuracy 62.500 (60.417)\n",
      "Current Accuracy: 60.576\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 63.9s\n",
      "********************97********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [97][ 0/87]\tLoss 0.6016 (0.6016)\tAccuracy 87.500 (87.500)\n",
      "Epoch: [97][10/87]\tLoss 0.5395 (0.6384)\tAccuracy 81.250 (73.295)\n",
      "Epoch: [97][20/87]\tLoss 1.0077 (0.6655)\tAccuracy 56.250 (70.982)\n",
      "Epoch: [97][30/87]\tLoss 0.3799 (0.6419)\tAccuracy 87.500 (72.077)\n",
      "Epoch: [97][40/87]\tLoss 0.8519 (0.6544)\tAccuracy 62.500 (71.113)\n",
      "Epoch: [97][50/87]\tLoss 0.7883 (0.6401)\tAccuracy 62.500 (71.936)\n",
      "Epoch: [97][60/87]\tLoss 0.6893 (0.6348)\tAccuracy 62.500 (72.285)\n",
      "Epoch: [97][70/87]\tLoss 0.6469 (0.6352)\tAccuracy 71.875 (72.183)\n",
      "Epoch: [97][80/87]\tLoss 0.6173 (0.6362)\tAccuracy 78.125 (72.029)\n",
      "Test: [ 0/25]\tLoss 0.7499 (0.7499)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.1071 (0.9323)\tAccuracy 56.250 (57.386)\n",
      "Test: [20/25]\tLoss 0.8550 (0.8663)\tAccuracy 62.500 (60.119)\n",
      "Current Accuracy: 60.451\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.3s\n",
      "********************98********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [98][ 0/87]\tLoss 0.7775 (0.7775)\tAccuracy 65.625 (65.625)\n",
      "Epoch: [98][10/87]\tLoss 0.5572 (0.6156)\tAccuracy 78.125 (71.875)\n",
      "Epoch: [98][20/87]\tLoss 0.4606 (0.6487)\tAccuracy 78.125 (71.577)\n",
      "Epoch: [98][30/87]\tLoss 0.5949 (0.6493)\tAccuracy 71.875 (70.968)\n",
      "Epoch: [98][40/87]\tLoss 0.5399 (0.6487)\tAccuracy 81.250 (72.104)\n",
      "Epoch: [98][50/87]\tLoss 0.4875 (0.6251)\tAccuracy 81.250 (73.591)\n",
      "Epoch: [98][60/87]\tLoss 0.5919 (0.6308)\tAccuracy 71.875 (73.514)\n",
      "Epoch: [98][70/87]\tLoss 0.4290 (0.6271)\tAccuracy 87.500 (73.636)\n",
      "Epoch: [98][80/87]\tLoss 0.7834 (0.6232)\tAccuracy 75.000 (73.727)\n",
      "Test: [ 0/25]\tLoss 0.7549 (0.7549)\tAccuracy 62.500 (62.500)\n",
      "Test: [10/25]\tLoss 1.1488 (0.9600)\tAccuracy 53.125 (57.386)\n",
      "Test: [20/25]\tLoss 0.8598 (0.8935)\tAccuracy 65.625 (59.970)\n",
      "Current Accuracy: 60.325\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.2s\n",
      "********************99********************\n",
      "Current learning rate:  0.0001\n",
      "Epoch: [99][ 0/87]\tLoss 0.5858 (0.5858)\tAccuracy 68.750 (68.750)\n",
      "Epoch: [99][10/87]\tLoss 0.6390 (0.7088)\tAccuracy 68.750 (71.591)\n",
      "Epoch: [99][20/87]\tLoss 0.7653 (0.6634)\tAccuracy 65.625 (71.875)\n",
      "Epoch: [99][30/87]\tLoss 0.5333 (0.6473)\tAccuracy 75.000 (72.177)\n",
      "Epoch: [99][40/87]\tLoss 0.6056 (0.6435)\tAccuracy 65.625 (71.341)\n",
      "Epoch: [99][50/87]\tLoss 0.6110 (0.6388)\tAccuracy 71.875 (71.814)\n",
      "Epoch: [99][60/87]\tLoss 0.5643 (0.6421)\tAccuracy 68.750 (71.465)\n",
      "Epoch: [99][70/87]\tLoss 0.6860 (0.6506)\tAccuracy 75.000 (70.995)\n",
      "Epoch: [99][80/87]\tLoss 0.7235 (0.6514)\tAccuracy 68.750 (70.949)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/25]\tLoss 0.7422 (0.7422)\tAccuracy 65.625 (65.625)\n",
      "Test: [10/25]\tLoss 1.1398 (0.9567)\tAccuracy 53.125 (57.102)\n",
      "Test: [20/25]\tLoss 0.8787 (0.8915)\tAccuracy 65.625 (59.524)\n",
      "Current Accuracy: 59.825\n",
      "The best accuracy: 63.579\n",
      "An epoch time: 64.2s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    inf = '********************' + str(epoch) + '********************'\n",
    "\n",
    "    # evaluate on validation set\n",
    "    val_acc, val_los = validate(val_loader, model, criterion, args)\n",
    "\n",
    "    # remember best acc and save checkpoint\n",
    "    is_best = val_acc > best_acc\n",
    "    best_acc = max(val_acc, best_acc)\n",
    "    save_checkpoint({'epoch': epoch + 1,\n",
    "                     'state_dict': model.state_dict(),\n",
    "                     'best_acc': best_acc,\n",
    "                     'optimizer': optimizer.state_dict(),\n",
    "                     'recorder': recorder}, is_best)\n",
    "\n",
    "    # print and save log\n",
    "    epoch_time = time.time() - start_time\n",
    "    recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n",
    "    recorder.plot_curve(log_curve_path)\n",
    "\n",
    "    print('The best accuracy: {:.3f}'.format(best_acc.item()))\n",
    "    print('An epoch time: {:.1f}s'.format(epoch_time))\n",
    "    with open(log_txt_path, 'a') as f:\n",
    "        f.write('The best accuracy: ' + str(best_acc.item()) + '\\n')\n",
    "        f.write('An epoch time: {:.1f}s' + str(epoch_time) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69b5cea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_loader):\n\u001b[1;32m      6\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      7\u001b[0m         target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/anaconda3/envs/nia/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/nia/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nia/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1315\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1315\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1317\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/nia/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nia/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/nia/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# switch to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, target) in enumerate(val_loader):\n",
    "        output = model(images)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe60bca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 0, 0, 4, 0, 0, 1, 4, 3, 2, 2, 1, 3, 0, 1, 0, 1, 1, 2, 0, 2, 2, 0,\n",
       "        2, 2, 0, 4, 3, 3, 0, 2], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0038a694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5110,  3.3695,  3.8335,  4.5357, -2.8376, -5.9850, -6.0877],\n",
       "        [ 3.3959,  2.8180,  3.7116,  4.6528, -2.7243, -5.8329, -5.9907],\n",
       "        [ 4.4607,  0.2919,  4.1597,  1.8861, -0.1025, -5.3760, -5.1569],\n",
       "        [ 3.4314,  0.6431,  2.0497,  1.2253,  1.7846, -4.5564, -4.7125],\n",
       "        [ 0.1662,  0.5564, -3.8358, -5.7132, 13.0709, -1.6205, -2.9633],\n",
       "        [ 2.4302,  1.7143,  1.7459,  1.5953,  1.1204, -4.3854, -4.6642],\n",
       "        [ 4.3323,  1.2517,  3.7745,  2.0542, -0.3597, -5.6882, -5.6275],\n",
       "        [ 0.8303,  9.5929,  1.9384,  4.8597, -2.9944, -6.2197, -8.0811],\n",
       "        [ 1.5242, -1.0064, -2.3783, -4.5763, 12.0179, -2.1769, -3.2284],\n",
       "        [ 2.8859,  2.2543,  3.0043,  3.6587, -1.1717, -5.0004, -5.4509],\n",
       "        [ 2.6237,  3.5168,  2.6947,  4.1646, -1.7337, -5.1878, -5.7990],\n",
       "        [ 3.1057,  1.6394,  2.9939,  3.8415, -1.0835, -5.0740, -5.2911],\n",
       "        [ 2.0512,  9.3580,  3.2799,  4.7642, -3.4347, -7.1573, -8.2486],\n",
       "        [ 2.7611,  1.8076,  2.9718,  4.2924, -1.5103, -4.8905, -5.1211],\n",
       "        [ 3.2356,  1.6989,  3.6721,  3.9777, -2.3527, -4.9719, -5.0983],\n",
       "        [ 1.5904,  8.8311,  2.0929,  3.6366, -1.9857, -6.4893, -7.7980],\n",
       "        [ 3.0963,  1.5597,  3.0947,  3.5436, -1.4127, -4.8158, -4.9610],\n",
       "        [ 0.6805, 10.4286,  1.7176,  3.8410, -2.6866, -6.3332, -7.4569],\n",
       "        [ 0.4168,  8.1380,  1.5583,  3.1481, -0.0490, -5.5313, -7.2818],\n",
       "        [ 2.1074,  5.2705,  2.7367,  4.1750, -2.2422, -5.6771, -6.0960],\n",
       "        [ 4.3548,  0.8958,  4.0234,  2.8283, -1.2683, -5.5467, -5.3466],\n",
       "        [ 3.8416,  0.8938,  3.6611,  2.5280, -0.6475, -5.3279, -4.9528],\n",
       "        [ 2.8531,  1.4373,  3.1017,  3.1896, -0.4498, -5.1830, -4.9433],\n",
       "        [ 2.9048,  2.7193,  2.9960,  4.0536, -1.8296, -5.4172, -5.4650],\n",
       "        [ 2.9531,  2.3042,  3.4029,  4.7785, -2.3337, -5.4533, -5.5347],\n",
       "        [ 3.2323,  2.1731,  3.8025,  4.8140, -1.7324, -5.5962, -5.9383],\n",
       "        [ 3.1726,  2.4927,  3.2083,  3.4243, -0.9559, -5.4692, -5.6634],\n",
       "        [ 0.7551, -0.7386, -3.2665, -4.9776, 12.9179, -1.5621, -2.8125],\n",
       "        [ 2.9125,  2.1937,  3.3681,  5.1093, -2.3085, -4.9876, -5.4971],\n",
       "        [ 2.9145,  3.0390,  3.6377,  5.4050, -3.9946, -5.2974, -5.4546],\n",
       "        [ 2.9581,  0.3504,  2.3938,  0.9244,  1.7568, -4.1118, -4.2505],\n",
       "        [ 3.7422,  1.9195,  3.9951,  4.1144, -2.4664, -5.5099, -5.5822]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7540861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fb48136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, args):\n",
    "    losses = AverageMeter('Loss', ':.4f')\n",
    "    top1 = AverageMeter('Accuracy', ':6.3f')\n",
    "    progress = ProgressMeter(len(val_loader),\n",
    "                             [losses, top1],\n",
    "                             prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, _ = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i, log_txt_path)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print('Current Accuracy: {top1.avg:.3f}'.format(top1=top1))\n",
    "        with open(log_txt_path, 'a') as f:\n",
    "            f.write('Current Accuracy: {top1.avg:.3f}'.format(top1=top1) + '\\n')\n",
    "            \n",
    "\n",
    "    return top1.avg, losses.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best):\n",
    "    torch.save(state, checkpoint_path)\n",
    "    if is_best:\n",
    "        shutil.copyfile(checkpoint_path, best_checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3d4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
